{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> <ipython-input-10-35b6cd717e55>(87)read_usr_file()->None\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-35b6cd717e55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;31m#read test user trajectory file. In real scenerio, this will be the GPS read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m \u001b[0mread_usr_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;31m#prepere dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-35b6cd717e55>\u001b[0m in \u001b[0;36mread_usr_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musr_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/input_trj_data.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0musr_trejec_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;31m#-------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_return\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;31m# The user issued a 'next' or 'until' command.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoplineno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import math \n",
    "import os\n",
    "import errno\n",
    "import matplotlib.patches as patches\n",
    "from copy import deepcopy\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib.patches import Ellipse, Circle\n",
    "import operator\n",
    "import pdb\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "def read_usr_file():\n",
    "    global usr_trejec_df\n",
    "    \n",
    "    #Load file names for user\n",
    "    filenames = glob.glob(file_source_raw)\n",
    "\n",
    "    #Read the files\n",
    "    list_of_dfs = [pd.read_csv(filename, skiprows=6, header = None) for filename in filenames]\n",
    "\n",
    "    #put the data from list into one dataframe\n",
    "    usr_trejec_df = pd.concat(list_of_dfs, ignore_index=True)\n",
    "    usr_trejec_df.columns = ['Latitude', 'Longitude', '0', 'Altitude', 'NumDays', 'Date', 'Time']\n",
    "    usr_trejec_df[\"Timestamp\"] = usr_trejec_df[\"Date\"].map(str) + \" \" + usr_trejec_df[\"Time\"]\n",
    "    \n",
    "    usr_trejec_df.Timestamp = pd.to_datetime(usr_trejec_df.Timestamp)\n",
    "    \n",
    "    usr_trejec_df.index = usr_trejec_df['Timestamp']\n",
    "    usr_trejec_df = usr_trejec_df.resample('1T').mean()\n",
    "    usr_trejec_df = usr_trejec_df.dropna()\n",
    "    \n",
    "     #add columns to user trajectory dataframe\n",
    "    #1. add timestamp as column\n",
    "    usr_trejec_df['Timestamp'] = pd.to_datetime(usr_trejec_df.index)\n",
    "    #restore date and time column\n",
    "    usr_trejec_df['Date'] = usr_trejec_df.Timestamp.dt.date\n",
    "    usr_trejec_df['Time'] = usr_trejec_df.Timestamp.dt.time\n",
    "\n",
    "    #sort values based on timestamp\n",
    "    usr_trejec_df = usr_trejec_df.sort_values(['Timestamp'])\n",
    "    #reset index\n",
    "    usr_trejec_df = usr_trejec_df.reset_index(drop=True)\n",
    "    #distance between consicutive points to for further checks\n",
    "    usr_trejec_df['Distance(Km)'] = 0\n",
    "    for i in range(0, len(usr_trejec_df)-1):\n",
    "        usr_trejec_df.loc[i+1, 'Distance(Km)'] = (meters(usr_trejec_df.loc[i, 'Latitude'],\n",
    "                                                    usr_trejec_df.loc[i, 'Longitude'],\n",
    "                                                   usr_trejec_df.loc[i+1, 'Latitude'],\n",
    "                                                   usr_trejec_df.loc[i+1, 'Longitude'])) / 1000\n",
    "    usr_trejec_df['Time(Hr)'] = 0\n",
    "    for i in range(0, len(usr_trejec_df)-1):\n",
    "        usr_trejec_df.loc[i+1, 'Time(Hr)'] = (usr_trejec_df.loc[i+1, 'Timestamp'] -\n",
    "                                              usr_trejec_df.loc[i, 'Timestamp']).seconds/3600\n",
    "                                        \n",
    "    usr_trejec_df['Speed(Km/Hr)'] = usr_trejec_df['Distance(Km)'] / usr_trejec_df['Time(Hr)']\n",
    "    \n",
    "    usr_trejec_df['Hour'] = usr_trejec_df.Timestamp.dt.hour\n",
    "\n",
    "    usr_trejec_df['Weekday'] = usr_trejec_df['Timestamp'].dt.weekday.map(str) + usr_trejec_df['Timestamp'].dt.weekday_name\n",
    "\n",
    "    usr_trejec_df['StayPoint'] = -1 # 1 if it is a staypoint, else 0\n",
    "    usr_trejec_df['StayptId'] = -1\n",
    "    usr_trejec_df['StayMeanLat'] = -1.0\n",
    "    usr_trejec_df['StayMeanLon'] = -1.0\n",
    "    usr_trejec_df['State'] = -1     # 1 if it is a state, else 0\n",
    "    usr_trejec_df['StateId'] = -1\n",
    "    usr_trejec_df['StateMeanLat'] = -1.0\n",
    "    usr_trejec_df['StateMeanLon'] = -1.0\n",
    "    \n",
    "    #remove columns not used/required\n",
    "    usr_trejec_df = usr_trejec_df.drop(['0', 'Altitude', 'NumDays'], axis = 1)\n",
    "    \n",
    "    file_name = usr_directory + \"/input_trj_data.csv\"\n",
    "    usr_trejec_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "    import pdb; pdb.set_trace()\n",
    "#-------------------------------\n",
    "def prepare_dfs():\n",
    "    global cluster_hourly_df    \n",
    "    \n",
    "    #create cluster_hourly_df columns\n",
    "    for i in range(0, 24):\n",
    "        cluster_hourly_df['Date'] = 0\n",
    "        cluster_hourly_df['StateId'] = 0\n",
    "        cluster_hourly_df['AvgLat'] = 0\n",
    "        cluster_hourly_df['AvgLon'] = 0\n",
    "        cluster_hourly_df[i] = 0\n",
    "        \n",
    "#------------------------------------------------------------------------------------\n",
    "#Find distance between two lan:lon points in meters\n",
    "def meters(lat1, lon1, lat2, lon2):  \n",
    "    R = 6378.137 # Radius of earth in KM\n",
    "    dLat = lat2 * math.pi / 180 - lat1 * math.pi / 180\n",
    "    dLon = lon2 * math.pi / 180 - lon1 * math.pi / 180\n",
    "    a = math.sin(dLat/2) * math.sin(dLat/2) + math.cos(lat1 * math.pi / 180) * math.cos(lat2 * math.pi / 180) * math.sin(dLon/2) * math.sin(dLon/2);\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a));\n",
    "    d = R * c\n",
    "    return d * 1000 # meters\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "def cluster(newlat, newlon, row, count):\n",
    "    global curr_hr_df\n",
    "    \n",
    "    currcluster = curr_hr_df['StayptId'][row-1]\n",
    "    curr_hr_df['StayptId'][row] = -1\n",
    "    curr_hr_df['StayMeanLat'][row] = -1.0\n",
    "    curr_hr_df['StayMeanLon'][row] = -1.0\n",
    "    curr_hr_df['StayPoint'][row] = -1\n",
    "    clulat = curr_hr_df['StayMeanLat'][row-1]\n",
    "    clulon = curr_hr_df['StayMeanLon'][row-1]\n",
    "    \n",
    "    #if the new point and old point's distance is less than threshold, then add it to current cluster\n",
    "    if meters(clulat, clulon, newlat, newlon)<= staypts_d_thrhld:\n",
    "        curr_hr_df['StayptId'][row] = currcluster\n",
    "        curr_hr_df['StayMeanLat'] = curr_hr_df.groupby('StayptId')['Latitude'].transform(np.mean)\n",
    "        curr_hr_df['StayMeanLon'] = curr_hr_df.groupby('StayptId')['Longitude'].transform(np.mean)\n",
    "        count = count + 1\n",
    "        \n",
    "    #if the new point and old point's distance is greater than threshold, it means the point moved away\n",
    "    #if the previous cluster has more than two points, check the duration of the previous cluster\n",
    "    #   if the duration of the previos cluster is greater than threshold, assign it as a staypoint\n",
    "    else:\n",
    "        \n",
    "        if count >= 2:\n",
    "            MinClusTime = curr_hr_df['Timestamp'][row-count]\n",
    "            MaxClusTime = curr_hr_df['Timestamp'][row-1]\n",
    "            k = MaxClusTime - MinClusTime\n",
    "            l = (k / np.timedelta64(1, 'm')).astype(int)\n",
    "            \n",
    "            if (l >= staypts_t_thrhld):\n",
    "                curr_hr_df.loc[ (curr_hr_df['StayptId']==currcluster), 'StayPoint'] = 1\n",
    "        count = 1\n",
    "        curr_hr_df['StayMeanLat'][row] = curr_hr_df['Latitude'][row]\n",
    "        curr_hr_df['StayMeanLon'][row] = curr_hr_df['Longitude'][row]\n",
    "        curr_hr_df['StayptId'][row] = currcluster + 1\n",
    "    return count\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "def read_trained_model():\n",
    "    global trained_model_df\n",
    "    \n",
    "    if os.path.isfile(dest_file_final_markov_chain):\n",
    "        trained_model_df = pd.read_csv(dest_file_final_markov_chain, header = 0, sep=\"\\t\")\n",
    "    \n",
    "#------------------------------------------------------------------------------------\n",
    "def create_last_hr_staypts():\n",
    "    global curr_hr_df          #holds current hour points\n",
    "    global staypts_df          #holds all staypoints\n",
    "    global curr_hr_staypts_df  #holds current hour staypoints only\n",
    "    \n",
    "    #clear current hour staypoints dataframe\n",
    "    curr_hr_staypts_df = curr_hr_staypts_df.iloc[0:0]\n",
    "    \n",
    "    #reset index of current hour points\n",
    "    curr_hr_df = curr_hr_df.reset_index(drop=True)\n",
    "    \n",
    "    #Read the file in an online manner as the points come and assign the points to clusters\n",
    "    row =1\n",
    "    count = 1\n",
    "    if not staypts_df.empty:\n",
    "        curr_hr_df['StayptId'][row-1] = staypts_df['StayptId'].max() + 1 #assign next possible staypt id\n",
    "    else:\n",
    "        curr_hr_df['StayptId'][row-1] = 1 #if this is the start, start from 1 as staypointID\n",
    "    \n",
    "    curr_hr_df['StayMeanLat'][row-1] = curr_hr_df['Latitude'][0]\n",
    "    curr_hr_df['StayMeanLon'][row-1] = curr_hr_df['Longitude'][0]\n",
    "    curr_hr_df['StayPoint'][row-1] = -1\n",
    "    \n",
    "    while row < len(curr_hr_df):\n",
    "        count = cluster(curr_hr_df['Latitude'][row], curr_hr_df['Longitude'][row], row, count)\n",
    "        row= row + 1\n",
    "    \n",
    "    #copy the staypoints to the current hour staypoints dataframe\n",
    "    curr_hr_staypts_df = curr_hr_df.loc[curr_hr_df['StayPoint'] == 1]\n",
    "    #copy the stay points into another dataframe\n",
    "    staypts_df = staypts_df.append(curr_hr_df.loc[curr_hr_df['StayPoint'] == 1])\n",
    "    #reset staypoints index\n",
    "    curr_hr_staypts_df.index = curr_hr_staypts_df['Timestamp']\n",
    "    staypts_df.index = staypts_df['Timestamp']\n",
    "    #clear current hour dataframe content\n",
    "    curr_hr_df = curr_hr_df.iloc[0:0]\n",
    "    \n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "def cal_hourly_state_weight():\n",
    "    global curr_hr_staypts_df\n",
    "    global cluster_hourly_df   \n",
    "    \n",
    "    curr_hr_cluster_hourly_df = pd.DataFrame()       \n",
    "    \n",
    "    last_hour = curr_hr_staypts_df['Timestamp'][0].hour\n",
    "    last_clusid = curr_hr_staypts_df['StateId'][0]\n",
    "    curr_count = 0\n",
    "    j = 0\n",
    "    \n",
    "    for i in range(0, 24):\n",
    "        curr_hr_cluster_hourly_df['Date'] = 0\n",
    "        curr_hr_cluster_hourly_df['StateId'] = 0\n",
    "        curr_hr_cluster_hourly_df['AvgLat'] = 0\n",
    "        curr_hr_cluster_hourly_df['AvgLon'] = 0\n",
    "        curr_hr_cluster_hourly_df[i] = 0\n",
    "    \n",
    "    for i in range(0, len(curr_hr_staypts_df)):\n",
    "\n",
    "        if (i == len(curr_hr_staypts_df)-1):\n",
    "            \n",
    "            k = curr_hr_staypts_df['Timestamp'][i] - curr_hr_staypts_df['Timestamp'][i-curr_count]\n",
    "            l = (k / np.timedelta64(1, 'm')).astype(int)\n",
    "            \n",
    "            date_read = curr_hr_staypts_df.index[i].date()\n",
    "            cluster_id = curr_hr_staypts_df['StateId'][i]\n",
    "            ClusterMeanLat = curr_hr_staypts_df['StateMeanLat'][i]\n",
    "            ClusterMeanLon = curr_hr_staypts_df['StateMeanLon'][i]\n",
    "            col_name = curr_hr_staypts_df.index[i].hour\n",
    "\n",
    "            curr_hr_cluster_hourly_df.loc[j,'AvgLat'] = ClusterMeanLat\n",
    "            curr_hr_cluster_hourly_df.loc[j,'AvgLon'] = ClusterMeanLon\n",
    "            curr_hr_cluster_hourly_df.loc[j,'Date'] = date_read\n",
    "            curr_hr_cluster_hourly_df.loc[j,'StateId'] = cluster_id\n",
    "            curr_hr_cluster_hourly_df.loc[j, col_name] = round((l)/60,4)\n",
    "            \n",
    "        if (curr_hr_staypts_df['Timestamp'][i].hour != last_hour) | (curr_hr_staypts_df['StateId'][i] != last_clusid):\n",
    "            #import pdb; pdb.set_trace()\n",
    "\n",
    "            if (curr_count == 1) & (curr_hr_staypts_df['Timestamp'][i].hour != last_hour):\n",
    "                k = ((curr_hr_staypts_df['Timestamp'][i-1] + pd.Timedelta(hours=1) - \n",
    "                      pd.Timedelta(minutes=curr_hr_staypts_df['Timestamp'][i-1].minute)) - \n",
    "                     curr_hr_staypts_df['Timestamp'][i-1])\n",
    "            else:\n",
    "                k = curr_hr_staypts_df['Timestamp'][i-1] - curr_hr_staypts_df['Timestamp'][i-curr_count]\n",
    "\n",
    "            l = (k / np.timedelta64(1, 'm')).astype(int)\n",
    "            date_read = curr_hr_staypts_df.index[i-1].date()\n",
    "            cluster_id = curr_hr_staypts_df['StateId'][i-1]\n",
    "            ClusterMeanLat = curr_hr_staypts_df['StateMeanLat'][i-1]\n",
    "            ClusterMeanLon = curr_hr_staypts_df['StateMeanLon'][i-1]\n",
    "            col_name = curr_hr_staypts_df.index[i-1].hour\n",
    "\n",
    "            curr_hr_cluster_hourly_df.loc[j, 'AvgLat'] = ClusterMeanLat\n",
    "            curr_hr_cluster_hourly_df.loc[j, 'AvgLon'] = ClusterMeanLon\n",
    "            curr_hr_cluster_hourly_df.loc[j, 'Date'] = date_read\n",
    "            curr_hr_cluster_hourly_df.loc[j, 'StateId'] = cluster_id\n",
    "            curr_hr_cluster_hourly_df.loc[j, col_name] = round((l)/60,4)\n",
    "            j = j + 1\n",
    "            curr_count = 1\n",
    "\n",
    "            if (curr_hr_staypts_df['Timestamp'][i].hour != last_hour):\n",
    "                last_hour = curr_hr_staypts_df['Timestamp'][i].hour\n",
    "            if (curr_hr_staypts_df['StateId'][i] != last_clusid):\n",
    "                last_clusid = curr_hr_staypts_df['StateId'][i]\n",
    "        else:\n",
    "            curr_count = curr_count + 1\n",
    "\n",
    "    curr_hr_cluster_hourly_df = curr_hr_cluster_hourly_df.fillna(0)\n",
    "    curr_hr_cluster_hourly_df = curr_hr_cluster_hourly_df.groupby(['Date', 'StateId', 'AvgLat', 'AvgLon']).sum()\n",
    "    curr_hr_cluster_hourly_df = curr_hr_cluster_hourly_df.reset_index(level=[0,1,2,3])\n",
    "   \n",
    "    cluster_hourly_df = cluster_hourly_df.append(curr_hr_cluster_hourly_df, ignore_index=True)\n",
    "    cluster_hourly_df = cluster_hourly_df.reset_index(drop=True)\n",
    "    \n",
    "#-------------form states-----------------------------------------------------------------------\n",
    "def form_states():\n",
    "    global staypts_df\n",
    "    global curr_hr_staypts_df\n",
    "    \n",
    "    #update states in final staypoints\n",
    "    #copy staypoint data as state data\n",
    "    staypts_df['StateId'] = staypts_df['StayptId']\n",
    "    staypts_df['StateMeanLat'] = staypts_df['StayMeanLat']\n",
    "    staypts_df['StateMeanLon'] = staypts_df['StayMeanLon']\n",
    "    \n",
    "    #this fucntion groups the staypoints together to from different days \n",
    "    #Copy the stay points dataframe into another dataframe and remove duplicates\n",
    "    staypts_df1 = staypts_df[['StateId', 'StateMeanLat', 'StateMeanLon']].copy()\n",
    "    staypts_df1 = staypts_df1.drop_duplicates(subset=['StateId', 'StateMeanLat', 'StateMeanLon'])\n",
    "\n",
    "    staypts_df1 = staypts_df1.sort_values(['StateMeanLat', 'StateMeanLon'])\n",
    "    staypts_df1 = staypts_df1.reset_index(drop=True)\n",
    "    \n",
    "    row = 1\n",
    "    for i in range(0, len(staypts_df1)):\n",
    "        for j in range(i+1, len(staypts_df1)):\n",
    "        \n",
    "            chk_cluster = staypts_df1['StateId'][i]\n",
    "            chk_clulat = staypts_df1['StateMeanLat'][i]\n",
    "            chk_clulon = staypts_df1['StateMeanLon'][i]\n",
    "            curr_cluster = staypts_df1['StateId'][j]\n",
    "            curr_clulat = staypts_df1['StateMeanLat'][j]\n",
    "            curr_clulon = staypts_df1['StateMeanLon'][j]\n",
    "        \n",
    "            if meters(chk_clulat, chk_clulon, curr_clulat, curr_clulon)<= state_d_thrhld:\n",
    "                staypts_df.loc[ (staypts_df['StateId']==curr_cluster), 'StateId'] = chk_cluster\n",
    "                staypts_df['StateMeanLat'] = staypts_df.groupby('StayptId')['StateMeanLat'].transform(np.mean)\n",
    "                staypts_df['StateMeanLon'] = staypts_df.groupby('StayptId')['StateMeanLon'].transform(np.mean)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    #update states for last hour staypoints\n",
    "    #copy staypoint data as state data\n",
    "    curr_hr_staypts_df['StateId'] = curr_hr_staypts_df['StayptId']\n",
    "    curr_hr_staypts_df['StateMeanLat'] = curr_hr_staypts_df['StayMeanLat']\n",
    "    curr_hr_staypts_df['StateMeanLon'] = curr_hr_staypts_df['StayMeanLon']\n",
    "    \n",
    "    #this fucntion groups the staypoints together to from different days \n",
    "    #Copy the stay points dataframe into another dataframe and remove duplicates\n",
    "    curr_hr_staypts_df1 = curr_hr_staypts_df[['StateId', 'StateMeanLat', 'StateMeanLon']].copy()\n",
    "    curr_hr_staypts_df1 = curr_hr_staypts_df1.drop_duplicates(subset=['StateId', 'StateMeanLat', 'StateMeanLon'])\n",
    "\n",
    "    curr_hr_staypts_df1 = curr_hr_staypts_df1.sort_values(['StateMeanLat', 'StateMeanLon'])\n",
    "    curr_hr_staypts_df1 = curr_hr_staypts_df1.reset_index(drop=True)\n",
    "    \n",
    "    row = 1\n",
    "    for i in range(0, len(curr_hr_staypts_df1)):\n",
    "        for j in range(i+1, len(curr_hr_staypts_df1)):\n",
    "        \n",
    "            chk_cluster = curr_hr_staypts_df1['StateId'][i]\n",
    "            chk_clulat = curr_hr_staypts_df1['StateMeanLat'][i]\n",
    "            chk_clulon = curr_hr_staypts_df1['StateMeanLon'][i]\n",
    "            curr_cluster = curr_hr_staypts_df1['StateId'][j]\n",
    "            curr_clulat = curr_hr_staypts_df1['StateMeanLat'][j]\n",
    "            curr_clulon = curr_hr_staypts_df1['StateMeanLon'][j]\n",
    "        \n",
    "            if meters(chk_clulat, chk_clulon, curr_clulat, curr_clulon)<= state_d_thrhld:\n",
    "                curr_hr_staypts_df.loc[ (curr_hr_staypts_df['StateId']==curr_cluster), 'StateId'] = chk_cluster\n",
    "                curr_hr_staypts_df['StateMeanLat'] = curr_hr_staypts_df.groupby('StayptId')['StateMeanLat'].transform(np.mean)\n",
    "                curr_hr_staypts_df['StateMeanLon'] = curr_hr_staypts_df.groupby('StayptId')['StateMeanLon'].transform(np.mean)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "#------------------------------------------------------------------------------------------------\n",
    "def visualize_hourly_state_weight():\n",
    "    global staypts_df\n",
    "    \n",
    "    #create a color dictionary for each cluster for the plot\n",
    "    dicts = {}\n",
    "    clu_list = []\n",
    "    clu_list = staypts_df['StateId'].unique()\n",
    "    #r = lambda: random.randint(0,255)\n",
    "    colors = sns.color_palette(\"Paired\", len(clu_list))\n",
    "    \n",
    "    for i in range(0, len(clu_list)):\n",
    "        dicts[clu_list[i]] = (colors[i])\n",
    "        #dicts[clu_list[i]] = ('#%02X%02X%02X' % (r(),r(),r()))\n",
    "        \n",
    "    #create a new graph where we will later add rectangles for each hour:cluster\n",
    "    fig2 = plt.figure(figsize=(15,15))\n",
    "    ax1 = fig2.add_subplot(111, aspect='equal')\n",
    "\n",
    "    #get all the dates for y axis\n",
    "    date_list = staypts_df['Timestamp'].dt.date.unique()\n",
    "    y = range(0, len(date_list))\n",
    "    def_yticks = date_list\n",
    "    plt.yticks(y, def_yticks)\n",
    "    \n",
    "    #set the x axis limit from 0-24 hours of a day, y axis with dates\n",
    "    limsx = (0, 24)\n",
    "    limsy = (0, len(date_list))\n",
    "\n",
    "    date_counter = 0\n",
    "    last_date = staypts_df['Timestamp'][0].date()\n",
    "    last_hour = staypts_df['Timestamp'][0].hour\n",
    "    last_clusid = staypts_df['StateId'][0]\n",
    "    curr_count = 0\n",
    "    j = 0\n",
    "    \n",
    "    #drawing verical lines for each hour\n",
    "    for i in range(0, 24):\n",
    "        ax1.axvline(x= i, linewidth=1, color='r')\n",
    "\n",
    "    for i in range(0, len(staypts_df)):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        \n",
    "        if (i == len(staypts_df)-1):\n",
    "            a = staypts_df['Timestamp'][i-curr_count].hour + staypts_df['Timestamp'][i-curr_count].minute/60\n",
    "            b = staypts_df['Timestamp'][i].hour + staypts_df['Timestamp'][i].minute/60\n",
    "            width = b - a\n",
    "            height = 1\n",
    "            col_id = dicts.get(staypts_df['StateId'][i])\n",
    "            ax1.add_patch(patches.Rectangle((a, date_counter), width, height, color=col_id, label=staypts_df['StateId'][i]))\n",
    "            \n",
    "        #plot a rectangle if the hour or stateid or date has changed\n",
    "        if ((staypts_df['Timestamp'][i].hour != last_hour) | (staypts_df['StateId'][i] != last_clusid)\n",
    "           | (last_date != staypts_df['Timestamp'][i].date())):\n",
    "\n",
    "            if (curr_count == 1) & (staypts_df['Timestamp'][i].hour != last_hour):\n",
    "                a = staypts_df['Timestamp'][i-curr_count].hour + 1\n",
    "            else:\n",
    "                a = staypts_df['Timestamp'][i-curr_count].hour + staypts_df['Timestamp'][i-curr_count].minute/60\n",
    "\n",
    "            b = staypts_df['Timestamp'][i-1].hour + staypts_df['Timestamp'][i-1].minute/60\n",
    "\n",
    "            width = b - a\n",
    "            height = 1\n",
    "            col_id = dicts.get(staypts_df['StateId'][i-1])\n",
    "            ax1.add_patch(patches.Rectangle((a, date_counter), width, height, color=col_id, label=staypts_df['StateId'][i-1]))\n",
    "\n",
    "            curr_count = 1\n",
    "\n",
    "            if (staypts_df['Timestamp'][i].hour != last_hour):\n",
    "                last_hour = staypts_df['Timestamp'][i].hour\n",
    "            if (staypts_df['StateId'][i] != last_clusid):\n",
    "                last_clusid = staypts_df['StateId'][i]\n",
    "            if (last_date != staypts_df['Timestamp'][i].date()):\n",
    "                date_counter = date_counter + 1\n",
    "                last_date = staypts_df['Timestamp'][i].date()\n",
    "                ax1.axhline(y= date_counter, linewidth=1, color='r')\n",
    "\n",
    "        else:\n",
    "            curr_count = curr_count + 1\n",
    "            \n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    handle_list, label_list = [], []\n",
    "    for handle, label in zip(handles, labels):\n",
    "        if label not in label_list:\n",
    "            handle_list.append(handle)\n",
    "            label_list.append(label)\n",
    "    plt.legend(handle_list, label_list)\n",
    "\n",
    "    plt.xlim(limsx)\n",
    "    plt.ylim(limsy)\n",
    "    plt.show()\n",
    "#-----------------------------------------------------------------------------------\n",
    "def update_staypts_csv():\n",
    "     with open(dest_file_staypoints, 'a') as f:\n",
    "             (staypts_df).to_csv(f,  sep='\\t', encoding='utf-8')\n",
    "#-----------------------------------------------------------------------------------\n",
    "def update_hourly_weights_csv():\n",
    "    with open(dest_file_hourly_weights, 'a') as f:\n",
    "             (cluster_hourly_df).to_csv(f,  sep='\\t', encoding='utf-8')\n",
    "#------------------------------------------------------------------------------------\n",
    "def create_save_seperate_trasition_matrices():\n",
    "    date_list = cluster_hourly_df['Date'].unique()\n",
    "    \n",
    "    #create a temp dataframe for each data, and calculate trasition matrices from hour t to t+1\n",
    "    for p in range(0, cluster_hourly_df['Date'].nunique()):\n",
    "\n",
    "        #create a temp dataframe for pervious date\n",
    "        temp_df = pd.DataFrame()\n",
    "        matrices_df = pd.DataFrame()\n",
    "        temp_df = cluster_hourly_df.loc[cluster_hourly_df['Date'] == date_list[p]]\n",
    "        temp_df = temp_df.reset_index(drop=True)\n",
    "\n",
    "        for i in range(0, 24):\n",
    "            matrices_df['Date'] = 0\n",
    "            matrices_df['StateId'] = 0\n",
    "            for j in range(0, len(temp_df)):\n",
    "                colname = '(' + str(i) + '-' + str(i+1) + ')-' + str(temp_df['StateId'][j])\n",
    "                matrices_df[colname] = 0\n",
    "\n",
    "        matrices_df['Date'] = temp_df['Date']\n",
    "        matrices_df['StateId'] = temp_df['StateId']\n",
    "\n",
    "        for i in range (0, 23):\n",
    "            for j in range (0, len(temp_df)):\n",
    "                for k in range (0, len(temp_df)):\n",
    "                    prob = temp_df[i][j] * temp_df[i+1][k]\n",
    "                    colname = '(' + str(i) + '-' + str(i+1) + ')-' + str(temp_df['StateId'][k])\n",
    "                    matrices_df[colname][j] = prob\n",
    "        file_name = dest_path_each_day_trsn_mat + str(date_list[p]) + \".csv\"\n",
    "        matrices_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "def create_save_markov_chains():\n",
    "    global final_transition_df\n",
    "    global co_loc\n",
    "    \n",
    "    final_transition_df = pd.DataFrame()\n",
    "    \n",
    "    #create an empty markov chain frame for each state, and transition for each hour of the day\n",
    "    date_list = cluster_hourly_df['Date'].unique()\n",
    "    cluster_list = cluster_hourly_df['StateId'].unique()\n",
    "    AvgLat_list = cluster_hourly_df['AvgLat'].unique()\n",
    "    AvgLon_list = cluster_hourly_df['AvgLon'].unique()\n",
    "    \n",
    "    for i in range(0, 24):\n",
    "        final_transition_df['Address'] = 0\n",
    "        final_transition_df['AvgLat'] = 0\n",
    "        final_transition_df['AvgLon'] = 0\n",
    "        final_transition_df['StateId'] = 0\n",
    "        for j in range(0, cluster_hourly_df['StateId'].nunique()):\n",
    "            colname = '(' + str(i) + '-' + str(i+1) + ')-' + str(cluster_list[j])\n",
    "            final_transition_df[colname] = 0\n",
    "          \n",
    "    final_transition_df['StateId'] = cluster_list\n",
    "    final_transition_df['AvgLat'] = AvgLat_list\n",
    "    final_transition_df['AvgLon'] = AvgLon_list\n",
    "    final_transition_df = final_transition_df.fillna(0)\n",
    "    final_transition_df.index = final_transition_df.StateId\n",
    "\n",
    "    #read each day file and sum the matching rows:cols combinations\n",
    "    date_list = cluster_hourly_df['Date'].unique()\n",
    "    path_dir = dest_path_each_day_trsn_mat\n",
    "\n",
    "    \n",
    "    for p in range(0, cluster_hourly_df['Date'].nunique()):\n",
    "        temp_df = pd.DataFrame()\n",
    "        filename = path_dir + str(date_list[p]) + '.csv'\n",
    "        temp_df =  pd.read_csv(filename, header = 0, sep='\\t')\n",
    "\n",
    "        for i in range(0, len(temp_df)):\n",
    "            rowname = temp_df['StateId'][i]\n",
    "            for src_column in temp_df:\n",
    "                for dest_column in final_transition_df:\n",
    "                    if src_column == dest_column and src_column != 'StateId' :\n",
    "                        #import pdb; pdb.set_trace()\n",
    "                        final_transition_df[dest_column][rowname] = (final_transition_df[dest_column][rowname] +\n",
    "                                                                    temp_df[src_column][i])\n",
    "\n",
    "    #calculate probability from cluster x to cluster y from time t to t+1\n",
    "    final_transition_df = final_transition_df.reset_index(drop=True)\n",
    "    for clus in range(0, len(final_transition_df)):\n",
    "        for i in range(0, 24):\n",
    "            temp_sum = 0\n",
    "            for j in range(0, len(final_transition_df)):\n",
    "                colname = '(' + str(i) + '-' + str(i+1) + ')-' + str(final_transition_df['StateId'][j])\n",
    "                temp_sum += (final_transition_df[colname][clus])\n",
    "            for k in range(0, len(final_transition_df)):\n",
    "                colname = '(' + str(i) + '-' + str(i+1) + ')-' + str(final_transition_df['StateId'][k])\n",
    "                if temp_sum != 0:\n",
    "                    final_transition_df[colname][clus] = final_transition_df[colname][clus]/temp_sum\n",
    "    \n",
    "    #create dictionary for coordinate : address\n",
    "    points = tuple(zip(final_transition_df.AvgLat, final_transition_df.AvgLon))\n",
    "    geocoder = Nominatim(timeout=10)\n",
    "    coordinate_location = {}\n",
    "    \n",
    "    for coordinate in points:\n",
    "        try:\n",
    "            location = geocoder.reverse(coordinate)\n",
    "        except:\n",
    "            location = 'unknown'\n",
    "        coordinate_location[coordinate] = location\n",
    "    \n",
    "    co_loc = {k:v for k,v in coordinate_location.items()}\n",
    "\n",
    "    for i in range(0, len(final_transition_df)):\n",
    "        address = co_loc.get((final_transition_df['AvgLat'][i], final_transition_df['AvgLon'][i]))\n",
    "        if address == 'unknown':\n",
    "            final_transition_df['Address'][i] = 'unknown'\n",
    "        else:\n",
    "            final_transition_df['Address'][i] = address[0]\n",
    "    \n",
    "    #replace zero probabilities to a small value and save the file\n",
    "    final_transition_df = final_transition_df.fillna(0)                    \n",
    "    final_transition_df = final_transition_df.replace(0, 0.00001)\n",
    "    final_transition_df.to_csv(dest_file_final_markov_chain, sep='\\t')\n",
    "    \n",
    "    for i in range(0, 24):\n",
    "        final_transition_temp_df = pd.DataFrame()\n",
    "        k = cluster_hourly_df['StateId'].nunique()*i + 4\n",
    "        final_transition_temp_df = final_transition_df.iloc[:,k:k + cluster_hourly_df['StateId'].nunique()]\n",
    "        final_transition_temp_df.index = cluster_list\n",
    "        file_name = usr_markov_chains_directory + \"/\" + str(i) + \" hour.csv\"\n",
    "        final_transition_temp_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "        \n",
    "        \n",
    "#------------------------------------------------------------------------------------\n",
    "def predict(new_hour):\n",
    "    global trained_model_df\n",
    "    global curr_hr_staypts_df\n",
    "    \n",
    "    tobepredicted_df = curr_hr_staypts_df[['StateId', 'StateMeanLat', 'StateMeanLon', 'Timestamp']]\n",
    "    tobepredicted_df = tobepredicted_df.drop_duplicates()\n",
    "    tobepredicted_df = tobepredicted_df.reset_index(drop=True)\n",
    "\n",
    "    for j in range(0, len(tobepredicted_df)):\n",
    "        new_lat = tobepredicted_df['StateMeanLat'][j]\n",
    "        new_lon = tobepredicted_df['StateMeanLon'][j]\n",
    "        file_name = \"Predicted Timestamp - \" +  str(tobepredicted_df['Timestamp'][j]) + \".csv\"\n",
    "        for i in range(0, len(trained_model_df)):\n",
    "\n",
    "            trn_lat = trained_model_df['AvgLat'][i]\n",
    "            trn_lon = trained_model_df['AvgLon'][i]\n",
    "            if meters(trn_lat, trn_lon, new_lat, new_lon) <= 10000:\n",
    "\n",
    "                predic_df = pd.DataFrame()\n",
    "\n",
    "                cluster_id = trained_model_df['StateId'][i]\n",
    "                curr_lat = trained_model_df['AvgLat'][i]\n",
    "                curr_lon = trained_model_df['AvgLon'][i]\n",
    "                curr_add = trained_model_df['Address'][i]\n",
    "                pred_loc = {\"current\":(cluster_id, curr_lat, curr_lon, curr_add)}\n",
    "\n",
    "                from_col_no = trained_model_df['StateId'].nunique() * new_hour + 5\n",
    "                to_col_no = from_col_no + trained_model_df['StateId'].nunique()\n",
    "                predic_df = trained_model_df.iloc[i:i+1,from_col_no:to_col_no]\n",
    "                predic_df = predic_df.T\n",
    "                predic_df['StateId'] = cluster_id\n",
    "                predic_df['SelectedState'] = predic_df.index\n",
    "                predic_df['SelectedState'] = predic_df['SelectedState'].map(lambda x: x.split('-', 2)[-1])\n",
    "                predic_df.columns = ['Probability', 'StateId', 'SelectedState']\n",
    "                predic_df = predic_df.sort_values('Probability', ascending=False).head(10)\n",
    "                predic_df['Address'] = 0\n",
    "                predic_df['Latitude'] = 0.0\n",
    "                predic_df['Longitude'] = 0.0\n",
    "                predic_df = predic_df.reset_index(drop=True)\n",
    "\n",
    "                for j in range (0, len(predic_df)):\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    clus_to_find = int(float(predic_df['SelectedState'][j]))\n",
    "                    add = trained_model_df.loc[ (trained_model_df['StateId'] == clus_to_find), 'Address'].values[0]\n",
    "                    lat = trained_model_df.loc[ (trained_model_df['StateId'] == clus_to_find), 'AvgLat'].values[0]\n",
    "                    lon = trained_model_df.loc[ (trained_model_df['StateId'] == clus_to_find), 'AvgLon'].values[0]\n",
    "\n",
    "                    predic_df.loc[j, 'Address'] = add\n",
    "                    predic_df.loc[j, 'Latitude'] = lat\n",
    "                    predic_df.loc[j, 'Longitude'] = lon\n",
    "                file = dest_predicted_dir + file_name\n",
    "                predic_df.to_csv(file, sep='\\t', encoding='utf-8')\n",
    "                break\n",
    "            \n",
    "#------------------------------------------ S T A R T -----------------------------------------------\n",
    "#global dataframes used\n",
    "#user raw trajectory dataframe\n",
    "usr_trejec_df = pd.DataFrame()\n",
    "#user trained model\n",
    "trained_model_df = pd.DataFrame()\n",
    "#current hour points\n",
    "curr_hr_df = pd.DataFrame()\n",
    "#current hour staypoints\n",
    "curr_hr_staypts_df = pd.DataFrame()\n",
    "#all staypoints\n",
    "staypts_df = pd.DataFrame()\n",
    "#hourly cluster\n",
    "cluster_hourly_df = pd.DataFrame()\n",
    "#final markov chains\n",
    "final_transition_df = pd.DataFrame()\n",
    "\n",
    "clus_dict = {}\n",
    "co_loc = {}\n",
    "pred_loc = {}\n",
    "lat_array = []\n",
    "lon_array = []\n",
    "global_count = 0\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------CHANGE HERE FOR USER AND DATE RANGE--------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Edit user name, and path locations for source and destination files\n",
    "user = \"041\"\n",
    "state_d_thrhld = 200\n",
    "staypts_d_thrhld = 200\n",
    "staypts_t_thrhld = 20\n",
    "\n",
    "#destination paths\n",
    "usr_directory = \"/home/shashank/Documents/location/code/several tests/test 6/results/User \" + user\n",
    "usr_hrly_wght_directory = \"/home/shashank/Documents/location/code/several tests/test 6/results/User \" + user + \"/hourlyweights\"\n",
    "usr_sty_pts_directory = \"/home/shashank/Documents/location/code/several tests/test 6/results/User \" + user + \"/staypoints\"\n",
    "usr_markov_chains_directory = \"/home/shashank/Documents/location/code/several tests/test 6/results/User \" + user + \"/markovchains\"\n",
    "dest_predicted_dir = \"/home/shashank/Documents/location/code/several tests/test 6/results/User \" + user + \"/predict/\"\n",
    "\n",
    "if not os.path.exists(usr_directory):\n",
    "    os.makedirs(usr_directory)\n",
    "if not os.path.exists(usr_hrly_wght_directory):\n",
    "    os.makedirs(usr_hrly_wght_directory)\n",
    "if not os.path.exists(usr_sty_pts_directory):\n",
    "    os.makedirs(usr_sty_pts_directory)  \n",
    "if not os.path.exists(usr_markov_chains_directory):\n",
    "    os.makedirs(usr_markov_chains_directory)  \n",
    "if not os.path.exists(dest_predicted_dir):\n",
    "    os.makedirs(dest_predicted_dir)  \n",
    "\n",
    "#destination file names\n",
    "dest_file_staypoints = usr_sty_pts_directory + \"/staypoints.csv\"\n",
    "dest_file_hourly_weights = usr_hrly_wght_directory + \"/hourlyweights.csv\"\n",
    "dest_path_each_day_trsn_mat = usr_hrly_wght_directory + \"/\"\n",
    "dest_file_final_markov_chain = usr_markov_chains_directory + \"/final.csv\"\n",
    "\n",
    "#remove if the file already exists\n",
    "try:\n",
    "    os.remove(dest_file_staypoints)\n",
    "    os.remove(dest_file_hourly_weights)\n",
    "    os.remove(dest_file_final_markov_chain)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "#source paths\n",
    "file_source_raw = \"/home/shashank/Documents/location/Geolife Trajectories 1.3/Data/\" + user + \"/Trajectory/200906*.plt\" \n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------CHANGE HERE FOR USER AND DATE RANGE--------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#read test user trajectory file. In real scenerio, this will be the GPS read data\n",
    "read_usr_file()\n",
    "\n",
    "#prepere dataframes\n",
    "prepare_dfs()\n",
    "\n",
    "#Save first date and time as prev date and time for the start\n",
    "prev_date = usr_trejec_df['Date'][0]\n",
    "prev_hour = usr_trejec_df['Hour'][0]\n",
    "\n",
    "#I. Read the new locations in an online gps location input mode\n",
    "#  1. Everytime the hour changes, \n",
    "#                  A. Find staypoints for the last hour and assign staypointID\n",
    "#                  B. Cluster staypoints based on distance for last hour, form states and assign stateID\n",
    "#                  C. Calculate state hourly weights for last hour\n",
    "#                  D. Predict based on trained data(if available)\n",
    "#  2. Everytime the date changes,\n",
    "#                  A. Add the days data into the training data\n",
    "#  3. If the hour and the time has not been changed, add the data to current hour data\n",
    "\n",
    "#I\n",
    "for i in range(0, len(usr_trejec_df)):\n",
    "    \n",
    "    #store the read hour and date as new hour and new date\n",
    "    new_hour = usr_trejec_df['Hour'][i]\n",
    "    new_date = usr_trejec_df['Date'][i]\n",
    "    \n",
    "    #1. \n",
    "    #if the hour has changed\n",
    "    if (new_hour != prev_hour): \n",
    "    \n",
    "        #process the last hour data if available\n",
    "        if not curr_hr_df.empty:\n",
    "            #A.\n",
    "            create_last_hr_staypts() \n",
    "            #B.\n",
    "            form_states()\n",
    "\n",
    "            if not curr_hr_staypts_df.empty:\n",
    "                #C.\n",
    "                cal_hourly_state_weight()\n",
    "                #D.\n",
    "#                 read_trained_model()\n",
    "#                 if not trained_model_df.empty:\n",
    "#                     predict(new_hour)\n",
    "                    \n",
    "        prev_hour = new_hour \n",
    "        \n",
    "    #2. \n",
    "    #if the date has changed\n",
    "    if (new_date != prev_date):\n",
    "        \n",
    "        if not staypts_df.empty:\n",
    "            visualize_hourly_state_weight()\n",
    "            update_staypts_csv()\n",
    "            update_hourly_weights_csv()\n",
    "            #A.\n",
    "            create_save_seperate_trasition_matrices()\n",
    "            create_save_markov_chains()\n",
    "            \n",
    "        prev_date = new_date\n",
    "    \n",
    "    #3. \n",
    "    #if the date and the hour has not changed, just add it to current hour dataframe.\n",
    "    # this dataframe is used once the hour is changed.\n",
    "    else:\n",
    "        curr_hr_df = curr_hr_df.append(usr_trejec_df.iloc[[i]])   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>0</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>NumDays</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Distance(Km)</th>\n",
       "      <th>Time(Hr)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.859498</td>\n",
       "      <td>116.257463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.400000</td>\n",
       "      <td>39965.241794</td>\n",
       "      <td>2009-06-01 05:48:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>05:48:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.859500</td>\n",
       "      <td>116.257462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.400000</td>\n",
       "      <td>39965.242674</td>\n",
       "      <td>2009-06-01 05:49:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>05:49:00</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.859549</td>\n",
       "      <td>116.257675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.600000</td>\n",
       "      <td>39965.246981</td>\n",
       "      <td>2009-06-01 05:55:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>05:55:00</td>\n",
       "      <td>0.019017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.860606</td>\n",
       "      <td>116.258776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.600000</td>\n",
       "      <td>39965.247631</td>\n",
       "      <td>2009-06-01 05:56:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>05:56:00</td>\n",
       "      <td>0.150610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.863663</td>\n",
       "      <td>116.260494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.528205</td>\n",
       "      <td>39965.248296</td>\n",
       "      <td>2009-06-01 05:57:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>05:57:00</td>\n",
       "      <td>0.370699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.863997</td>\n",
       "      <td>116.267371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.611667</td>\n",
       "      <td>39965.248953</td>\n",
       "      <td>2009-06-01 05:58:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>05:58:00</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39.864191</td>\n",
       "      <td>116.278868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.173333</td>\n",
       "      <td>39965.249647</td>\n",
       "      <td>2009-06-01 05:59:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>05:59:00</td>\n",
       "      <td>0.982648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39.865044</td>\n",
       "      <td>116.291259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.870000</td>\n",
       "      <td>39965.250341</td>\n",
       "      <td>2009-06-01 06:00:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>1.062980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.865827</td>\n",
       "      <td>116.303533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.865000</td>\n",
       "      <td>39965.251036</td>\n",
       "      <td>2009-06-01 06:01:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:01:00</td>\n",
       "      <td>1.052365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39.866408</td>\n",
       "      <td>116.312419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.750000</td>\n",
       "      <td>39965.251547</td>\n",
       "      <td>2009-06-01 06:02:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:02:00</td>\n",
       "      <td>0.761974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39.866676</td>\n",
       "      <td>116.318361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.897674</td>\n",
       "      <td>39965.252523</td>\n",
       "      <td>2009-06-01 06:03:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:03:00</td>\n",
       "      <td>0.508565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39.866686</td>\n",
       "      <td>116.323572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.984211</td>\n",
       "      <td>39965.252886</td>\n",
       "      <td>2009-06-01 06:04:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:04:00</td>\n",
       "      <td>0.445229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39.866693</td>\n",
       "      <td>116.326697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.880000</td>\n",
       "      <td>39965.253772</td>\n",
       "      <td>2009-06-01 06:05:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:05:00</td>\n",
       "      <td>0.267033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39.866705</td>\n",
       "      <td>116.330126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.634783</td>\n",
       "      <td>39965.254702</td>\n",
       "      <td>2009-06-01 06:06:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:06:00</td>\n",
       "      <td>0.292947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39.866730</td>\n",
       "      <td>116.337670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.426667</td>\n",
       "      <td>39965.255203</td>\n",
       "      <td>2009-06-01 06:07:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:07:00</td>\n",
       "      <td>0.644592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>39.866880</td>\n",
       "      <td>116.349362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.626667</td>\n",
       "      <td>39965.255897</td>\n",
       "      <td>2009-06-01 06:08:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:08:00</td>\n",
       "      <td>0.999120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>39.868127</td>\n",
       "      <td>116.360584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.338333</td>\n",
       "      <td>39965.256591</td>\n",
       "      <td>2009-06-01 06:09:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:09:00</td>\n",
       "      <td>0.968848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>39.868998</td>\n",
       "      <td>116.370495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.291667</td>\n",
       "      <td>39965.257286</td>\n",
       "      <td>2009-06-01 06:10:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:10:00</td>\n",
       "      <td>0.852308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39.869613</td>\n",
       "      <td>116.380020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.481667</td>\n",
       "      <td>39965.257980</td>\n",
       "      <td>2009-06-01 06:11:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:11:00</td>\n",
       "      <td>0.816640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39.870130</td>\n",
       "      <td>116.389544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.758333</td>\n",
       "      <td>39965.258675</td>\n",
       "      <td>2009-06-01 06:12:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:12:00</td>\n",
       "      <td>0.815783</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>39.870569</td>\n",
       "      <td>116.399904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.691667</td>\n",
       "      <td>39965.259369</td>\n",
       "      <td>2009-06-01 06:13:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:13:00</td>\n",
       "      <td>0.886481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>39.870426</td>\n",
       "      <td>116.408229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.450000</td>\n",
       "      <td>39965.260064</td>\n",
       "      <td>2009-06-01 06:14:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:14:00</td>\n",
       "      <td>0.711414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>39.869823</td>\n",
       "      <td>116.416563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.290000</td>\n",
       "      <td>39965.260758</td>\n",
       "      <td>2009-06-01 06:15:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>0.715225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>39.869612</td>\n",
       "      <td>116.426208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.756667</td>\n",
       "      <td>39965.261453</td>\n",
       "      <td>2009-06-01 06:16:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:16:00</td>\n",
       "      <td>0.824373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>39.869503</td>\n",
       "      <td>116.434904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.196078</td>\n",
       "      <td>39965.262105</td>\n",
       "      <td>2009-06-01 06:17:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:17:00</td>\n",
       "      <td>0.743074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>39.870443</td>\n",
       "      <td>116.441120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.910870</td>\n",
       "      <td>39965.262811</td>\n",
       "      <td>2009-06-01 06:18:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:18:00</td>\n",
       "      <td>0.541299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>39.870238</td>\n",
       "      <td>116.446251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.970000</td>\n",
       "      <td>39965.263704</td>\n",
       "      <td>2009-06-01 06:19:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:19:00</td>\n",
       "      <td>0.438966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39.870302</td>\n",
       "      <td>116.450400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.834375</td>\n",
       "      <td>39965.264333</td>\n",
       "      <td>2009-06-01 06:20:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:20:00</td>\n",
       "      <td>0.354535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>39.870282</td>\n",
       "      <td>116.453338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.542857</td>\n",
       "      <td>39965.264851</td>\n",
       "      <td>2009-06-01 06:21:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:21:00</td>\n",
       "      <td>0.251015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>39.869679</td>\n",
       "      <td>116.454047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>39965.266790</td>\n",
       "      <td>2009-06-01 06:24:00</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>06:24:00</td>\n",
       "      <td>0.090455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8201</th>\n",
       "      <td>39.905546</td>\n",
       "      <td>116.265762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.643750</td>\n",
       "      <td>39994.480195</td>\n",
       "      <td>2009-06-30 11:31:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>11:31:00</td>\n",
       "      <td>0.125498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>39.906509</td>\n",
       "      <td>116.266540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.500000</td>\n",
       "      <td>39994.480880</td>\n",
       "      <td>2009-06-30 11:32:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>11:32:00</td>\n",
       "      <td>0.126083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>39.907590</td>\n",
       "      <td>116.266779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.850000</td>\n",
       "      <td>39994.481545</td>\n",
       "      <td>2009-06-30 11:33:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>11:33:00</td>\n",
       "      <td>0.122147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8204</th>\n",
       "      <td>39.902687</td>\n",
       "      <td>116.258666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>259.818750</td>\n",
       "      <td>39994.935888</td>\n",
       "      <td>2009-06-30 22:27:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:27:00</td>\n",
       "      <td>0.882037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8205</th>\n",
       "      <td>39.901172</td>\n",
       "      <td>116.258624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.443750</td>\n",
       "      <td>39994.936445</td>\n",
       "      <td>2009-06-30 22:28:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:28:00</td>\n",
       "      <td>0.168700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8206</th>\n",
       "      <td>39.899707</td>\n",
       "      <td>116.258541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.416667</td>\n",
       "      <td>39994.937024</td>\n",
       "      <td>2009-06-30 22:29:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:29:00</td>\n",
       "      <td>0.163233</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>39.898195</td>\n",
       "      <td>116.258504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.005556</td>\n",
       "      <td>39994.937874</td>\n",
       "      <td>2009-06-30 22:30:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>0.168351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8208</th>\n",
       "      <td>39.896513</td>\n",
       "      <td>116.258458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.988235</td>\n",
       "      <td>39994.938521</td>\n",
       "      <td>2009-06-30 22:31:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:31:00</td>\n",
       "      <td>0.187245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8209</th>\n",
       "      <td>39.894872</td>\n",
       "      <td>116.258468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171.764706</td>\n",
       "      <td>39994.939236</td>\n",
       "      <td>2009-06-30 22:32:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:32:00</td>\n",
       "      <td>0.182664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8210</th>\n",
       "      <td>39.893065</td>\n",
       "      <td>116.258386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.042105</td>\n",
       "      <td>39994.939915</td>\n",
       "      <td>2009-06-30 22:33:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:33:00</td>\n",
       "      <td>0.201276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>39.891142</td>\n",
       "      <td>116.258392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.952632</td>\n",
       "      <td>39994.940631</td>\n",
       "      <td>2009-06-30 22:34:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:34:00</td>\n",
       "      <td>0.214044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8212</th>\n",
       "      <td>39.889316</td>\n",
       "      <td>116.258387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.052632</td>\n",
       "      <td>39994.941310</td>\n",
       "      <td>2009-06-30 22:35:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:35:00</td>\n",
       "      <td>0.203297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8213</th>\n",
       "      <td>39.887526</td>\n",
       "      <td>116.258378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.766667</td>\n",
       "      <td>39994.942030</td>\n",
       "      <td>2009-06-30 22:36:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:36:00</td>\n",
       "      <td>0.199246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8214</th>\n",
       "      <td>39.885720</td>\n",
       "      <td>116.258356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.252632</td>\n",
       "      <td>39994.942707</td>\n",
       "      <td>2009-06-30 22:37:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:37:00</td>\n",
       "      <td>0.201074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8215</th>\n",
       "      <td>39.883841</td>\n",
       "      <td>116.258325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.810000</td>\n",
       "      <td>39994.943397</td>\n",
       "      <td>2009-06-30 22:38:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:38:00</td>\n",
       "      <td>0.209213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8216</th>\n",
       "      <td>39.881889</td>\n",
       "      <td>116.258311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.542105</td>\n",
       "      <td>39994.944076</td>\n",
       "      <td>2009-06-30 22:39:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:39:00</td>\n",
       "      <td>0.217287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8217</th>\n",
       "      <td>39.880023</td>\n",
       "      <td>116.258325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.511765</td>\n",
       "      <td>39994.944769</td>\n",
       "      <td>2009-06-30 22:40:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:40:00</td>\n",
       "      <td>0.207685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8218</th>\n",
       "      <td>39.878277</td>\n",
       "      <td>116.258319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.288889</td>\n",
       "      <td>39994.945466</td>\n",
       "      <td>2009-06-30 22:41:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:41:00</td>\n",
       "      <td>0.194377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8219</th>\n",
       "      <td>39.876318</td>\n",
       "      <td>116.258309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>39994.946186</td>\n",
       "      <td>2009-06-30 22:42:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:42:00</td>\n",
       "      <td>0.218071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8220</th>\n",
       "      <td>39.874190</td>\n",
       "      <td>116.258291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.135000</td>\n",
       "      <td>39994.946881</td>\n",
       "      <td>2009-06-30 22:43:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:43:00</td>\n",
       "      <td>0.236874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8221</th>\n",
       "      <td>39.872254</td>\n",
       "      <td>116.258280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.200000</td>\n",
       "      <td>39994.947575</td>\n",
       "      <td>2009-06-30 22:44:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:44:00</td>\n",
       "      <td>0.215599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>39.871066</td>\n",
       "      <td>116.258284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.180000</td>\n",
       "      <td>39994.948292</td>\n",
       "      <td>2009-06-30 22:45:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:45:00</td>\n",
       "      <td>0.132204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8223</th>\n",
       "      <td>39.869934</td>\n",
       "      <td>116.258332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.758824</td>\n",
       "      <td>39994.948945</td>\n",
       "      <td>2009-06-30 22:46:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:46:00</td>\n",
       "      <td>0.126108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8224</th>\n",
       "      <td>39.868260</td>\n",
       "      <td>116.258400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.853333</td>\n",
       "      <td>39994.949664</td>\n",
       "      <td>2009-06-30 22:47:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:47:00</td>\n",
       "      <td>0.186384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8225</th>\n",
       "      <td>39.866434</td>\n",
       "      <td>116.258375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171.905000</td>\n",
       "      <td>39994.950372</td>\n",
       "      <td>2009-06-30 22:48:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:48:00</td>\n",
       "      <td>0.203288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8226</th>\n",
       "      <td>39.864250</td>\n",
       "      <td>116.258381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.215000</td>\n",
       "      <td>39994.951024</td>\n",
       "      <td>2009-06-30 22:49:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:49:00</td>\n",
       "      <td>0.243104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8227</th>\n",
       "      <td>39.862214</td>\n",
       "      <td>116.258479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.284211</td>\n",
       "      <td>39994.951733</td>\n",
       "      <td>2009-06-30 22:50:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:50:00</td>\n",
       "      <td>0.226814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8228</th>\n",
       "      <td>39.860347</td>\n",
       "      <td>116.258856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.033333</td>\n",
       "      <td>39994.952413</td>\n",
       "      <td>2009-06-30 22:51:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:51:00</td>\n",
       "      <td>0.210299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229</th>\n",
       "      <td>39.859507</td>\n",
       "      <td>116.258085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.931250</td>\n",
       "      <td>39994.953054</td>\n",
       "      <td>2009-06-30 22:52:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:52:00</td>\n",
       "      <td>0.114415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8230</th>\n",
       "      <td>39.859697</td>\n",
       "      <td>116.257592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.300000</td>\n",
       "      <td>39994.954045</td>\n",
       "      <td>2009-06-30 22:53:00</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>22:53:00</td>\n",
       "      <td>0.047183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8231 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Latitude   Longitude    0    Altitude       NumDays  \\\n",
       "0     39.859498  116.257463  0.0  180.400000  39965.241794   \n",
       "1     39.859500  116.257462  0.0  180.400000  39965.242674   \n",
       "2     39.859549  116.257675  0.0  193.600000  39965.246981   \n",
       "3     39.860606  116.258776  0.0  193.600000  39965.247631   \n",
       "4     39.863663  116.260494  0.0  194.528205  39965.248296   \n",
       "5     39.863997  116.267371  0.0  184.611667  39965.248953   \n",
       "6     39.864191  116.278868  0.0  142.173333  39965.249647   \n",
       "7     39.865044  116.291259  0.0  146.870000  39965.250341   \n",
       "8     39.865827  116.303533  0.0  132.865000  39965.251036   \n",
       "9     39.866408  116.312419  0.0  151.750000  39965.251547   \n",
       "10    39.866676  116.318361  0.0  151.897674  39965.252523   \n",
       "11    39.866686  116.323572  0.0  147.984211  39965.252886   \n",
       "12    39.866693  116.326697  0.0  134.880000  39965.253772   \n",
       "13    39.866705  116.330126  0.0  132.634783  39965.254702   \n",
       "14    39.866730  116.337670  0.0  133.426667  39965.255203   \n",
       "15    39.866880  116.349362  0.0  117.626667  39965.255897   \n",
       "16    39.868127  116.360584  0.0   83.338333  39965.256591   \n",
       "17    39.868998  116.370495  0.0  152.291667  39965.257286   \n",
       "18    39.869613  116.380020  0.0  132.481667  39965.257980   \n",
       "19    39.870130  116.389544  0.0  106.758333  39965.258675   \n",
       "20    39.870569  116.399904  0.0  120.691667  39965.259369   \n",
       "21    39.870426  116.408229  0.0  124.450000  39965.260064   \n",
       "22    39.869823  116.416563  0.0  120.290000  39965.260758   \n",
       "23    39.869612  116.426208  0.0  164.756667  39965.261453   \n",
       "24    39.869503  116.434904  0.0  156.196078  39965.262105   \n",
       "25    39.870443  116.441120  0.0  154.910870  39965.262811   \n",
       "26    39.870238  116.446251  0.0  189.970000  39965.263704   \n",
       "27    39.870302  116.450400  0.0  184.834375  39965.264333   \n",
       "28    39.870282  116.453338  0.0  194.542857  39965.264851   \n",
       "29    39.869679  116.454047  0.0  187.000000  39965.266790   \n",
       "...         ...         ...  ...         ...           ...   \n",
       "8201  39.905546  116.265762  0.0  237.643750  39994.480195   \n",
       "8202  39.906509  116.266540  0.0  254.500000  39994.480880   \n",
       "8203  39.907590  116.266779  0.0  260.850000  39994.481545   \n",
       "8204  39.902687  116.258666  0.0  259.818750  39994.935888   \n",
       "8205  39.901172  116.258624  0.0  237.443750  39994.936445   \n",
       "8206  39.899707  116.258541  0.0  203.416667  39994.937024   \n",
       "8207  39.898195  116.258504  0.0  187.005556  39994.937874   \n",
       "8208  39.896513  116.258458  0.0  170.988235  39994.938521   \n",
       "8209  39.894872  116.258468  0.0  171.764706  39994.939236   \n",
       "8210  39.893065  116.258386  0.0  165.042105  39994.939915   \n",
       "8211  39.891142  116.258392  0.0  166.952632  39994.940631   \n",
       "8212  39.889316  116.258387  0.0  165.052632  39994.941310   \n",
       "8213  39.887526  116.258378  0.0  164.766667  39994.942030   \n",
       "8214  39.885720  116.258356  0.0  160.252632  39994.942707   \n",
       "8215  39.883841  116.258325  0.0  159.810000  39994.943397   \n",
       "8216  39.881889  116.258311  0.0  158.542105  39994.944076   \n",
       "8217  39.880023  116.258325  0.0  173.511765  39994.944769   \n",
       "8218  39.878277  116.258319  0.0  165.288889  39994.945466   \n",
       "8219  39.876318  116.258309  0.0  164.000000  39994.946186   \n",
       "8220  39.874190  116.258291  0.0  159.135000  39994.946881   \n",
       "8221  39.872254  116.258280  0.0  154.200000  39994.947575   \n",
       "8222  39.871066  116.258284  0.0  156.180000  39994.948292   \n",
       "8223  39.869934  116.258332  0.0  160.758824  39994.948945   \n",
       "8224  39.868260  116.258400  0.0  175.853333  39994.949664   \n",
       "8225  39.866434  116.258375  0.0  171.905000  39994.950372   \n",
       "8226  39.864250  116.258381  0.0  163.215000  39994.951024   \n",
       "8227  39.862214  116.258479  0.0  161.284211  39994.951733   \n",
       "8228  39.860347  116.258856  0.0  162.033333  39994.952413   \n",
       "8229  39.859507  116.258085  0.0  158.931250  39994.953054   \n",
       "8230  39.859697  116.257592  0.0  167.300000  39994.954045   \n",
       "\n",
       "               Timestamp        Date      Time  Distance(Km)  Time(Hr)  \n",
       "0    2009-06-01 05:48:00  2009-06-01  05:48:00      0.000000         0  \n",
       "1    2009-06-01 05:49:00  2009-06-01  05:49:00      0.000234         0  \n",
       "2    2009-06-01 05:55:00  2009-06-01  05:55:00      0.019017         0  \n",
       "3    2009-06-01 05:56:00  2009-06-01  05:56:00      0.150610         0  \n",
       "4    2009-06-01 05:57:00  2009-06-01  05:57:00      0.370699         0  \n",
       "5    2009-06-01 05:58:00  2009-06-01  05:58:00      0.588752         0  \n",
       "6    2009-06-01 05:59:00  2009-06-01  05:59:00      0.982648         0  \n",
       "7    2009-06-01 06:00:00  2009-06-01  06:00:00      1.062980         0  \n",
       "8    2009-06-01 06:01:00  2009-06-01  06:01:00      1.052365         0  \n",
       "9    2009-06-01 06:02:00  2009-06-01  06:02:00      0.761974         0  \n",
       "10   2009-06-01 06:03:00  2009-06-01  06:03:00      0.508565         0  \n",
       "11   2009-06-01 06:04:00  2009-06-01  06:04:00      0.445229         0  \n",
       "12   2009-06-01 06:05:00  2009-06-01  06:05:00      0.267033         0  \n",
       "13   2009-06-01 06:06:00  2009-06-01  06:06:00      0.292947         0  \n",
       "14   2009-06-01 06:07:00  2009-06-01  06:07:00      0.644592         0  \n",
       "15   2009-06-01 06:08:00  2009-06-01  06:08:00      0.999120         0  \n",
       "16   2009-06-01 06:09:00  2009-06-01  06:09:00      0.968848         0  \n",
       "17   2009-06-01 06:10:00  2009-06-01  06:10:00      0.852308         0  \n",
       "18   2009-06-01 06:11:00  2009-06-01  06:11:00      0.816640         0  \n",
       "19   2009-06-01 06:12:00  2009-06-01  06:12:00      0.815783         0  \n",
       "20   2009-06-01 06:13:00  2009-06-01  06:13:00      0.886481         0  \n",
       "21   2009-06-01 06:14:00  2009-06-01  06:14:00      0.711414         0  \n",
       "22   2009-06-01 06:15:00  2009-06-01  06:15:00      0.715225         0  \n",
       "23   2009-06-01 06:16:00  2009-06-01  06:16:00      0.824373         0  \n",
       "24   2009-06-01 06:17:00  2009-06-01  06:17:00      0.743074         0  \n",
       "25   2009-06-01 06:18:00  2009-06-01  06:18:00      0.541299         0  \n",
       "26   2009-06-01 06:19:00  2009-06-01  06:19:00      0.438966         0  \n",
       "27   2009-06-01 06:20:00  2009-06-01  06:20:00      0.354535         0  \n",
       "28   2009-06-01 06:21:00  2009-06-01  06:21:00      0.251015         0  \n",
       "29   2009-06-01 06:24:00  2009-06-01  06:24:00      0.090455         0  \n",
       "...                  ...         ...       ...           ...       ...  \n",
       "8201 2009-06-30 11:31:00  2009-06-30  11:31:00      0.125498         0  \n",
       "8202 2009-06-30 11:32:00  2009-06-30  11:32:00      0.126083         0  \n",
       "8203 2009-06-30 11:33:00  2009-06-30  11:33:00      0.122147         0  \n",
       "8204 2009-06-30 22:27:00  2009-06-30  22:27:00      0.882037         0  \n",
       "8205 2009-06-30 22:28:00  2009-06-30  22:28:00      0.168700         0  \n",
       "8206 2009-06-30 22:29:00  2009-06-30  22:29:00      0.163233         0  \n",
       "8207 2009-06-30 22:30:00  2009-06-30  22:30:00      0.168351         0  \n",
       "8208 2009-06-30 22:31:00  2009-06-30  22:31:00      0.187245         0  \n",
       "8209 2009-06-30 22:32:00  2009-06-30  22:32:00      0.182664         0  \n",
       "8210 2009-06-30 22:33:00  2009-06-30  22:33:00      0.201276         0  \n",
       "8211 2009-06-30 22:34:00  2009-06-30  22:34:00      0.214044         0  \n",
       "8212 2009-06-30 22:35:00  2009-06-30  22:35:00      0.203297         0  \n",
       "8213 2009-06-30 22:36:00  2009-06-30  22:36:00      0.199246         0  \n",
       "8214 2009-06-30 22:37:00  2009-06-30  22:37:00      0.201074         0  \n",
       "8215 2009-06-30 22:38:00  2009-06-30  22:38:00      0.209213         0  \n",
       "8216 2009-06-30 22:39:00  2009-06-30  22:39:00      0.217287         0  \n",
       "8217 2009-06-30 22:40:00  2009-06-30  22:40:00      0.207685         0  \n",
       "8218 2009-06-30 22:41:00  2009-06-30  22:41:00      0.194377         0  \n",
       "8219 2009-06-30 22:42:00  2009-06-30  22:42:00      0.218071         0  \n",
       "8220 2009-06-30 22:43:00  2009-06-30  22:43:00      0.236874         0  \n",
       "8221 2009-06-30 22:44:00  2009-06-30  22:44:00      0.215599         0  \n",
       "8222 2009-06-30 22:45:00  2009-06-30  22:45:00      0.132204         0  \n",
       "8223 2009-06-30 22:46:00  2009-06-30  22:46:00      0.126108         0  \n",
       "8224 2009-06-30 22:47:00  2009-06-30  22:47:00      0.186384         0  \n",
       "8225 2009-06-30 22:48:00  2009-06-30  22:48:00      0.203288         0  \n",
       "8226 2009-06-30 22:49:00  2009-06-30  22:49:00      0.243104         0  \n",
       "8227 2009-06-30 22:50:00  2009-06-30  22:50:00      0.226814         0  \n",
       "8228 2009-06-30 22:51:00  2009-06-30  22:51:00      0.210299         0  \n",
       "8229 2009-06-30 22:52:00  2009-06-30  22:52:00      0.114415         0  \n",
       "8230 2009-06-30 22:53:00  2009-06-30  22:53:00      0.047183         0  \n",
       "\n",
       "[8231 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_trejec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
