{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "import math\n",
    "import os\n",
    "from matplotlib.pyplot import figure\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import ipywidgets as widgets\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from_user = 21\n",
    "to_user = 22\n",
    "src_path = \"C:/Users/12sha/Documents/thesislocation/Data/Final Example Results\"\n",
    "\n",
    "# fetch user vs train test months\n",
    "\n",
    "usern_mnth_df = pd.read_csv(\"C:/Users/12sha/Documents/thesislocation/Data/user_vs_traintestmonth.csv\", sep = \"\\t\")\n",
    "usern_mnth_df = usern_mnth_df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Similarity\n",
    "\n",
    "# Find distance between two lan:lon points in meters\n",
    "def meters(lat1, lon1, lat2, lon2):\n",
    "    R = 6378.137  # Radius of earth in KM\n",
    "    dLat = lat2 * math.pi / 180 - lat1 * math.pi / 180\n",
    "    dLon = lon2 * math.pi / 180 - lon1 * math.pi / 180\n",
    "    a = math.sin(dLat / 2) * math.sin(dLat / 2) + math.cos(lat1 * math.pi / 180) * math.cos(\n",
    "        lat2 * math.pi / 180) * math.sin(dLon / 2) * math.sin(dLon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = R * c\n",
    "    return d * 1000  # meters\n",
    "\n",
    "def dotproduct(v1, v2):\n",
    "    return sum((a*b) for a, b in zip(v1, v2))\n",
    "\n",
    "def length(v):\n",
    "    return math.sqrt(dotproduct(v, v))\n",
    "\n",
    "#def find_similarity(pred_prob, act_prob_all):\n",
    "#    return math.acos(dotproduct(pred_prob, act_prob_all) / (length(pred_prob) * length(act_prob_all)))\n",
    "\n",
    "def find_similarity(pred_prob, act_prob_all):\n",
    "    result = 1 - spatial.distance.cosine(pred_prob, act_prob_all)\n",
    "    return result\n",
    "\n",
    "# calculate prediction parameters\n",
    "def check_pred(hour, indx_row):\n",
    "    global predic_df\n",
    "    global hrywghts_df\n",
    "    global similarity_arr\n",
    "\n",
    "    pred_prob = predic_df['PredProbability'].values\n",
    "    act_prob_all = [0] * len(pred_prob)\n",
    "    curr_date = hrywghts_df.loc[indx_row, 'Date']\n",
    "    state_wght = hrywghts_df.loc[indx_row, str(hour)]\n",
    "\n",
    "    jmp_dat = False\n",
    "    if hour == 23:\n",
    "        jmp_dat = True\n",
    "\n",
    "    # check if there are points found in next hour\n",
    "    hrywghts_day_df = hrywghts_df.loc[hrywghts_df['Date'] == curr_date]\n",
    "    hrywghts_day_df = hrywghts_day_df.reset_index(drop=True)\n",
    "    for k in range(0, len(hrywghts_day_df)):\n",
    "        if jmp_dat == True:\n",
    "            if k + 1 < len(hrywghts_day_df):\n",
    "                next_hour = 0\n",
    "                row = k + 1\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            next_hour = hour + 1\n",
    "            row = k\n",
    "\n",
    "        if hrywghts_day_df.loc[row, str(next_hour)] != 0:\n",
    "\n",
    "            true_lat = hrywghts_day_df['AvgLat'][row]\n",
    "            true_lon = hrywghts_day_df['AvgLon'][row]\n",
    "\n",
    "            for i in range(0, len(predic_df)):\n",
    "                pred_lat = predic_df.loc[i, 'Latitude']\n",
    "                pred_lon = predic_df.loc[i, 'Longitude']\n",
    "\n",
    "                if meters(true_lat, true_lon, pred_lat, pred_lon) <= state_d_thrhld:\n",
    "                    act_prob_all[i] = hrywghts_day_df.loc[k, str(next_hour)]\n",
    "                    break\n",
    "\n",
    "#     #if the actual_prob_all has all 0's, this means the prediction is incorrect and hence similarity is 0.\n",
    "#     if np.mean(act_prob_all) == 0:\n",
    "#         similarity = 90\n",
    "#     else:\n",
    "#         similarity = find_similarity(pred_prob, act_prob_all)\n",
    "    similarity = find_similarity(pred_prob, act_prob_all)\n",
    "    similarity_arr = np.append(similarity_arr, similarity)\n",
    "    predic_df['ActProbability'] = act_prob_all\n",
    "    predic_df['Similarity'] = similarity\n",
    "\n",
    "\n",
    "def predict():\n",
    "    global trained_model_df\n",
    "    global hrywghts_df\n",
    "    global predic_df\n",
    "\n",
    "    file_name = \"Similarity.csv\"\n",
    "    file = dest_predicted_dir + file_name\n",
    "\n",
    "    # remove if the file already exists\n",
    "    try:\n",
    "        os.remove(file)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    for j in range(0, len(hrywghts_df)):\n",
    "        # If user has data for hours\n",
    "        for h in range(0, 24):\n",
    "            if hrywghts_df.loc[j, str(h)] != 0:\n",
    "                hour = h\n",
    "                new_lat = hrywghts_df['AvgLat'][j]\n",
    "                new_lon = hrywghts_df['AvgLon'][j]\n",
    "                # current state probabilities                        \n",
    "                curr_state_prob = hrywghts_df.loc[j, str(h)]\n",
    "\n",
    "                for i in range(0, len(trained_model_df)):\n",
    "\n",
    "                    trn_lat = trained_model_df['AvgLat'][i]\n",
    "                    trn_lon = trained_model_df['AvgLon'][i]\n",
    "                    predic_df = pd.DataFrame()\n",
    "\n",
    "                    if meters(trn_lat, trn_lon, new_lat, new_lon) <= state_d_thrhld:\n",
    "\n",
    "                        cluster_id = trained_model_df['StateId'][i]\n",
    "\n",
    "                        # next hour prediction probabilities\n",
    "                        jmp_dat = False\n",
    "                        if hour == 23:\n",
    "                            jmp_dat = True\n",
    "\n",
    "                        if jmp_dat == True:\n",
    "                            # check if there exists a next row\n",
    "                            if i+1 < len(trained_model_df):\n",
    "                                from_col_no = 5\n",
    "                                to_col_no = from_col_no + trained_model_df['StateId'].nunique()\n",
    "                                predic_df = trained_model_df.iloc[i + 1:i + 2, from_col_no:to_col_no]\n",
    "                            else:\n",
    "                                break\n",
    "                        else:\n",
    "                            from_col_no = trained_model_df['StateId'].nunique() * (hour + 1) + 5\n",
    "                            to_col_no = from_col_no + trained_model_df['StateId'].nunique()\n",
    "                            predic_df = trained_model_df.iloc[i:i + 1, from_col_no:to_col_no]\n",
    "\n",
    "                        predic_df = (predic_df * curr_state_prob).T\n",
    "\n",
    "                        predic_df['StateId'] = cluster_id\n",
    "                        predic_df['PredState'] = predic_df.index\n",
    "                        predic_df['PredState'] = predic_df['PredState'].map(lambda x: x.split('-', 2)[-1])\n",
    "\n",
    "                        predic_df.columns = ['PredProbability', 'StateId', 'PredState']\n",
    "\n",
    "                        # predic_df = predic_df.sort_values('Probability', ascending=False).head(10)\n",
    "                        predic_df = predic_df.sort_values('PredProbability', ascending=False)\n",
    "                        predic_df['DateHour'] = str(hrywghts_df['Date'][j]) + \" \" + str(hour)\n",
    "                        predic_df['Address'] = 0\n",
    "                        predic_df['Latitude'] = 0.0\n",
    "                        predic_df['Longitude'] = 0.0\n",
    "                        predic_df = predic_df.reset_index(drop=True)\n",
    "\n",
    "                        for k in range(0, len(predic_df)):\n",
    "                            # import pdb; pdb.set_trace()\n",
    "                            clus_to_find = int(float(predic_df['PredState'][k]))\n",
    "                            add = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'Address'].values[\n",
    "                                0]\n",
    "                            lat = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'AvgLat'].values[\n",
    "                                0]\n",
    "                            lon = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'AvgLon'].values[\n",
    "                                0]\n",
    "\n",
    "                            predic_df.loc[k, 'Address'] = add\n",
    "                            predic_df.loc[k, 'Latitude'] = lat\n",
    "                            predic_df.loc[k, 'Longitude'] = lon\n",
    "\n",
    "                        # if prediction was made, calculate prediction parameters\n",
    "                        check_pred(hour, j)\n",
    "\n",
    "                        predic_df.to_csv(file, mode='a')\n",
    "                        break\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "state_d_thrhld = 200\n",
    "cos_sim = []\n",
    "\n",
    "for i in range (from_user, to_user):\n",
    "    \n",
    "    user = \"{0:0=3d}\".format(usern_mnth_df.loc[i, 'User'])\n",
    "    train_month = str(usern_mnth_df.loc[i, 'TrainMonth'])\n",
    "    test_month = str(usern_mnth_df.loc[i, 'TestMonth'])\n",
    "    \n",
    "    tobepredicted_df = pd.DataFrame()\n",
    "    predic_df = pd.DataFrame()\n",
    "\n",
    "    # hourly weights file\n",
    "    hrly_wghts_file = src_path + \"/User \" + user + \"/\" + test_month + \"/hourlyweights/hourlyweights.csv\"\n",
    "    # trained model\n",
    "    trained_model_file = src_path + \"/User \" + user + \"/\" + train_month + \"/markovchains/final.csv\"\n",
    "    # predicted file\n",
    "    dest_predicted_dir = src_path + \"/User \" + user + \"/\" + test_month + \"/predict/\"\n",
    "\n",
    "    similarity_arr = []\n",
    "    \n",
    "     # check if the path is found\n",
    "    if ((not os.path.exists(src_path + \"/User \" + user + \"/\" + test_month)) or\n",
    "       not os.path.exists(src_path + \"/User \" + user + \"/\" + train_month)):\n",
    "        print(\"For user: \" + user + \" test and training path not found.\" +\n",
    "             \" Check if you have files inside: <<\" + src_path + \"/User \" + user + \"/\" + test_month + \"/staypoints/staypoints.csv\"\n",
    "             \">> and <<\" + src_path + \"/User \" + user + \"/\" + train_month + \"/markovchains/final.csv>>\")\n",
    "        continue\n",
    "    \n",
    "    # check if the file is found\n",
    "    if ((not os.path.isfile(trained_model_file)) or\n",
    "        (not os.path.isfile(hrly_wghts_file))):\n",
    "        print(\"For user: \" + user + \" test and training files not found.\")\n",
    "        continue\n",
    "\n",
    "    trained_model_df = pd.read_csv(trained_model_file, header=0)\n",
    "    hrywghts_df = pd.read_csv(hrly_wghts_file, header=0, sep='\\t')\n",
    "\n",
    "    predict()\n",
    "\n",
    "    # save similarity results\n",
    "    if similarity_arr:\n",
    "        similarity_arr = similarity_arr[np.logical_not(np.isnan(similarity_arr))]\n",
    "        sim_mean = np.mean(similarity_arr)\n",
    "        text_file = dest_predicted_dir + \"Similarity mean \" + str(sim_mean) + \" .txt\"\n",
    "        f = open(text_file, \"w+\")\n",
    "        print(\"User: \" + user + \". Cosine Similarity is: \" + str(sim_mean) + \"degrees\")\n",
    "\n",
    "        cos_sim.append(sim_mean)\n",
    "if cos_sim:    \n",
    "    print(\"mean cosine similarity: \" + str(sum(cos_sim)/len(cos_sim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
