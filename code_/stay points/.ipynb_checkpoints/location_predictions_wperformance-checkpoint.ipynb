{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import timedelta\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "import math\n",
    "import os\n",
    "from matplotlib.pyplot import figure\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import ipywidgets as widgets\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "user = \"002\"\n",
    "train_month = \"200811\"\n",
    "test_month = \"200812\"\n",
    "src_path = \"C:/Users/12sha/Documents/thesislocation/code_/stay points/v0.8 results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: 002 test and training path not found. Check if you have files inside: <<C:/Users/12sha/Documents/thesislocation/code_/stay points/v0.8 results/User 002/200812/staypoints/staypoints.csv>> and <<C:/Users/12sha/Documents/thesislocation/code_/stay points/v0.8 results/User 002/200811/markovchains/final.csv>>\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m Error message\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#True positives, true negatives, false positives, false negatives, accuracy\n",
    "\n",
    "# Find distance between two lan:lon points in meters\n",
    "def meters(lat1, lon1, lat2, lon2):\n",
    "    R = 6378.137  # Radius of earth in KM\n",
    "    dlat = lat2 * math.pi / 180 - lat1 * math.pi / 180\n",
    "    dlon = lon2 * math.pi / 180 - lon1 * math.pi / 180\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(lat1 * math.pi / 180) * math.cos(\n",
    "        lat2 * math.pi / 180) * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = R * c\n",
    "    return d * 1000  # meters\n",
    "\n",
    "\n",
    "# calculate prediction parameters\n",
    "def check_pred(indx_row):\n",
    "    global predic_df\n",
    "    global tobepredicted_df\n",
    "    global correct_pred\n",
    "    global incorrect_pred\n",
    "    global true_pos\n",
    "    global false_pos\n",
    "    global true_neg\n",
    "    global false_neg\n",
    "\n",
    "    true_pred = False\n",
    "    visit_next_hour = False\n",
    "    visit_count_next_hour = 0\n",
    "    curr_hour = tobepredicted_df.loc[indx_row, 'Hour']\n",
    "    curr_date = tobepredicted_df.loc[indx_row, 'Date']\n",
    "\n",
    "    # check if there are points found in next hour\n",
    "    for k in range(indx_row + 1, len(tobepredicted_df)):\n",
    "\n",
    "        next_hour = tobepredicted_df.loc[k, 'Hour']\n",
    "        next_date = tobepredicted_df.loc[k, 'Date']\n",
    "\n",
    "        if (curr_hour != next_hour) or (curr_date != next_date):\n",
    "\n",
    "            if (curr_hour == 23) and (next_date == curr_date + timedelta(days=1)) and (next_hour == 0):\n",
    "                visit_next_hour = True\n",
    "                visit_count_next_hour = visit_count_next_hour + 1\n",
    "            elif (next_date == curr_date) and (next_hour == curr_hour + 1):\n",
    "                visit_next_hour = True\n",
    "                visit_count_next_hour = visit_count_next_hour + 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # visit encountered in next hour: Either:\n",
    "    #      A. True Positive, or\n",
    "    #      B. False Negative\n",
    "    if visit_next_hour == True:\n",
    "\n",
    "        # B. False Negative\n",
    "        if predic_df.empty:\n",
    "            false_neg = false_neg + 1\n",
    "        # A. True Positive\n",
    "        else:\n",
    "            true_pos = true_pos + 1\n",
    "\n",
    "            # check if prediction is correct or incorrect\n",
    "            for l in range(1, visit_count_next_hour + 1):\n",
    "\n",
    "                true_lat = tobepredicted_df['StateMeanLat'][indx_row + l]\n",
    "                true_lon = tobepredicted_df['StateMeanLon'][indx_row + l]\n",
    "                true_pred = False\n",
    "                for i in range(0, len(predic_df)):\n",
    "\n",
    "                    pred_lat = predic_df.loc[i, 'Latitude']\n",
    "                    pred_lon = predic_df.loc[i, 'Longitude']\n",
    "\n",
    "                    if meters(true_lat, true_lon, pred_lat, pred_lon) <= state_d_thrhld:\n",
    "                        correct_pred = correct_pred + 1\n",
    "                        true_pred = True\n",
    "                        break\n",
    "\n",
    "                if true_pred == True:\n",
    "                    break\n",
    "\n",
    "            if true_pred == False:\n",
    "                incorrect_pred = incorrect_pred + 1\n",
    "\n",
    "    # visit not encountered in next hour: Either:\n",
    "    #      A. False Positive, or\n",
    "    #      B. True Negative\n",
    "    else:\n",
    "        # B. True Negative\n",
    "        if predic_df.empty:\n",
    "            true_neg = true_neg + 1\n",
    "        # A. False Positive\n",
    "        else:\n",
    "            false_pos = false_pos + 1\n",
    "\n",
    "\n",
    "def predict():\n",
    "    global trained_model_df\n",
    "    global staypts_df\n",
    "    global tobepredicted_df\n",
    "    global predic_df\n",
    "    global total_pred\n",
    "    global correct_pred\n",
    "    global incorrect_pred\n",
    "    global true_pos\n",
    "    global false_pos\n",
    "    global true_neg\n",
    "    global false_neg\n",
    "\n",
    "    pred_made = False\n",
    "    tobepredicted_df = staypts_df[['StateId', 'StateMeanLat', 'StateMeanLon', 'Timestamp']]\n",
    "    tobepredicted_df.Timestamp = pd.to_datetime(tobepredicted_df.Timestamp)\n",
    "    tobepredicted_df['Date'] = tobepredicted_df['Timestamp'].dt.date\n",
    "    tobepredicted_df['Hour'] = tobepredicted_df['Timestamp'].dt.hour\n",
    "    tobepredicted_df = tobepredicted_df.drop(['Timestamp'], axis=1)\n",
    "    tobepredicted_df = tobepredicted_df.drop_duplicates()\n",
    "    tobepredicted_df = tobepredicted_df.reset_index(drop=True)\n",
    "\n",
    "    file_name = \"Predictions.csv\"\n",
    "    file = dest_predicted_dir + file_name\n",
    "\n",
    "    # remove if the file already exists\n",
    "    try:\n",
    "        os.remove(file)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    for j in range(0, len(tobepredicted_df)):\n",
    "\n",
    "        new_lat = tobepredicted_df['StateMeanLat'][j]\n",
    "        new_lon = tobepredicted_df['StateMeanLon'][j]\n",
    "        hour = tobepredicted_df.loc[j, 'Hour']\n",
    "\n",
    "        for i in range(0, len(trained_model_df)):\n",
    "\n",
    "            trn_lat = trained_model_df['AvgLat'][i]\n",
    "            trn_lon = trained_model_df['AvgLon'][i]\n",
    "            predic_df = pd.DataFrame()\n",
    "            pred_made = False\n",
    "\n",
    "            if meters(trn_lat, trn_lon, new_lat, new_lon) <= state_d_thrhld:\n",
    "                # prediction is made\n",
    "                pred_made = True\n",
    "                total_pred = total_pred + 1\n",
    "\n",
    "                cluster_id = trained_model_df['StateId'][i]\n",
    "                \n",
    "                jmp_dat = False\n",
    "                if hour == 23:\n",
    "                    jmp_dat = True\n",
    "\n",
    "                if jmp_dat == True:\n",
    "                    from_col_no = 5\n",
    "                    to_col_no = from_col_no + trained_model_df['StateId'].nunique()\n",
    "                    predic_df = trained_model_df.iloc[i + 1:i + 2, from_col_no:to_col_no]\n",
    "                else:\n",
    "                    from_col_no = trained_model_df['StateId'].nunique() * (hour+1) + 5\n",
    "                    to_col_no = from_col_no + trained_model_df['StateId'].nunique()\n",
    "                    predic_df = trained_model_df.iloc[i:i + 1, from_col_no:to_col_no]\n",
    "\n",
    "                predic_df = predic_df.T\n",
    "                predic_df['StateId'] = cluster_id\n",
    "                predic_df['PredState'] = predic_df.index\n",
    "                predic_df['PredState'] = predic_df['PredState'].map(lambda x: x.split('-', 2)[-1])\n",
    "                predic_df.columns = ['Probability', 'StateId', 'PredState']\n",
    "\n",
    "                # predic_df = predic_df.sort_values('Probability', ascending=False).head(10)\n",
    "                predic_df = predic_df.sort_values('Probability', ascending=False)\n",
    "                predic_df['DateHour'] = str(tobepredicted_df['Date'][j]) + \" \" + str(tobepredicted_df['Hour'][j])\n",
    "                predic_df['Address'] = 0\n",
    "                predic_df['Latitude'] = 0.0\n",
    "                predic_df['Longitude'] = 0.0\n",
    "                predic_df = predic_df.reset_index(drop=True)\n",
    "\n",
    "                for k in range(0, len(predic_df)):\n",
    "                    # import pdb; pdb.set_trace()\n",
    "                    clus_to_find = int(float(predic_df['PredState'][k]))\n",
    "                    add = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'Address'].values[0]\n",
    "                    lat = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'AvgLat'].values[0]\n",
    "                    lon = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'AvgLon'].values[0]\n",
    "\n",
    "                    predic_df.loc[k, 'Address'] = add\n",
    "                    predic_df.loc[k, 'Latitude'] = lat\n",
    "                    predic_df.loc[k, 'Longitude'] = lon\n",
    "\n",
    "                #                 print(\"Prediction --\\n\")\n",
    "                #                 print(\"Current hour - \" + str(hour))\n",
    "                #                 print(\"\\nPrediction\\n\")\n",
    "                #                 print(predic_df)\n",
    "\n",
    "                predic_df.to_csv(file, mode='a')\n",
    "                break\n",
    "\n",
    "        # if prediction was made, calculate prediction parameters\n",
    "        if pred_made == True:\n",
    "            check_pred(j)\n",
    "\n",
    "    # plot parameters\n",
    "    figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    objects = ('Tot Pred', 'Corr Pred', 'Incor Pred', 'True Pos', 'False Pos', 'False Neg', 'True Neg')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    performance = [total_pred, correct_pred, incorrect_pred, true_pos, false_pos, false_neg, true_neg]\n",
    "\n",
    "    plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Prediction Performance')\n",
    "    destpng = dest_predicted_dir + \"pred performance.png\"\n",
    "    plt.savefig(destpng)\n",
    "    plt.show()\n",
    "\n",
    "    # prediction parameters\n",
    "    if total_pred != 0:\n",
    "        acc = correct_pred / total_pred * 100\n",
    "    else:\n",
    "        acc = 0\n",
    "\n",
    "    if true_pos + false_pos != 0:\n",
    "        true_pos_rate = true_pos / (true_pos + false_neg) * 100\n",
    "    else:\n",
    "        true_pos_rate = 0\n",
    "\n",
    "    if total_pred != 0:\n",
    "        acc_pos = (true_pos + true_neg) / total_pred * 100\n",
    "    else:\n",
    "        acc_pos = 0\n",
    "\n",
    "    if true_pos + false_pos != 0:\n",
    "        pos_pred_value = true_pos / (true_pos + false_pos) * 100\n",
    "        false_dis_rate = false_pos / (true_pos + false_pos) * 100\n",
    "    else:\n",
    "        pos_pred_value = 0\n",
    "        false_dis_rate = 0\n",
    "\n",
    "    prediction_perf = (\"Total Predictions: \" + str(total_pred) + \"\\nCorrect Predictions: \" + str(correct_pred) +\n",
    "                       \"\\nIncorrect Predictions: \" + str(incorrect_pred) +\n",
    "                       \"\\nAccuracy%: \" + str(acc) +\n",
    "                       \"\\nTrue Positives: \" + str(true_pos) + \"\\nFalse Positives: \" + str(false_pos) +\n",
    "                       \"\\nFalse Negatives: \" + str(false_neg) + \"\\nTrue Negatives: \" + str(true_neg) +\n",
    "                       \"\\nTrue positive rate(Recall)%: \" + str(true_pos_rate) +\n",
    "                       # \"\\nFalse positive rate(Fall-out): \" + str(false_pos_rate) +\n",
    "                       \"\\nAccuracy Positives%: \" + str(acc_pos) +\n",
    "                       \"\\nPositive predictive value(Precision)%: \" + str(pos_pred_value) +\n",
    "                       \"\\nFalse discovery rate%: \" + str(false_dis_rate))\n",
    "    text_file = dest_predicted_dir + \"corr pred ratio \" + str(acc) + \" .txt\"\n",
    "    f = open(text_file, \"w+\")\n",
    "    f.write(prediction_perf)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# uncomment and change this if you want to use some other values as that of the 2nd cell\n",
    "# train_month = \"200705\"\n",
    "# test_month = \"200704\"\n",
    "# user = \"021\"\n",
    "# src_path = \"C:/Users/12sha/Documents/thesislocation/code_/stay points/v0.6 results\"\n",
    "\n",
    "state_d_thrhld = 200\n",
    "tobepredicted_df = pd.DataFrame()\n",
    "predic_df = pd.DataFrame()\n",
    "\n",
    "# staypoints file path\n",
    "stay_points_file = src_path + \"/User \" + user + \"/\" + test_month + \"/staypoints/staypoints.csv\"\n",
    "# trained model\n",
    "trained_model_file = src_path + \"/User \" + user + \"/\" + train_month + \"/markovchains/final.csv\"\n",
    "# predicted file\n",
    "dest_predicted_dir = src_path + \"/User \" + user + \"/\" + test_month + \"/predict/\"\n",
    "\n",
    "# counts\n",
    "total_pred = 0\n",
    "correct_pred = 0\n",
    "incorrect_pred = 0\n",
    "true_pos = 0\n",
    "false_pos = 0\n",
    "true_neg = 0\n",
    "false_neg = 0\n",
    "\n",
    " # check if the path is found\n",
    "if ((not os.path.exists(src_path + \"/User \" + user + \"/\" + test_month)) or\n",
    "   not os.path.exists(src_path + \"/User \" + user + \"/\" + train_month)):\n",
    "    print(\"For user: \" + user + \" test and training path not found.\" +\n",
    "         \" Check if you have files inside: <<\" + src_path + \"/User \" + user + \"/\" + test_month + \"/staypoints/staypoints.csv\"\n",
    "         \">> and <<\" + src_path + \"/User \" + user + \"/\" + train_month + \"/markovchains/final.csv>>\")\n",
    "    sys.exit(\"Error message\")\n",
    "\n",
    "# check if the file is found\n",
    "if ((not os.path.isfile(trained_model_file)) or\n",
    "    (not os.path.isfile(stay_points_file))):\n",
    "    print(\"For user: \" + user + \" test and training files not found.\")\n",
    "    sys.exit(\"Error message\")\n",
    "\n",
    "\n",
    "trained_model_df = pd.read_csv(trained_model_file, header=0)\n",
    "staypts_df = pd.read_csv(stay_points_file, header=0, sep='\\t')\n",
    "\n",
    "predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: 002 test and training path not found. Check if you have files inside: <<C:/Users/12sha/Documents/thesislocation/code_/stay points/v0.8 results/User 002/200812/staypoints/staypoints.csv>> and <<C:/Users/12sha/Documents/thesislocation/code_/stay points/v0.8 results/User 002/200811/markovchains/final.csv>>\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m Error message\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Cosine Similarity\n",
    "\n",
    "# Find distance between two lan:lon points in meters\n",
    "def meters(lat1, lon1, lat2, lon2):\n",
    "    R = 6378.137  # Radius of earth in KM\n",
    "    dLat = lat2 * math.pi / 180 - lat1 * math.pi / 180\n",
    "    dLon = lon2 * math.pi / 180 - lon1 * math.pi / 180\n",
    "    a = math.sin(dLat / 2) * math.sin(dLat / 2) + math.cos(lat1 * math.pi / 180) * math.cos(\n",
    "        lat2 * math.pi / 180) * math.sin(dLon / 2) * math.sin(dLon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = R * c\n",
    "    return d * 1000  # meters\n",
    "\n",
    "def dotproduct(v1, v2):\n",
    "    return sum((a*b) for a, b in zip(v1, v2))\n",
    "\n",
    "def length(v):\n",
    "    return math.sqrt(dotproduct(v, v))\n",
    "\n",
    "def find_similarity(pred_prob, act_prob_all):\n",
    "    return math.acos(dotproduct(pred_prob, act_prob_all) / (length(pred_prob) * length(act_prob_all)))\n",
    "\n",
    "def check_pred(hour, indx_row):\n",
    "    global predic_df\n",
    "    global hrywghts_df\n",
    "    global similarity_arr\n",
    "\n",
    "    pred_prob = predic_df['PredProbability'].values\n",
    "    act_prob_all = [0] * len(pred_prob)\n",
    "    curr_date = hrywghts_df.loc[indx_row, 'Date']\n",
    "    state_wght = hrywghts_df.loc[indx_row, str(hour)]\n",
    "\n",
    "    jmp_dat = False\n",
    "    if hour == 23:\n",
    "        jmp_dat = True\n",
    "\n",
    "    # check if there are points found in next hour\n",
    "    hrywghts_day_df = hrywghts_df.loc[hrywghts_df['Date'] == curr_date]\n",
    "    hrywghts_day_df = hrywghts_day_df.reset_index(drop=True)\n",
    "    for k in range(0, len(hrywghts_day_df)):\n",
    "        if jmp_dat == True:\n",
    "            if k + 1 < len(hrywghts_day_df):\n",
    "                next_hour = 0\n",
    "                row = k + 1\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            next_hour = hour + 1\n",
    "            row = k\n",
    "\n",
    "        if hrywghts_day_df.loc[row, str(next_hour)] != 0:\n",
    "\n",
    "            true_lat = hrywghts_day_df['AvgLat'][row]\n",
    "            true_lon = hrywghts_day_df['AvgLon'][row]\n",
    "\n",
    "            for i in range(0, len(predic_df)):\n",
    "                pred_lat = predic_df.loc[i, 'Latitude']\n",
    "                pred_lon = predic_df.loc[i, 'Longitude']\n",
    "\n",
    "                if meters(true_lat, true_lon, pred_lat, pred_lon) <= state_d_thrhld:\n",
    "                    act_prob_all[i] = hrywghts_day_df.loc[k, str(next_hour)]\n",
    "                    break\n",
    "\n",
    "    #if the actual_prob_all has all 0's, this means the prediction is incorrect and hence similarity is 0.\n",
    "    if np.mean(act_prob_all) == 0:\n",
    "        similarity = 90\n",
    "    else:\n",
    "        similarity = find_similarity(pred_prob, act_prob_all)\n",
    "\n",
    "    similarity_arr = np.append(similarity_arr, similarity)\n",
    "    predic_df['ActProbability'] = act_prob_all\n",
    "    predic_df['Similarity'] = similarity\n",
    "\n",
    "\n",
    "def predict():\n",
    "    global trained_model_df\n",
    "    global hrywghts_df\n",
    "    global predic_df\n",
    "\n",
    "    file_name = \"Similarity.csv\"\n",
    "    file = dest_predicted_dir + file_name\n",
    "\n",
    "    # remove if the file already exists\n",
    "    try:\n",
    "        os.remove(file)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    for j in range(0, len(hrywghts_df)):\n",
    "        # If user has data for hours\n",
    "        for h in range(0, 24):\n",
    "            if hrywghts_df.loc[j, str(h)] != 0:\n",
    "                hour = h\n",
    "                new_lat = hrywghts_df['AvgLat'][j]\n",
    "                new_lon = hrywghts_df['AvgLon'][j]\n",
    "                # current state probabilities\n",
    "                curr_state_prob = hrywghts_df.loc[j, str(h)]\n",
    "\n",
    "                for i in range(0, len(trained_model_df)):\n",
    "\n",
    "                    trn_lat = trained_model_df['AvgLat'][i]\n",
    "                    trn_lon = trained_model_df['AvgLon'][i]\n",
    "                    predic_df = pd.DataFrame()\n",
    "\n",
    "                    if meters(trn_lat, trn_lon, new_lat, new_lon) <= state_d_thrhld:\n",
    "\n",
    "                        cluster_id = trained_model_df['StateId'][i]\n",
    "\n",
    "                        # next hour prediction probabilities\n",
    "                        jmp_dat = False\n",
    "                        if hour == 23:\n",
    "                            jmp_dat = True\n",
    "\n",
    "                        if jmp_dat == True:\n",
    "                            from_col_no = 5\n",
    "                            to_col_no = from_col_no + trained_model_df['StateId'].nunique()\n",
    "                            predic_df = trained_model_df.iloc[i + 1:i + 2, from_col_no:to_col_no]\n",
    "                        else:\n",
    "                            from_col_no = trained_model_df['StateId'].nunique() * (hour + 1) + 5\n",
    "                            to_col_no = from_col_no + trained_model_df['StateId'].nunique()\n",
    "                            predic_df = trained_model_df.iloc[i:i + 1, from_col_no:to_col_no]\n",
    "\n",
    "                        predic_df = (predic_df * curr_state_prob).T\n",
    "\n",
    "                        predic_df['StateId'] = cluster_id\n",
    "                        predic_df['PredState'] = predic_df.index\n",
    "                        predic_df['PredState'] = predic_df['PredState'].map(lambda x: x.split('-', 2)[-1])\n",
    "\n",
    "                        predic_df.columns = ['PredProbability', 'StateId', 'PredState']\n",
    "\n",
    "                        # predic_df = predic_df.sort_values('Probability', ascending=False).head(10)\n",
    "                        predic_df = predic_df.sort_values('PredProbability', ascending=False)\n",
    "                        predic_df['DateHour'] = str(hrywghts_df['Date'][j]) + \" \" + str(hour)\n",
    "                        predic_df['Address'] = 0\n",
    "                        predic_df['Latitude'] = 0.0\n",
    "                        predic_df['Longitude'] = 0.0\n",
    "                        predic_df = predic_df.reset_index(drop=True)\n",
    "\n",
    "                        for k in range(0, len(predic_df)):\n",
    "                            # import pdb; pdb.set_trace()\n",
    "                            clus_to_find = int(float(predic_df['PredState'][k]))\n",
    "                            add = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'Address'].values[\n",
    "                                0]\n",
    "                            lat = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'AvgLat'].values[\n",
    "                                0]\n",
    "                            lon = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'AvgLon'].values[\n",
    "                                0]\n",
    "\n",
    "                            predic_df.loc[k, 'Address'] = add\n",
    "                            predic_df.loc[k, 'Latitude'] = lat\n",
    "                            predic_df.loc[k, 'Longitude'] = lon\n",
    "\n",
    "                        # if prediction was made, calculate prediction parameters\n",
    "                        check_pred(hour, j)\n",
    "\n",
    "                        predic_df.to_csv(file, mode='a')\n",
    "                        break\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "# uncomment and change this if you want to use some other values as that of the 2nd cell\n",
    "# train_month = \"201109\"\n",
    "# test_month = \"201110\"\n",
    "# user = \"020\"\n",
    "# src_path = \"C:/Users/12sha/Documents/thesislocation/code_/stay points/v0.6 results\"\n",
    "\n",
    "state_d_thrhld = 200\n",
    "tobepredicted_df = pd.DataFrame()\n",
    "predic_df = pd.DataFrame()\n",
    "\n",
    "# hourly weights file\n",
    "hrly_wghts_file = src_path + \"/User \" + user + \"/\" + test_month + \"/hourlyweights/hourlyweights.csv\"\n",
    "# trained model\n",
    "trained_model_file = src_path + \"/User \" + user + \"/\" + train_month + \"/markovchains/final.csv\"\n",
    "# predicted file\n",
    "dest_predicted_dir = src_path + \"/User \" + user + \"/\" + test_month + \"/predict/\"\n",
    "\n",
    "similarity_arr = []\n",
    "\n",
    " # check if the path is found\n",
    "if ((not os.path.exists(src_path + \"/User \" + user + \"/\" + test_month)) or\n",
    "   not os.path.exists(src_path + \"/User \" + user + \"/\" + train_month)):\n",
    "    print(\"For user: \" + user + \" test and training path not found.\" +\n",
    "         \" Check if you have files inside: <<\" + src_path + \"/User \" + user + \"/\" + test_month + \"/staypoints/staypoints.csv\"\n",
    "         \">> and <<\" + src_path + \"/User \" + user + \"/\" + train_month + \"/markovchains/final.csv>>\")\n",
    "    sys.exit(\"Error message\")\n",
    "\n",
    "# check if the file is found\n",
    "if ((not os.path.isfile(trained_model_file)) or\n",
    "    (not os.path.isfile(stay_points_file))):\n",
    "    print(\"For user: \" + user + \" test and training files not found.\")\n",
    "    sys.exit(\"Error message\")\n",
    "    \n",
    "trained_model_df = pd.read_csv(trained_model_file, header=0)\n",
    "hrywghts_df = pd.read_csv(hrly_wghts_file, header=0, sep='\\t')\n",
    "\n",
    "predict()\n",
    "\n",
    "# save similarity results\n",
    "similarity_arr = similarity_arr[np.logical_not(np.isnan(similarity_arr))]\n",
    "sim_mean = np.mean(similarity_arr)\n",
    "text_file = dest_predicted_dir + \"similarity mean \" + str(sim_mean) + \" .txt\"\n",
    "f = open(text_file, \"w+\")\n",
    "print(\"Cosine Similarity is: \" + str(sim_mean) + \"degrees\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
