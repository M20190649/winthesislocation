{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import math \n",
    "import os\n",
    "import errno\n",
    "import matplotlib.patches as patches\n",
    "from copy import deepcopy\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib.patches import Ellipse, Circle\n",
    "import operator\n",
    "import pdb\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "def read_usr_file():\n",
    "    global usr_trejec_df\n",
    "    \n",
    "    #Load file names for user\n",
    "    filenames = glob.glob(file_source_raw)\n",
    "\n",
    "    #Read the files\n",
    "    list_of_dfs = [pd.read_csv(filename, skiprows=6, header = None) for filename in filenames]\n",
    "\n",
    "    #put the data from list into one dataframe\n",
    "    usr_trejec_df = pd.concat(list_of_dfs, ignore_index=True)\n",
    "    usr_trejec_df.columns = ['Latitude', 'Longitude', '0', 'Altitude', 'NumDays', 'Date', 'Time']\n",
    "    usr_trejec_df[\"Timestamp\"] = usr_trejec_df[\"Date\"].map(str) + \" \" + usr_trejec_df[\"Time\"]\n",
    "    \n",
    "    usr_trejec_df.Timestamp = pd.to_datetime(usr_trejec_df.Timestamp)\n",
    "    \n",
    "    usr_trejec_df.index = usr_trejec_df['Timestamp']\n",
    "    usr_trejec_df = usr_trejec_df.resample('1T').mean()\n",
    "    usr_trejec_df = usr_trejec_df.dropna()\n",
    "    \n",
    "     #add columns to user trajectory dataframe\n",
    "    #1. add timestamp as column\n",
    "    usr_trejec_df['Timestamp'] = pd.to_datetime(usr_trejec_df.index)\n",
    "    #restore date and time column\n",
    "    usr_trejec_df['Date'] = usr_trejec_df.Timestamp.dt.date\n",
    "    usr_trejec_df['Time'] = usr_trejec_df.Timestamp.dt.time\n",
    "\n",
    "    #sort values based on timestamp\n",
    "    usr_trejec_df = usr_trejec_df.sort_values(['Timestamp'])\n",
    "    #reset index\n",
    "    usr_trejec_df = usr_trejec_df.reset_index(drop=True)\n",
    "    \n",
    "    #some test columns\n",
    "    #distance between consicutive points to for further checks\n",
    "    usr_trejec_df['Distance(Km)'] = 0\n",
    "    for i in range(0, len(usr_trejec_df)-1):\n",
    "        usr_trejec_df.loc[i+1, 'Distance(Km)'] = (meters(usr_trejec_df.loc[i, 'Latitude'],\n",
    "                                                    usr_trejec_df.loc[i, 'Longitude'],\n",
    "                                                   usr_trejec_df.loc[i+1, 'Latitude'],\n",
    "                                                   usr_trejec_df.loc[i+1, 'Longitude'])) / 1000\n",
    "    #time difference between two points\n",
    "    usr_trejec_df['Time(Hr)'] = 0\n",
    "    for i in range(0, len(usr_trejec_df)-1):\n",
    "        usr_trejec_df.loc[i+1, 'Time(Hr)'] = (usr_trejec_df.loc[i+1, 'Timestamp'] -\n",
    "                                              usr_trejec_df.loc[i, 'Timestamp']).seconds/3600\n",
    "    #speed                                    \n",
    "    usr_trejec_df['Speed(Km/Hr)'] = usr_trejec_df['Distance(Km)'] / usr_trejec_df['Time(Hr)']\n",
    "    \n",
    "    usr_trejec_df['Hour'] = usr_trejec_df.Timestamp.dt.hour\n",
    "    \n",
    "    #distance clusters\n",
    "    usr_trejec_df['DistClus'] = 0\n",
    "    usr_trejec_df['ClusDur'] = 0\n",
    "    last_hr =  usr_trejec_df['Hour'][0]\n",
    "    clusid = 0\n",
    "    i = 0\n",
    "\n",
    "    while i < len(usr_trejec_df)-1:\n",
    "        clusid+=1\n",
    "        \n",
    "        #update the cluster duration\n",
    "        if i != 0:\n",
    "            usr_trejec_df.loc[i-1, 'ClusDur']= (usr_trejec_df.loc[i-1, 'Timestamp'] - \n",
    "                                            usr_trejec_df.loc[i-curr_clus_count, 'Timestamp']).seconds/60\n",
    "        curr_clus_count = 1\n",
    "        \n",
    "        #add current cluster to mean values\n",
    "        array_lat = usr_trejec_df.loc[i,'Latitude']\n",
    "        array_lon = usr_trejec_df.loc[i,'Longitude']\n",
    "        new_lat_mean = np.mean(array_lat)\n",
    "        new_lon_mean = np.mean(array_lon)\n",
    "        \n",
    "        usr_trejec_df.loc[i, 'DistClus'] = clusid\n",
    "        for j in range(i+1, len(usr_trejec_df)):\n",
    "            #if the hour changes, stop j loop\n",
    "            if usr_trejec_df.loc[j, 'Hour'] != last_hr:\n",
    "                last_hr =  usr_trejec_df.loc[j, 'Hour']\n",
    "                i=j\n",
    "                break\n",
    "            else:\n",
    "                if meters(new_lat_mean, \n",
    "                           new_lon_mean, \n",
    "                           usr_trejec_df.loc[j,'Latitude'], \n",
    "                           usr_trejec_df.loc[j,'Longitude'])<= staypts_d_thrhld:\n",
    "                        curr_clus_count+=1\n",
    "                        \n",
    "                        array_lat= np.append(array_lat, usr_trejec_df.loc[j,'Latitude'])\n",
    "                        array_lon= np.append(array_lon, usr_trejec_df.loc[j,'Longitude'])\n",
    "                        new_lat_mean = np.mean(array_lat)\n",
    "                        new_lon_mean = np.mean(array_lon)\n",
    "        \n",
    "                        usr_trejec_df.loc[j, 'DistClus'] = usr_trejec_df.loc[i, 'DistClus']\n",
    "                        \n",
    "                else:\n",
    "                    i=j\n",
    "                    break\n",
    "        i=j\n",
    "        \n",
    "\n",
    "    usr_trejec_df['Weekday'] = usr_trejec_df['Timestamp'].dt.weekday.map(str) + usr_trejec_df['Timestamp'].dt.weekday_name\n",
    "\n",
    "    usr_trejec_df['StayPoint'] = -1 # 1 if it is a staypoint, else 0\n",
    "    usr_trejec_df['StayptId'] = -1\n",
    "    usr_trejec_df['StayMeanLat'] = -1.0\n",
    "    usr_trejec_df['StayMeanLon'] = -1.0\n",
    "    usr_trejec_df['StateId'] = -1\n",
    "    \n",
    "    #remove columns not used/required\n",
    "    usr_trejec_df = usr_trejec_df.drop(['0', 'Altitude', 'NumDays'], axis = 1)\n",
    "    \n",
    "    file_name = usr_directory + \"/input_trj_data.csv\"\n",
    "    usr_trejec_df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "        \n",
    "#------------------------------------------------------------------------------------\n",
    "#Find distance between two lan:lon points in meters\n",
    "def meters(lat1, lon1, lat2, lon2):  \n",
    "    R = 6378.137 # Radius of earth in KM\n",
    "    dLat = lat2 * math.pi / 180 - lat1 * math.pi / 180\n",
    "    dLon = lon2 * math.pi / 180 - lon1 * math.pi / 180\n",
    "    a = math.sin(dLat/2) * math.sin(dLat/2) + math.cos(lat1 * math.pi / 180) * math.cos(lat2 * math.pi / 180) * math.sin(dLon/2) * math.sin(dLon/2);\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a));\n",
    "    d = R * c\n",
    "    return d * 1000 # meters\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "def setting_for_staypoint(row, count):\n",
    "    global usr_trejec_df\n",
    "    global staypts_df\n",
    "\n",
    "    \n",
    "    staypts_df = staypts_df.iloc[0:0]\n",
    "    staypts_df['StayptId'] = -1\n",
    "    staypts_df['StayMeanLat'] = 0.0\n",
    "    staypts_df['StayMeanLon'] = 0.0\n",
    "    staypts_df['StartTimestamp'] = 0\n",
    "    staypts_df['EndTimestamp'] = 0\n",
    "    staypts_df['StateId'] = -1\n",
    "    staypts_df['StateMeanLat'] = 0.0\n",
    "    staypts_df['StateMeanLon'] = 0.0\n",
    "    staypts_df['StateStart'] = 0\n",
    "    staypts_df['StateEnd'] = 0\n",
    "    \n",
    "    staypts_df['StartTimestamp'] = pd.to_datetime(staypts_df.StartTimestamp)\n",
    "    staypts_df['EndTimestamp'] = pd.to_datetime(staypts_df.EndTimestamp)\n",
    "    staypts_df['StateStart'] = pd.to_datetime(staypts_df.StateStart)\n",
    "    staypts_df['StateEnd'] = pd.to_datetime(staypts_df.StateEnd)\n",
    "    \n",
    "    usr_trejec_df['StayptId'][row-1] = 1\n",
    "    usr_trejec_df['StayMeanLat'][row-1] = usr_trejec_df['Latitude'][0] #latitude as mean lat\n",
    "    usr_trejec_df['StayMeanLon'][row-1] = usr_trejec_df['Longitude'][0] #longitude as mean lon\n",
    "    usr_trejec_df['StayPoint'][row-1] = -1 #assign as -1 to say this is not a stay-point initially\n",
    "    \n",
    "#------------------------------------------------------------------------------------\n",
    "def find_stay_points(newlat, newlon, row, count):\n",
    "    global usr_trejec_df\n",
    "    global new_staypt_flag\n",
    "    \n",
    "    #resert return varaibles\n",
    "    new_staypt_flag = False\n",
    "    staypt_count = 0\n",
    "    currcluster1 = 0 \n",
    "    clulat1 = 0\n",
    "    clulon1 = 0\n",
    "    MinClusTime1 = 0\n",
    "    MaxClusTime1 = 0\n",
    "    currcluster2 = 0 \n",
    "    clulat2 = 0\n",
    "    clulon2 = 0\n",
    "    MinClusTime2 = 0\n",
    "    MaxClusTime2 = 0\n",
    "    \n",
    "    #set default values for the new location\n",
    "    currcluster = usr_trejec_df['StayptId'][row-1]\n",
    "    usr_trejec_df['StayptId'][row] = -1\n",
    "    usr_trejec_df['StayMeanLat'][row] = -1.0\n",
    "    usr_trejec_df['StayMeanLon'][row] = -1.0\n",
    "    usr_trejec_df['StayPoint'][row] = -1\n",
    "    clulat = usr_trejec_df['StayMeanLat'][row-1]\n",
    "    clulon = usr_trejec_df['StayMeanLon'][row-1]\n",
    "    \n",
    "    #Case I----------------\n",
    "    #if the new point and the old point time difference is greater than tracking threshold\n",
    "    # then add both the points as staypoints \n",
    "    prevPointTime = usr_trejec_df['Timestamp'][row-1]\n",
    "    currPointTime = usr_trejec_df['Timestamp'][row]\n",
    "    k = currPointTime - prevPointTime\n",
    "    l = (k / np.timedelta64(1, 'm')).astype(int)\n",
    "            \n",
    "    if (l >= track_t_thrhld):\n",
    "        new_staypt_flag = True\n",
    "        count = 1\n",
    "        staypt_count = 2\n",
    "        \n",
    "        usr_trejec_df.loc[row, 'StayptId'] = currcluster + 1\n",
    "        usr_trejec_df.loc[row, 'StayPoint'] = 1\n",
    "        usr_trejec_df.loc[row-1, 'StayPoint'] = 1\n",
    "        \n",
    "        currcluster1 = usr_trejec_df.loc[row-1, 'StayptId']\n",
    "        clulat1 = usr_trejec_df.loc[row-1, 'Latitude']\n",
    "        clulon1 = usr_trejec_df.loc[row-1, 'Longitude']\n",
    "        MinClusTime1 = usr_trejec_df.loc[row-1, 'Timestamp']\n",
    "        MaxClusTime1 = usr_trejec_df.loc[row-1, 'Timestamp']\n",
    "        \n",
    "        currcluster2 = usr_trejec_df.loc[row, 'StayptId']\n",
    "        clulat2 = usr_trejec_df.loc[row, 'Latitude']\n",
    "        clulon2 = usr_trejec_df.loc[row, 'Longitude']\n",
    "        MinClusTime2 = usr_trejec_df.loc[row, 'Timestamp']\n",
    "        MaxClusTime2 = usr_trejec_df.loc[row, 'Timestamp']\n",
    "        \n",
    "        return (count, new_staypt_flag, staypt_count, \n",
    "                currcluster1, clulat1, clulon1, MinClusTime1, MaxClusTime1,\n",
    "                currcluster2, clulat2, clulon2, MinClusTime2, MaxClusTime2) \n",
    "    \n",
    "    #Case II----------------\n",
    "    #if the new point and old point's distance is less than threshold, then add it to current cluster\n",
    "    if meters(clulat, clulon, newlat, newlon)<= staypts_d_thrhld:\n",
    "        usr_trejec_df['StayptId'][row] = currcluster\n",
    "        #calculate new mean lat and lon for the cluster\n",
    "        array_lat = usr_trejec_df['Latitude'].loc[usr_trejec_df['StayptId'] == currcluster].values\n",
    "        array_lon = usr_trejec_df['Longitude'].loc[usr_trejec_df['StayptId'] == currcluster].values\n",
    "        \n",
    "        #cal new means\n",
    "        new_lat_mean = np.mean(array_lat)\n",
    "        new_lon_mean = np.mean(array_lon)\n",
    "         \n",
    "        usr_trejec_df.loc[ (usr_trejec_df['StayptId']==currcluster), 'StayMeanLat'] = new_lat_mean\n",
    "        usr_trejec_df.loc[ (usr_trejec_df['StayptId']==currcluster), 'StayMeanLon'] = new_lon_mean\n",
    "        \n",
    "#         usr_trejec_df['StayMeanLat'] = usr_trejec_df.groupby('StayptId')['Latitude'].transform(np.mean)\n",
    "#         usr_trejec_df['StayMeanLon'] = usr_trejec_df.groupby('StayptId')['Longitude'].transform(np.mean)\n",
    "        count = count + 1\n",
    "        \n",
    "    #if the new point and old point's distance is greater than threshold, it means the point moved away\n",
    "    #if the previous cluster has more than two points, check the duration of the previous cluster\n",
    "    #   if the duration of the previos cluster is greater than threshold, assign it as a staypoint\n",
    "    \n",
    "    #Case III----------------\n",
    "    #if the row read is the last row for this hour\n",
    "    if (row == len(usr_trejec_df)-1):\n",
    "        if count >= 2:\n",
    "            MinClusTime = usr_trejec_df['Timestamp'][row-count+1]\n",
    "            MaxClusTime = usr_trejec_df['Timestamp'][row]\n",
    "            k = MaxClusTime - MinClusTime\n",
    "            l = (k / np.timedelta64(1, 'm')).astype(int)\n",
    "            \n",
    "            if (l >= staypts_t_thrhld):\n",
    "                usr_trejec_df.loc[ (usr_trejec_df['StayptId']==currcluster), 'StayPoint'] = 1        \n",
    "    \n",
    "    #Case IV----------------\n",
    "    #if the new point is moving away from the cluster\n",
    "    if meters(clulat, clulon, newlat, newlon)> staypts_d_thrhld:\n",
    "        if count >= 2:\n",
    "            MinClusTime = usr_trejec_df['Timestamp'][row-count]\n",
    "            MaxClusTime = usr_trejec_df['Timestamp'][row-1]\n",
    "            k = MaxClusTime - MinClusTime\n",
    "            l = (k / np.timedelta64(1, 'm')).astype(int)\n",
    "            \n",
    "            if (l >= staypts_t_thrhld):\n",
    "                \n",
    "                new_staypt_flag = True\n",
    "                staypt_count = 1\n",
    "                currcluster1 = currcluster\n",
    "                clulat1 = clulat\n",
    "                clulon1 = clulon\n",
    "                MinClusTime1 = MinClusTime\n",
    "                MaxClusTime1 = MaxClusTime\n",
    "                currcluster2 = 0 \n",
    "                clulat2 = 0\n",
    "                clulon2 = 0\n",
    "                MinClusTime2 = 0\n",
    "                MaxClusTime2 = 0\n",
    "                \n",
    "                usr_trejec_df.loc[ (usr_trejec_df['StayptId']==currcluster), 'StayPoint'] = 1\n",
    "        count = 1\n",
    "        usr_trejec_df['StayMeanLat'][row] = usr_trejec_df['Latitude'][row]\n",
    "        usr_trejec_df['StayMeanLon'][row] = usr_trejec_df['Longitude'][row]\n",
    "        usr_trejec_df['StayptId'][row] = currcluster + 1\n",
    "\n",
    "    return (count, new_staypt_flag, staypt_count, \n",
    "                currcluster1, clulat1, clulon1, MinClusTime1, MaxClusTime1,\n",
    "                currcluster2, clulat2, clulon2, MinClusTime2, MaxClusTime2) \n",
    "#------------------------------------------------------------------------------------\n",
    "def update_staypts(pos, staypt_count, staypt_id1, mean_lat1, mean_lon1, start_time1, end_time1,\n",
    "                  staypt_id2, mean_lat2, mean_lon2, start_time2, end_time2):\n",
    "    global staypts_df\n",
    "    \n",
    "    staypts_df.loc[pos, 'StayptId'] = staypt_id1\n",
    "    staypts_df.loc[pos, 'StayMeanLat'] = mean_lat1\n",
    "    staypts_df.loc[pos, 'StayMeanLon'] = mean_lon1\n",
    "    staypts_df.loc[pos, 'StartTimestamp'] = start_time1\n",
    "    staypts_df.loc[pos, 'EndTimestamp'] = end_time1\n",
    "    \n",
    "    if staypt_count == 2:\n",
    "        \n",
    "        staypts_df.loc[pos+1, 'StayptId'] = staypt_id2\n",
    "        staypts_df.loc[pos+1, 'StayMeanLat'] = mean_lat2\n",
    "        staypts_df.loc[pos+1, 'StayMeanLon'] = mean_lon2\n",
    "        staypts_df.loc[pos+1, 'StartTimestamp'] = start_time2\n",
    "        staypts_df.loc[pos+1, 'EndTimestamp'] = end_time2\n",
    "    \n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "def cal_hourly_state_weight():\n",
    "    global curr_hr_staypts_df\n",
    "    global cluster_hourly_df   \n",
    "    \n",
    "    curr_hr_cluster_hourly_df = pd.DataFrame()       \n",
    "    \n",
    "    last_hour = curr_hr_staypts_df['Timestamp'][0].hour\n",
    "    last_clusid = curr_hr_staypts_df['StateId'][0]\n",
    "    curr_count = 0\n",
    "    j = 0\n",
    "    \n",
    "    for i in range(0, 24):\n",
    "        curr_hr_cluster_hourly_df['Date'] = 0\n",
    "        curr_hr_cluster_hourly_df['StateId'] = 0\n",
    "        curr_hr_cluster_hourly_df['AvgLat'] = 0\n",
    "        curr_hr_cluster_hourly_df['AvgLon'] = 0\n",
    "        curr_hr_cluster_hourly_df[i] = 0\n",
    "    \n",
    "    for i in range(0, len(curr_hr_staypts_df)):\n",
    "\n",
    "        if (i == len(curr_hr_staypts_df)-1):\n",
    "            \n",
    "            k = curr_hr_staypts_df['Timestamp'][i] - curr_hr_staypts_df['Timestamp'][i-curr_count]\n",
    "            l = (k / np.timedelta64(1, 'm')).astype(int)\n",
    "            \n",
    "            date_read = curr_hr_staypts_df.index[i].date()\n",
    "            cluster_id = curr_hr_staypts_df['StateId'][i]\n",
    "            ClusterMeanLat = curr_hr_staypts_df['StateMeanLat'][i]\n",
    "            ClusterMeanLon = curr_hr_staypts_df['StateMeanLon'][i]\n",
    "            col_name = curr_hr_staypts_df.index[i].hour\n",
    "\n",
    "            curr_hr_cluster_hourly_df.loc[j,'AvgLat'] = ClusterMeanLat\n",
    "            curr_hr_cluster_hourly_df.loc[j,'AvgLon'] = ClusterMeanLon\n",
    "            curr_hr_cluster_hourly_df.loc[j,'Date'] = date_read\n",
    "            curr_hr_cluster_hourly_df.loc[j,'StateId'] = cluster_id\n",
    "            curr_hr_cluster_hourly_df.loc[j, col_name] = round((l)/60,4)\n",
    "            \n",
    "        if (curr_hr_staypts_df['Timestamp'][i].hour != last_hour) | (curr_hr_staypts_df['StateId'][i] != last_clusid):\n",
    "            #import pdb; pdb.set_trace()\n",
    "\n",
    "            if (curr_count == 1) & (curr_hr_staypts_df['Timestamp'][i].hour != last_hour):\n",
    "                k = ((curr_hr_staypts_df['Timestamp'][i-1] + pd.Timedelta(hours=1) - \n",
    "                      pd.Timedelta(minutes=curr_hr_staypts_df['Timestamp'][i-1].minute)) - \n",
    "                     curr_hr_staypts_df['Timestamp'][i-1])\n",
    "            else:\n",
    "                k = curr_hr_staypts_df['Timestamp'][i-1] - curr_hr_staypts_df['Timestamp'][i-curr_count]\n",
    "\n",
    "            l = (k / np.timedelta64(1, 'm')).astype(int)\n",
    "            date_read = curr_hr_staypts_df.index[i-1].date()\n",
    "            cluster_id = curr_hr_staypts_df['StateId'][i-1]\n",
    "            ClusterMeanLat = curr_hr_staypts_df['StateMeanLat'][i-1]\n",
    "            ClusterMeanLon = curr_hr_staypts_df['StateMeanLon'][i-1]\n",
    "            col_name = curr_hr_staypts_df.index[i-1].hour\n",
    "\n",
    "            curr_hr_cluster_hourly_df.loc[j, 'AvgLat'] = ClusterMeanLat\n",
    "            curr_hr_cluster_hourly_df.loc[j, 'AvgLon'] = ClusterMeanLon\n",
    "            curr_hr_cluster_hourly_df.loc[j, 'Date'] = date_read\n",
    "            curr_hr_cluster_hourly_df.loc[j, 'StateId'] = cluster_id\n",
    "            curr_hr_cluster_hourly_df.loc[j, col_name] = round((l)/60,4)\n",
    "            j = j + 1\n",
    "            curr_count = 1\n",
    "\n",
    "            if (curr_hr_staypts_df['Timestamp'][i].hour != last_hour):\n",
    "                last_hour = curr_hr_staypts_df['Timestamp'][i].hour\n",
    "            if (curr_hr_staypts_df['StateId'][i] != last_clusid):\n",
    "                last_clusid = curr_hr_staypts_df['StateId'][i]\n",
    "        else:\n",
    "            curr_count = curr_count + 1\n",
    "\n",
    "    curr_hr_cluster_hourly_df = curr_hr_cluster_hourly_df.fillna(0)\n",
    "    curr_hr_cluster_hourly_df = curr_hr_cluster_hourly_df.groupby(['Date', 'StateId', 'AvgLat', 'AvgLon']).sum()\n",
    "    curr_hr_cluster_hourly_df = curr_hr_cluster_hourly_df.reset_index(level=[0,1,2,3])\n",
    "   \n",
    "    cluster_hourly_df = cluster_hourly_df.append(curr_hr_cluster_hourly_df, ignore_index=True)\n",
    "    cluster_hourly_df = cluster_hourly_df.reset_index(drop=True)\n",
    "    \n",
    "#-------------form states-----------------------------------------------------------------------\n",
    "def form_states(pos, staypt_count, \n",
    "                staypt_id1, mean_lat1, mean_lon1, start_time1, end_time1,\n",
    "                staypt_id2, mean_lat2, mean_lon2, start_time2, end_time2):\n",
    "    global usr_trejec_df\n",
    "    global staypts_df\n",
    "    \n",
    "    #Step I---------------------------\n",
    "    #Add the new staypoint as a new state\n",
    "    \n",
    "    staypts_df.loc[pos, 'StateId'] = staypt_id1\n",
    "    staypts_df.loc[pos, 'StateMeanLat'] = mean_lat1\n",
    "    staypts_df.loc[pos, 'StateMeanLon'] = mean_lon1\n",
    "     \n",
    "    if staypt_count == 2:\n",
    "        staypts_df.loc[pos+1, 'StateId'] = staypt_id2\n",
    "        staypts_df.loc[pos+1, 'StateMeanLat'] = mean_lat2\n",
    "        staypts_df.loc[pos+1, 'StateMeanLon'] = mean_lon2\n",
    "    \n",
    "    #update user trejectory file\n",
    "    usr_trejec_df['StateId'] = usr_trejec_df['StayptId']\n",
    "    \n",
    "    #Step II---------------------------\n",
    "    #Snapping new staypoints to existing states\n",
    "      \n",
    "    add_state1 = \"No\"\n",
    "    stayptid = staypt_id1\n",
    "    stay_lat = mean_lat1\n",
    "    stay_lon = mean_lon1\n",
    "    for j in range(0, pos):\n",
    "        stateid = staypts_df.loc[j, 'StateId']\n",
    "        state_lat = staypts_df.loc[j, 'StateMeanLat']\n",
    "        state_lon = staypts_df.loc[j, 'StateMeanLon']\n",
    "        add_state1 = add_state(j, pos, stayptid, stay_lat, stay_lon, stateid, state_lat, state_lon)\n",
    "    \n",
    "    \n",
    "    if staypt_count == 2:\n",
    "        add_state2 = \"No\"\n",
    "        stayptid = staypt_id2\n",
    "        stay_lat = mean_lat2\n",
    "        stay_lon = mean_lon2\n",
    "        for j in range(0, pos+1):\n",
    "            stateid = staypts_df.loc[j, 'StateId']\n",
    "            state_lat = staypts_df.loc[j, 'StateMeanLat']\n",
    "            state_lon = staypts_df.loc[j, 'StateMeanLon']\n",
    "            add_state2 = add_state(j, pos+1, stayptid, stay_lat, stay_lon, stateid, state_lat, state_lon)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "def add_state(j, pos, stayptid, stay_lat, stay_lon, stateid, state_lat, state_lon):\n",
    "    global usr_trejec_df\n",
    "    global staypts_df\n",
    "    \n",
    "    add_state_flag = \"No\"\n",
    "    \n",
    "    if meters(stay_lat, stay_lon, state_lat, state_lon)<= state_d_thrhld:\n",
    "        #before adding this point to the ith state, \n",
    "        #   calculate new mean with jth point,\n",
    "        #   if the new mean is still keeping all the states with id(i) than add jth to the state\n",
    "        #   else not\n",
    "\n",
    "        add_state_flag = \"Yes\"\n",
    "        #form the existing lat and lon array\n",
    "        array_lat = usr_trejec_df['Latitude'].loc[usr_trejec_df['StayptId'] == stateid].values\n",
    "        array_lon = usr_trejec_df['Longitude'].loc[usr_trejec_df['StayptId'] == stateid].values\n",
    "        #add the new lat and lon values to the array\n",
    "        array_lat= np.append(array_lat, stay_lat)\n",
    "        array_lon= np.append(array_lon, stay_lon)\n",
    "        #cal new means\n",
    "        new_lat_mean = np.mean(array_lat)\n",
    "        new_lon_mean = np.mean(array_lon)\n",
    "\n",
    "        for k in range(0, len(array_lat)):\n",
    "            if meters(array_lat[k], array_lon[k], new_lat_mean, new_lon_mean) > state_d_thrhld:\n",
    "                add_state_flag = \"No\"\n",
    "\n",
    "        if add_state_flag == \"Yes\": \n",
    "            staypts_df.loc[pos, 'StateId'] = stateid\n",
    "            staypts_df.loc[ (staypts_df['StateId']==stateid), 'StateMeanLat'] = new_lat_mean\n",
    "            staypts_df.loc[ (staypts_df['StateId']==stateid), 'StateMeanLon'] = new_lon_mean\n",
    "\n",
    "            #update usr_trejec_df\n",
    "            usr_trejec_df.loc[ (usr_trejec_df['StateId']==stayptid), 'StateId'] = stateid\n",
    "\n",
    "    return add_state_flag\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def cal_start_end_states_time(pos, staypt_count):\n",
    "    global staypts_df\n",
    "    \n",
    "    if pos == 0:\n",
    "        return\n",
    "    import pdb; pdb.set_trace()\n",
    "    \n",
    "    #update default state start and end times\n",
    "    staypts_df.loc[pos, 'StateStart'] = staypts_df.loc[pos, 'StartTimestamp']\n",
    "    staypts_df.loc[pos, 'StateEnd'] = staypts_df.loc[pos, 'EndTimestamp']\n",
    "    staypts_df.loc[pos-1, 'StateStart'] = staypts_df.loc[pos-1, 'StartTimestamp']\n",
    "    staypts_df.loc[pos-1, 'StateEnd'] = staypts_df.loc[pos-1, 'EndTimestamp']\n",
    "    if staypt_count == 2:\n",
    "        staypts_df.loc[pos+1, 'StateStart'] = staypts_df.loc[pos+1, 'StartTimestamp']\n",
    "        staypts_df.loc[pos+1, 'StateEnd'] = staypts_df.loc[pos+1, 'EndTimestamp']\n",
    "    \n",
    "    end1_time = staypts_df.loc[pos-1, 'EndTimestamp']\n",
    "    end1_lat = staypts_df.loc[pos-1, 'StayMeanLat']\n",
    "    end1_lon = staypts_df.loc[pos-1, 'StayMeanLon']\n",
    "    str2_time = staypts_df.loc[pos, 'StartTimestamp']\n",
    "    str2_lat = staypts_df.loc[pos, 'StayMeanLat']\n",
    "    str2_lon = staypts_df.loc[pos, 'StayMeanLon']\n",
    "                \n",
    "    dist = meters(end1_lat, end1_lon, str2_lat, str2_lon)\n",
    "    time = (str2_time - end1_time).seconds / 60\n",
    "    \n",
    "    #this indicate, either it is the same point or it has no scope to add time. \n",
    "    if time == 0:\n",
    "        return\n",
    "    \n",
    "    avg_speed = dist/time\n",
    "    \n",
    "    #this indicate it is the same point  \n",
    "    if avg_speed == 0:\n",
    "        return\n",
    "    \n",
    "    delta_t = min(state_d_thrhld, dist)/avg_speed\n",
    "    \n",
    "    end1_time = end1_time + timedelta(minutes=delta_t)\n",
    "    str2_time = str2_time - timedelta(minutes=delta_t)\n",
    "    \n",
    "    staypts_df.loc[pos-1, 'StateStart'] = end1_time\n",
    "    staypts_df.loc[pos, 'StateEnd'] = str2_time\n",
    "    \n",
    "    if staypt_count == 2:\n",
    "        end1_time = staypts_df.loc[pos, 'EndTimestamp']\n",
    "        end1_lat = staypts_df.loc[pos, 'StayMeanLat']\n",
    "        end1_lon = staypts_df.loc[pos, 'StayMeanLon']\n",
    "        str2_time = staypts_df.loc[pos+1, 'StartTimestamp']\n",
    "        str2_lat = staypts_df.loc[pos+1, 'StayMeanLat']\n",
    "        str2_lon = staypts_df.loc[pos+1, 'StayMeanLon']\n",
    "\n",
    "        dist = meters(end1_lat, end1_lon, str2_lat, str2_lon)\n",
    "        time = (str2_time - end1_time).seconds / 60\n",
    "        \n",
    "        #this indicate, either it is the same point or it has no scope to add time. \n",
    "        if time == 0:\n",
    "            return\n",
    "        \n",
    "        avg_speed = dist/time\n",
    "        \n",
    "        #this indicate it is the same point \n",
    "        if avg_speed == 0:\n",
    "            return\n",
    "    \n",
    "        delta_t = min(state_d_thrhld, dist)/avg_speed\n",
    "\n",
    "        end1_time = end1_time + timedelta(minutes=delta_t)\n",
    "        str2_time = str2_time - timedelta(minutes=delta_t)\n",
    "\n",
    "        staypts_df.loc[pos, 'StateStart'] = end1_time\n",
    "        staypts_df.loc[pos+1, 'StateEnd'] = str2_time\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def visualize_hourly_state_weight():\n",
    "    global staypts_df\n",
    "    \n",
    "    #create a color dictionary for each cluster for the plot\n",
    "    dicts = {}\n",
    "    clu_list = []\n",
    "    clu_list = staypts_df['StateId'].unique()\n",
    "    r = lambda: random.randint(0,255)\n",
    "    #olors = sns.color_palette(\"Paired\", len(clu_list))\n",
    "    \n",
    "    for i in range(0, len(clu_list)):\n",
    "        #icts[clu_list[i]] = (colors[i])\n",
    "        dicts[clu_list[i]] = ('#%02X%02X%02X' % (r(),r(),r()))\n",
    "        \n",
    "    #create a new graph where we will later add rectangles for each hour:cluster\n",
    "    fig2 = plt.figure(figsize=(15,15))\n",
    "    ax1 = fig2.add_subplot(111, aspect='equal')\n",
    "\n",
    "    #get all the dates for y axis\n",
    "    date_list = staypts_df['Timestamp'].dt.date.unique()\n",
    "    y = range(0, len(date_list))\n",
    "    def_yticks = date_list\n",
    "    plt.yticks(y, def_yticks)\n",
    "    \n",
    "    #set the x axis limit from 0-24 hours of a day, y axis with dates\n",
    "    limsx = (0, 24)\n",
    "    limsy = (0, len(date_list))\n",
    "\n",
    "    date_counter = 0\n",
    "    last_date = staypts_df['Timestamp'][0].date()\n",
    "    last_hour = staypts_df['Timestamp'][0].hour\n",
    "    last_clusid = staypts_df['StateId'][0]\n",
    "    curr_count = 0\n",
    "    j = 0\n",
    "    \n",
    "    #drawing verical lines for each hour\n",
    "    for i in range(0, 24):\n",
    "        ax1.axvline(x= i, linewidth=1, color='r')\n",
    "\n",
    "    for i in range(0, len(staypts_df)):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        \n",
    "        if (i == len(staypts_df)-1):\n",
    "            a = staypts_df['Timestamp'][i-curr_count].hour + staypts_df['Timestamp'][i-curr_count].minute/60\n",
    "            b = staypts_df['Timestamp'][i].hour + staypts_df['Timestamp'][i].minute/60\n",
    "            width = b - a\n",
    "            height = 1\n",
    "            col_id = dicts.get(staypts_df['StateId'][i])\n",
    "            ax1.add_patch(patches.Rectangle((a, date_counter), width, height, color=col_id, label=staypts_df['StateId'][i]))\n",
    "            \n",
    "        #plot a rectangle if the hour or stateid or date has changed\n",
    "        if ((staypts_df['Timestamp'][i].hour != last_hour) | (staypts_df['StateId'][i] != last_clusid)\n",
    "           | (last_date != staypts_df['Timestamp'][i].date())):\n",
    "\n",
    "            if (curr_count == 1) & (staypts_df['Timestamp'][i].hour != last_hour):\n",
    "                a = staypts_df['Timestamp'][i-curr_count].hour + 1\n",
    "            else:\n",
    "                a = staypts_df['Timestamp'][i-curr_count].hour + staypts_df['Timestamp'][i-curr_count].minute/60\n",
    "\n",
    "            b = staypts_df['Timestamp'][i-1].hour + staypts_df['Timestamp'][i-1].minute/60\n",
    "\n",
    "            width = b - a\n",
    "            height = 1\n",
    "            col_id = dicts.get(staypts_df['StateId'][i-1])\n",
    "            ax1.add_patch(patches.Rectangle((a, date_counter), width, height, color=col_id, label=staypts_df['StateId'][i-1]))\n",
    "\n",
    "            curr_count = 1\n",
    "\n",
    "            if (staypts_df['Timestamp'][i].hour != last_hour):\n",
    "                last_hour = staypts_df['Timestamp'][i].hour\n",
    "            if (staypts_df['StateId'][i] != last_clusid):\n",
    "                last_clusid = staypts_df['StateId'][i]\n",
    "            if (last_date != staypts_df['Timestamp'][i].date()):\n",
    "                date_counter = date_counter + 1\n",
    "                last_date = staypts_df['Timestamp'][i].date()\n",
    "                ax1.axhline(y= date_counter, linewidth=1, color='r')\n",
    "\n",
    "        else:\n",
    "            curr_count = curr_count + 1\n",
    "            \n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    handle_list, label_list = [], []\n",
    "    for handle, label in zip(handles, labels):\n",
    "        if label not in label_list:\n",
    "            handle_list.append(handle)\n",
    "            label_list.append(label)\n",
    "    plt.legend(handle_list, label_list)\n",
    "\n",
    "    plt.xlim(limsx)\n",
    "    plt.ylim(limsy)\n",
    "    plt.show()\n",
    "#-----------------------------------------------------------------------------------\n",
    "def update_staypts_csv():\n",
    "     with open(dest_file_staypoints, 'a') as f:\n",
    "             (staypts_df).to_csv(f,  sep='\\t', encoding='utf-8')\n",
    "#-----------------------------------------------------------------------------------\n",
    "def update_hourly_weights_csv():\n",
    "    with open(dest_file_hourly_weights, 'a') as f:\n",
    "             (cluster_hourly_df).to_csv(f,  sep='\\t', encoding='utf-8')\n",
    "\n",
    "#------------------------------------------ S T A R T -----------------------------------------------\n",
    "#global dataframes used\n",
    "#user raw trajectory dataframe\n",
    "usr_trejec_df = pd.DataFrame()\n",
    "#all staypoints\n",
    "staypts_df = pd.DataFrame()\n",
    "#user trained model\n",
    "trained_model_df = pd.DataFrame()\n",
    "#current hour points\n",
    "curr_hr_df = pd.DataFrame()\n",
    "#current hour staypoints\n",
    "curr_hr_staypts_df = pd.DataFrame()\n",
    "#all staypoints\n",
    "staypts_df = pd.DataFrame()\n",
    "#hourly cluster\n",
    "cluster_hourly_df = pd.DataFrame()\n",
    "#final markov chains\n",
    "final_transition_df = pd.DataFrame()\n",
    "\n",
    "clus_dict = {}\n",
    "co_loc = {}\n",
    "pred_loc = {}\n",
    "lat_array = []\n",
    "lon_array = []\n",
    "global_count = 0\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------CHANGE HERE FOR USER AND DATE RANGE--------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Edit user name, and path locations for source and destination files\n",
    "user = \"001\"\n",
    "\n",
    "#parameters which can be changed\n",
    "state_d_thrhld = 200 #meters\n",
    "staypts_d_thrhld = 200 #meters\n",
    "staypts_t_thrhld = 20 #minutes\n",
    "track_t_thrhld = 30 #minutes\n",
    "\n",
    "#destination paths\n",
    "usr_directory = \"/home/shashank/Documents/location/code/stay points/v0.5 results/User \" + user\n",
    "usr_hrly_wght_directory = \"/home/shashank/Documents/location/code/stay points/v0.5 results/User \" + user + \"/hourlyweights\"\n",
    "usr_sty_pts_directory = \"/home/shashank/Documents/location/code/stay points/v0.5 results/User \" + user + \"/staypoints\"\n",
    "usr_markov_chains_directory = \"/home/shashank/Documents/location/code/stay points/v0.5 results/User \" + user + \"/markovchains\"\n",
    "dest_predicted_dir = \"/home/shashank/Documents/location/code/stay points/v0.5 results/User \" + user + \"/predict/\"\n",
    "\n",
    "if not os.path.exists(usr_directory):\n",
    "    os.makedirs(usr_directory)\n",
    "if not os.path.exists(usr_hrly_wght_directory):\n",
    "    os.makedirs(usr_hrly_wght_directory)\n",
    "if not os.path.exists(usr_sty_pts_directory):\n",
    "    os.makedirs(usr_sty_pts_directory)  \n",
    "if not os.path.exists(usr_markov_chains_directory):\n",
    "    os.makedirs(usr_markov_chains_directory)  \n",
    "if not os.path.exists(dest_predicted_dir):\n",
    "    os.makedirs(dest_predicted_dir)  \n",
    "\n",
    "#destination file names\n",
    "dest_file_staypoints = usr_sty_pts_directory + \"/staypoints.csv\"\n",
    "dest_file_hourly_weights = usr_hrly_wght_directory + \"/hourlyweights.csv\"\n",
    "dest_path_each_day_trsn_mat = usr_hrly_wght_directory + \"/\"\n",
    "dest_file_final_markov_chain = usr_markov_chains_directory + \"/final.csv\"\n",
    "\n",
    "#remove if the file already exists\n",
    "try:\n",
    "    os.remove(dest_file_staypoints)\n",
    "    os.remove(dest_file_hourly_weights)\n",
    "    os.remove(dest_file_final_markov_chain)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "#source paths\n",
    "file_source_raw = \"/home/shashank/Documents/location/Geolife Trajectories 1.3/Data/\" + user + \"/Trajectory/200811*.plt\" \n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------CHANGE HERE FOR USER AND DATE RANGE--------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#read test user trajectory file. In real scenerio, this will be the GPS read data\n",
    "read_usr_file()\n",
    "\n",
    "state_count = 0\n",
    "pos = 0\n",
    "row =1\n",
    "count = 1\n",
    "setting_for_staypoint(row, count)\n",
    "\n",
    "#I. Read the new locations in an online gps location input mode\n",
    "#  1. Everytime the hour changes, \n",
    "#                  A. Find staypoints for the last hour and assign staypointID\n",
    "#                  B. Cluster staypoints based on distance for last hour, form states and assign stateID\n",
    "#                  C. Calculate state hourly weights for last hour\n",
    "#                  D. Predict based on trained data(if available)\n",
    "#  2. Everytime the date changes,\n",
    "#                  A. Add the days data into the training data\n",
    "#  3. If the hour and the time has not been changed, add the data to current hour data\n",
    "\n",
    "#I\n",
    "for i in range(1, len(usr_trejec_df)):\n",
    "    \n",
    "    #stay_point_tuple structure\n",
    "    #(current cluster count, Stay point found flag, Staypoint ID, \n",
    "    #                                         Mean Lat, Mean Lon, Start Time, End Time)\n",
    "    stay_point_tuple = find_stay_points(usr_trejec_df['Latitude'][i], usr_trejec_df['Longitude'][i], \n",
    "                                        i, count)\n",
    "    \n",
    "    count = stay_point_tuple[0]\n",
    "    new_staypt_flag = stay_point_tuple[1]\n",
    "    \n",
    "    if (new_staypt_flag == True):\n",
    "        \n",
    "        staypt_count = stay_point_tuple[2]\n",
    "        \n",
    "        staypt_id1 = stay_point_tuple[3]\n",
    "        mean_lat1 = stay_point_tuple[4]\n",
    "        mean_lon1 = stay_point_tuple[5]\n",
    "        start_time1 = stay_point_tuple[6]\n",
    "        end_time1 = stay_point_tuple[7]\n",
    "        \n",
    "        staypt_id2 = stay_point_tuple[8]\n",
    "        mean_lat2 = stay_point_tuple[9]\n",
    "        mean_lon2 = stay_point_tuple[10]\n",
    "        start_time2 = stay_point_tuple[11]\n",
    "        end_time2 = stay_point_tuple[12]\n",
    "        \n",
    "        update_staypts(pos, staypt_count, staypt_id1, mean_lat1, mean_lon1, start_time1, end_time1,\n",
    "                      staypt_id2, mean_lat2, mean_lon2, start_time2, end_time2)\n",
    "        \n",
    "        form_states(pos, staypt_count, \n",
    "                    staypt_id1, mean_lat1, mean_lon1, start_time1, end_time1,\n",
    "                    staypt_id2, mean_lat2, mean_lon2, start_time2, end_time2)\n",
    "        \n",
    "        cal_start_end_states_time(pos, staypt_count)\n",
    "        \n",
    "        if staypt_count == 2:\n",
    "            pos = pos + 2\n",
    "        else:\n",
    "            pos = pos + 1\n",
    "            \n",
    "        \n",
    "        #cal_hourly_state_weight()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "staypts_df.to_csv(dest_file_staypoints, sep='\\t', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StayptId</th>\n",
       "      <th>StayMeanLat</th>\n",
       "      <th>StayMeanLon</th>\n",
       "      <th>StartTimestamp</th>\n",
       "      <th>EndTimestamp</th>\n",
       "      <th>StateId</th>\n",
       "      <th>StateMeanLat</th>\n",
       "      <th>StateMeanLon</th>\n",
       "      <th>StateStart</th>\n",
       "      <th>StateEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>40.069728</td>\n",
       "      <td>116.330728</td>\n",
       "      <td>2008-11-01 01:10:00</td>\n",
       "      <td>2008-11-01 01:40:38.201767</td>\n",
       "      <td>19.0</td>\n",
       "      <td>40.069728</td>\n",
       "      <td>116.330728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>40.074957</td>\n",
       "      <td>116.341682</td>\n",
       "      <td>2008-11-01 01:46:21.798233</td>\n",
       "      <td>2008-11-01 03:58:00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>40.074986</td>\n",
       "      <td>116.342950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>40.074895</td>\n",
       "      <td>116.341730</td>\n",
       "      <td>2008-11-01 01:48:00</td>\n",
       "      <td>2008-11-01 03:59:01.379877</td>\n",
       "      <td>23.0</td>\n",
       "      <td>40.074986</td>\n",
       "      <td>116.342950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>40.013874</td>\n",
       "      <td>116.306429</td>\n",
       "      <td>2008-11-01 04:34:58.620123</td>\n",
       "      <td>2008-11-01 05:44:10.521259</td>\n",
       "      <td>47.0</td>\n",
       "      <td>40.013874</td>\n",
       "      <td>116.306429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.0</td>\n",
       "      <td>39.903385</td>\n",
       "      <td>116.419932</td>\n",
       "      <td>2008-11-01 07:13:49.478741</td>\n",
       "      <td>2008-11-01 07:15:49.043554</td>\n",
       "      <td>73.0</td>\n",
       "      <td>39.903385</td>\n",
       "      <td>116.419932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74.0</td>\n",
       "      <td>39.975451</td>\n",
       "      <td>116.331571</td>\n",
       "      <td>2008-11-01 07:59:10.956446</td>\n",
       "      <td>2008-11-01 08:04:02.140333</td>\n",
       "      <td>74.0</td>\n",
       "      <td>39.974953</td>\n",
       "      <td>116.331919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76.0</td>\n",
       "      <td>39.978024</td>\n",
       "      <td>116.327564</td>\n",
       "      <td>2008-11-01 08:04:57.859667</td>\n",
       "      <td>2008-11-01 09:01:10.598430</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.977306</td>\n",
       "      <td>116.327396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013760</td>\n",
       "      <td>116.306470</td>\n",
       "      <td>2008-11-02 02:15:49.401570</td>\n",
       "      <td>2008-11-02 03:36:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>78.0</td>\n",
       "      <td>40.013825</td>\n",
       "      <td>116.306527</td>\n",
       "      <td>2008-11-02 03:08:00</td>\n",
       "      <td>2008-11-02 04:19:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79.0</td>\n",
       "      <td>40.013803</td>\n",
       "      <td>116.306475</td>\n",
       "      <td>2008-11-02 03:36:00</td>\n",
       "      <td>2008-11-02 04:19:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>79.0</td>\n",
       "      <td>40.013803</td>\n",
       "      <td>116.306475</td>\n",
       "      <td>2008-11-02 04:19:00</td>\n",
       "      <td>2008-11-02 04:19:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>80.0</td>\n",
       "      <td>40.017991</td>\n",
       "      <td>116.307560</td>\n",
       "      <td>2008-11-02 09:44:00</td>\n",
       "      <td>2008-11-02 09:47:05.131158</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.017991</td>\n",
       "      <td>116.307560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>84.0</td>\n",
       "      <td>40.004052</td>\n",
       "      <td>116.313039</td>\n",
       "      <td>2008-11-02 10:05:54.868842</td>\n",
       "      <td>2008-11-02 11:15:58.789349</td>\n",
       "      <td>84.0</td>\n",
       "      <td>40.004052</td>\n",
       "      <td>116.313039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>86.0</td>\n",
       "      <td>39.999491</td>\n",
       "      <td>116.318392</td>\n",
       "      <td>2008-11-02 11:23:01.210651</td>\n",
       "      <td>2008-11-02 12:05:00</td>\n",
       "      <td>86.0</td>\n",
       "      <td>39.999903</td>\n",
       "      <td>116.318208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>87.0</td>\n",
       "      <td>39.999873</td>\n",
       "      <td>116.318327</td>\n",
       "      <td>2008-11-02 11:28:00</td>\n",
       "      <td>2008-11-02 12:08:51.053646</td>\n",
       "      <td>86.0</td>\n",
       "      <td>39.999903</td>\n",
       "      <td>116.318208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90.0</td>\n",
       "      <td>40.005733</td>\n",
       "      <td>116.316286</td>\n",
       "      <td>2008-11-02 12:14:08.946354</td>\n",
       "      <td>2008-11-02 12:50:40.955969</td>\n",
       "      <td>90.0</td>\n",
       "      <td>40.005733</td>\n",
       "      <td>116.316286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>94.0</td>\n",
       "      <td>40.013970</td>\n",
       "      <td>116.306337</td>\n",
       "      <td>2008-11-02 13:06:19.044031</td>\n",
       "      <td>2008-11-02 14:10:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>95.0</td>\n",
       "      <td>40.013742</td>\n",
       "      <td>116.306543</td>\n",
       "      <td>2008-11-02 13:10:00</td>\n",
       "      <td>2008-11-02 14:10:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>95.0</td>\n",
       "      <td>40.013742</td>\n",
       "      <td>116.306543</td>\n",
       "      <td>2008-11-02 14:10:00</td>\n",
       "      <td>2008-11-02 14:10:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>96.0</td>\n",
       "      <td>40.013817</td>\n",
       "      <td>116.305757</td>\n",
       "      <td>2008-11-02 23:34:00</td>\n",
       "      <td>2008-11-02 23:34:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>96.0</td>\n",
       "      <td>40.013817</td>\n",
       "      <td>116.305757</td>\n",
       "      <td>2008-11-02 23:34:00</td>\n",
       "      <td>2008-11-02 23:34:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>97.0</td>\n",
       "      <td>40.014051</td>\n",
       "      <td>116.306287</td>\n",
       "      <td>2008-11-03 00:25:00</td>\n",
       "      <td>2008-11-03 00:26:19.239813</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>116.0</td>\n",
       "      <td>39.977966</td>\n",
       "      <td>116.327103</td>\n",
       "      <td>2008-11-03 00:52:40.760187</td>\n",
       "      <td>2008-11-03 13:32:00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.977306</td>\n",
       "      <td>116.327396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>117.0</td>\n",
       "      <td>39.979685</td>\n",
       "      <td>116.327149</td>\n",
       "      <td>2008-11-03 00:54:00</td>\n",
       "      <td>2008-11-03 13:33:34.614870</td>\n",
       "      <td>117.0</td>\n",
       "      <td>39.978903</td>\n",
       "      <td>116.327010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>134.0</td>\n",
       "      <td>40.013796</td>\n",
       "      <td>116.306506</td>\n",
       "      <td>2008-11-03 14:03:25.385130</td>\n",
       "      <td>2008-11-03 23:37:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>135.0</td>\n",
       "      <td>40.013849</td>\n",
       "      <td>116.306514</td>\n",
       "      <td>2008-11-03 14:05:00</td>\n",
       "      <td>2008-11-03 23:39:36.343995</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>152.0</td>\n",
       "      <td>39.978755</td>\n",
       "      <td>116.327531</td>\n",
       "      <td>2008-11-04 00:30:23.656005</td>\n",
       "      <td>2008-11-04 05:48:00</td>\n",
       "      <td>117.0</td>\n",
       "      <td>39.978903</td>\n",
       "      <td>116.327010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>153.0</td>\n",
       "      <td>39.978216</td>\n",
       "      <td>116.325524</td>\n",
       "      <td>2008-11-04 00:33:00</td>\n",
       "      <td>2008-11-04 05:49:20.012990</td>\n",
       "      <td>117.0</td>\n",
       "      <td>39.978903</td>\n",
       "      <td>116.327010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>158.0</td>\n",
       "      <td>39.975363</td>\n",
       "      <td>116.313794</td>\n",
       "      <td>2008-11-04 05:53:39.987010</td>\n",
       "      <td>2008-11-04 06:37:47.139910</td>\n",
       "      <td>158.0</td>\n",
       "      <td>39.975363</td>\n",
       "      <td>116.313794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>164.0</td>\n",
       "      <td>39.977878</td>\n",
       "      <td>116.327018</td>\n",
       "      <td>2008-11-04 06:52:12.860090</td>\n",
       "      <td>2008-11-04 09:51:20.864980</td>\n",
       "      <td>117.0</td>\n",
       "      <td>39.978903</td>\n",
       "      <td>116.327010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>705.0</td>\n",
       "      <td>39.986763</td>\n",
       "      <td>116.347678</td>\n",
       "      <td>2008-11-16 04:41:00</td>\n",
       "      <td>2008-11-16 05:35:50.987536</td>\n",
       "      <td>703.0</td>\n",
       "      <td>39.986730</td>\n",
       "      <td>116.347788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>725.0</td>\n",
       "      <td>40.015894</td>\n",
       "      <td>116.306619</td>\n",
       "      <td>2008-11-16 06:38:09.012464</td>\n",
       "      <td>2008-11-16 07:06:11.672417</td>\n",
       "      <td>725.0</td>\n",
       "      <td>40.015894</td>\n",
       "      <td>116.306619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>726.0</td>\n",
       "      <td>40.013824</td>\n",
       "      <td>116.306419</td>\n",
       "      <td>2008-11-16 07:01:48.327583</td>\n",
       "      <td>2008-11-16 09:51:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>727.0</td>\n",
       "      <td>40.013807</td>\n",
       "      <td>116.306544</td>\n",
       "      <td>2008-11-16 07:07:00</td>\n",
       "      <td>2008-11-16 09:51:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>727.0</td>\n",
       "      <td>40.013807</td>\n",
       "      <td>116.306544</td>\n",
       "      <td>2008-11-16 09:51:00</td>\n",
       "      <td>2008-11-16 09:51:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>728.0</td>\n",
       "      <td>40.014677</td>\n",
       "      <td>116.307099</td>\n",
       "      <td>2008-11-16 23:53:00</td>\n",
       "      <td>2008-11-16 23:56:04.409614</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>748.0</td>\n",
       "      <td>39.977752</td>\n",
       "      <td>116.328283</td>\n",
       "      <td>2008-11-17 00:58:55.590386</td>\n",
       "      <td>2008-11-17 04:24:00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.977306</td>\n",
       "      <td>116.327396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>749.0</td>\n",
       "      <td>39.978527</td>\n",
       "      <td>116.326272</td>\n",
       "      <td>2008-11-17 01:02:00</td>\n",
       "      <td>2008-11-17 04:31:51.445690</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.977306</td>\n",
       "      <td>116.327396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>752.0</td>\n",
       "      <td>39.982611</td>\n",
       "      <td>116.328957</td>\n",
       "      <td>2008-11-17 04:36:08.554310</td>\n",
       "      <td>2008-11-17 05:33:51.829664</td>\n",
       "      <td>631.0</td>\n",
       "      <td>39.982576</td>\n",
       "      <td>116.328367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>754.0</td>\n",
       "      <td>39.977982</td>\n",
       "      <td>116.327207</td>\n",
       "      <td>2008-11-17 05:35:08.170336</td>\n",
       "      <td>2008-11-17 07:01:17.191002</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.977306</td>\n",
       "      <td>116.327396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>755.0</td>\n",
       "      <td>39.984119</td>\n",
       "      <td>116.326999</td>\n",
       "      <td>2008-11-17 09:00:42.808998</td>\n",
       "      <td>2008-11-17 10:30:13.488783</td>\n",
       "      <td>755.0</td>\n",
       "      <td>39.984119</td>\n",
       "      <td>116.326999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>763.0</td>\n",
       "      <td>39.998484</td>\n",
       "      <td>116.325050</td>\n",
       "      <td>2008-11-17 11:01:46.511217</td>\n",
       "      <td>2008-11-17 13:15:29.089006</td>\n",
       "      <td>763.0</td>\n",
       "      <td>39.998484</td>\n",
       "      <td>116.325050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>767.0</td>\n",
       "      <td>40.008909</td>\n",
       "      <td>116.316549</td>\n",
       "      <td>2008-11-17 13:27:30.910994</td>\n",
       "      <td>2008-11-17 14:02:20.190903</td>\n",
       "      <td>330.0</td>\n",
       "      <td>40.009103</td>\n",
       "      <td>116.316503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>770.0</td>\n",
       "      <td>40.013800</td>\n",
       "      <td>116.306446</td>\n",
       "      <td>2008-11-17 14:12:39.809097</td>\n",
       "      <td>2008-11-17 23:44:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>771.0</td>\n",
       "      <td>40.013972</td>\n",
       "      <td>116.306082</td>\n",
       "      <td>2008-11-17 14:16:00</td>\n",
       "      <td>2008-11-17 23:46:46.764725</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>790.0</td>\n",
       "      <td>39.977447</td>\n",
       "      <td>116.327614</td>\n",
       "      <td>2008-11-18 00:43:13.235275</td>\n",
       "      <td>2008-11-18 13:28:00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.977306</td>\n",
       "      <td>116.327396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>791.0</td>\n",
       "      <td>39.978793</td>\n",
       "      <td>116.327243</td>\n",
       "      <td>2008-11-18 00:46:00</td>\n",
       "      <td>2008-11-18 13:28:41.033266</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.977306</td>\n",
       "      <td>116.327396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>792.0</td>\n",
       "      <td>39.981419</td>\n",
       "      <td>116.327315</td>\n",
       "      <td>2008-11-18 13:28:18.966734</td>\n",
       "      <td>2008-11-18 13:57:05.558313</td>\n",
       "      <td>631.0</td>\n",
       "      <td>39.982576</td>\n",
       "      <td>116.328367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>807.0</td>\n",
       "      <td>40.013770</td>\n",
       "      <td>116.306523</td>\n",
       "      <td>2008-11-18 14:34:54.441687</td>\n",
       "      <td>2008-11-18 23:50:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>808.0</td>\n",
       "      <td>40.013908</td>\n",
       "      <td>116.306575</td>\n",
       "      <td>2008-11-18 14:37:00</td>\n",
       "      <td>2008-11-18 23:51:58.795366</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>827.0</td>\n",
       "      <td>39.978120</td>\n",
       "      <td>116.326872</td>\n",
       "      <td>2008-11-19 00:31:01.204634</td>\n",
       "      <td>2008-11-19 10:47:00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.977306</td>\n",
       "      <td>116.327396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>828.0</td>\n",
       "      <td>39.976633</td>\n",
       "      <td>116.327381</td>\n",
       "      <td>2008-11-19 00:33:00</td>\n",
       "      <td>2008-11-19 10:48:11.490731</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.977306</td>\n",
       "      <td>116.327396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>834.0</td>\n",
       "      <td>39.951212</td>\n",
       "      <td>116.331678</td>\n",
       "      <td>2008-11-19 11:02:48.509269</td>\n",
       "      <td>2008-11-19 13:02:00</td>\n",
       "      <td>303.0</td>\n",
       "      <td>39.951160</td>\n",
       "      <td>116.332207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>835.0</td>\n",
       "      <td>39.951118</td>\n",
       "      <td>116.332246</td>\n",
       "      <td>2008-11-19 11:04:00</td>\n",
       "      <td>2008-11-19 13:04:09.503799</td>\n",
       "      <td>303.0</td>\n",
       "      <td>39.951160</td>\n",
       "      <td>116.332207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>863.0</td>\n",
       "      <td>40.013838</td>\n",
       "      <td>116.306459</td>\n",
       "      <td>2008-11-19 14:18:50.496201</td>\n",
       "      <td>2008-11-19 22:12:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>864.0</td>\n",
       "      <td>40.013845</td>\n",
       "      <td>116.306517</td>\n",
       "      <td>2008-11-19 14:21:00</td>\n",
       "      <td>2008-11-19 22:12:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>864.0</td>\n",
       "      <td>40.013845</td>\n",
       "      <td>116.306517</td>\n",
       "      <td>2008-11-19 22:12:00</td>\n",
       "      <td>2008-11-19 22:12:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>865.0</td>\n",
       "      <td>39.981643</td>\n",
       "      <td>116.328221</td>\n",
       "      <td>2008-11-20 12:18:00</td>\n",
       "      <td>2008-11-20 12:20:58.677396</td>\n",
       "      <td>631.0</td>\n",
       "      <td>39.982576</td>\n",
       "      <td>116.328367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>881.0</td>\n",
       "      <td>40.013807</td>\n",
       "      <td>116.306540</td>\n",
       "      <td>2008-11-20 13:15:01.322604</td>\n",
       "      <td>2008-11-20 23:49:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>882.0</td>\n",
       "      <td>40.013949</td>\n",
       "      <td>116.306552</td>\n",
       "      <td>2008-11-20 13:18:00</td>\n",
       "      <td>2008-11-20 23:49:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>40.013854</td>\n",
       "      <td>116.306511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     StayptId  StayMeanLat  StayMeanLon              StartTimestamp  \\\n",
       "0        19.0    40.069728   116.330728         2008-11-01 01:10:00   \n",
       "1        23.0    40.074957   116.341682  2008-11-01 01:46:21.798233   \n",
       "2        24.0    40.074895   116.341730         2008-11-01 01:48:00   \n",
       "3        47.0    40.013874   116.306429  2008-11-01 04:34:58.620123   \n",
       "4        73.0    39.903385   116.419932  2008-11-01 07:13:49.478741   \n",
       "5        74.0    39.975451   116.331571  2008-11-01 07:59:10.956446   \n",
       "6        76.0    39.978024   116.327564  2008-11-01 08:04:57.859667   \n",
       "7        77.0    40.013760   116.306470  2008-11-02 02:15:49.401570   \n",
       "8        78.0    40.013825   116.306527         2008-11-02 03:08:00   \n",
       "9        79.0    40.013803   116.306475         2008-11-02 03:36:00   \n",
       "10       79.0    40.013803   116.306475         2008-11-02 04:19:00   \n",
       "11       80.0    40.017991   116.307560         2008-11-02 09:44:00   \n",
       "12       84.0    40.004052   116.313039  2008-11-02 10:05:54.868842   \n",
       "13       86.0    39.999491   116.318392  2008-11-02 11:23:01.210651   \n",
       "14       87.0    39.999873   116.318327         2008-11-02 11:28:00   \n",
       "15       90.0    40.005733   116.316286  2008-11-02 12:14:08.946354   \n",
       "16       94.0    40.013970   116.306337  2008-11-02 13:06:19.044031   \n",
       "17       95.0    40.013742   116.306543         2008-11-02 13:10:00   \n",
       "18       95.0    40.013742   116.306543         2008-11-02 14:10:00   \n",
       "19       96.0    40.013817   116.305757         2008-11-02 23:34:00   \n",
       "20       96.0    40.013817   116.305757         2008-11-02 23:34:00   \n",
       "21       97.0    40.014051   116.306287         2008-11-03 00:25:00   \n",
       "22      116.0    39.977966   116.327103  2008-11-03 00:52:40.760187   \n",
       "23      117.0    39.979685   116.327149         2008-11-03 00:54:00   \n",
       "24      134.0    40.013796   116.306506  2008-11-03 14:03:25.385130   \n",
       "25      135.0    40.013849   116.306514         2008-11-03 14:05:00   \n",
       "26      152.0    39.978755   116.327531  2008-11-04 00:30:23.656005   \n",
       "27      153.0    39.978216   116.325524         2008-11-04 00:33:00   \n",
       "28      158.0    39.975363   116.313794  2008-11-04 05:53:39.987010   \n",
       "29      164.0    39.977878   116.327018  2008-11-04 06:52:12.860090   \n",
       "..        ...          ...          ...                         ...   \n",
       "106     705.0    39.986763   116.347678         2008-11-16 04:41:00   \n",
       "107     725.0    40.015894   116.306619  2008-11-16 06:38:09.012464   \n",
       "108     726.0    40.013824   116.306419  2008-11-16 07:01:48.327583   \n",
       "109     727.0    40.013807   116.306544         2008-11-16 07:07:00   \n",
       "110     727.0    40.013807   116.306544         2008-11-16 09:51:00   \n",
       "111     728.0    40.014677   116.307099         2008-11-16 23:53:00   \n",
       "112     748.0    39.977752   116.328283  2008-11-17 00:58:55.590386   \n",
       "113     749.0    39.978527   116.326272         2008-11-17 01:02:00   \n",
       "114     752.0    39.982611   116.328957  2008-11-17 04:36:08.554310   \n",
       "115     754.0    39.977982   116.327207  2008-11-17 05:35:08.170336   \n",
       "116     755.0    39.984119   116.326999  2008-11-17 09:00:42.808998   \n",
       "117     763.0    39.998484   116.325050  2008-11-17 11:01:46.511217   \n",
       "118     767.0    40.008909   116.316549  2008-11-17 13:27:30.910994   \n",
       "119     770.0    40.013800   116.306446  2008-11-17 14:12:39.809097   \n",
       "120     771.0    40.013972   116.306082         2008-11-17 14:16:00   \n",
       "121     790.0    39.977447   116.327614  2008-11-18 00:43:13.235275   \n",
       "122     791.0    39.978793   116.327243         2008-11-18 00:46:00   \n",
       "123     792.0    39.981419   116.327315  2008-11-18 13:28:18.966734   \n",
       "124     807.0    40.013770   116.306523  2008-11-18 14:34:54.441687   \n",
       "125     808.0    40.013908   116.306575         2008-11-18 14:37:00   \n",
       "126     827.0    39.978120   116.326872  2008-11-19 00:31:01.204634   \n",
       "127     828.0    39.976633   116.327381         2008-11-19 00:33:00   \n",
       "128     834.0    39.951212   116.331678  2008-11-19 11:02:48.509269   \n",
       "129     835.0    39.951118   116.332246         2008-11-19 11:04:00   \n",
       "130     863.0    40.013838   116.306459  2008-11-19 14:18:50.496201   \n",
       "131     864.0    40.013845   116.306517         2008-11-19 14:21:00   \n",
       "132     864.0    40.013845   116.306517         2008-11-19 22:12:00   \n",
       "133     865.0    39.981643   116.328221         2008-11-20 12:18:00   \n",
       "134     881.0    40.013807   116.306540  2008-11-20 13:15:01.322604   \n",
       "135     882.0    40.013949   116.306552         2008-11-20 13:18:00   \n",
       "\n",
       "                   EndTimestamp  StateId  StateMeanLat  StateMeanLon  \\\n",
       "0    2008-11-01 01:40:38.201767     19.0     40.069728    116.330728   \n",
       "1           2008-11-01 03:58:00     23.0     40.074986    116.342950   \n",
       "2    2008-11-01 03:59:01.379877     23.0     40.074986    116.342950   \n",
       "3    2008-11-01 05:44:10.521259     47.0     40.013874    116.306429   \n",
       "4    2008-11-01 07:15:49.043554     73.0     39.903385    116.419932   \n",
       "5    2008-11-01 08:04:02.140333     74.0     39.974953    116.331919   \n",
       "6    2008-11-01 09:01:10.598430     76.0     39.977306    116.327396   \n",
       "7           2008-11-02 03:36:00     77.0     40.013854    116.306511   \n",
       "8           2008-11-02 04:19:00     77.0     40.013854    116.306511   \n",
       "9           2008-11-02 04:19:00     77.0     40.013854    116.306511   \n",
       "10          2008-11-02 04:19:00     77.0     40.013854    116.306511   \n",
       "11   2008-11-02 09:47:05.131158     80.0     40.017991    116.307560   \n",
       "12   2008-11-02 11:15:58.789349     84.0     40.004052    116.313039   \n",
       "13          2008-11-02 12:05:00     86.0     39.999903    116.318208   \n",
       "14   2008-11-02 12:08:51.053646     86.0     39.999903    116.318208   \n",
       "15   2008-11-02 12:50:40.955969     90.0     40.005733    116.316286   \n",
       "16          2008-11-02 14:10:00     77.0     40.013854    116.306511   \n",
       "17          2008-11-02 14:10:00     77.0     40.013854    116.306511   \n",
       "18          2008-11-02 14:10:00     77.0     40.013854    116.306511   \n",
       "19          2008-11-02 23:34:00     77.0     40.013854    116.306511   \n",
       "20          2008-11-02 23:34:00     77.0     40.013854    116.306511   \n",
       "21   2008-11-03 00:26:19.239813     77.0     40.013854    116.306511   \n",
       "22          2008-11-03 13:32:00     76.0     39.977306    116.327396   \n",
       "23   2008-11-03 13:33:34.614870    117.0     39.978903    116.327010   \n",
       "24          2008-11-03 23:37:00     77.0     40.013854    116.306511   \n",
       "25   2008-11-03 23:39:36.343995     77.0     40.013854    116.306511   \n",
       "26          2008-11-04 05:48:00    117.0     39.978903    116.327010   \n",
       "27   2008-11-04 05:49:20.012990    117.0     39.978903    116.327010   \n",
       "28   2008-11-04 06:37:47.139910    158.0     39.975363    116.313794   \n",
       "29   2008-11-04 09:51:20.864980    117.0     39.978903    116.327010   \n",
       "..                          ...      ...           ...           ...   \n",
       "106  2008-11-16 05:35:50.987536    703.0     39.986730    116.347788   \n",
       "107  2008-11-16 07:06:11.672417    725.0     40.015894    116.306619   \n",
       "108         2008-11-16 09:51:00     77.0     40.013854    116.306511   \n",
       "109         2008-11-16 09:51:00     77.0     40.013854    116.306511   \n",
       "110         2008-11-16 09:51:00     77.0     40.013854    116.306511   \n",
       "111  2008-11-16 23:56:04.409614     77.0     40.013854    116.306511   \n",
       "112         2008-11-17 04:24:00     76.0     39.977306    116.327396   \n",
       "113  2008-11-17 04:31:51.445690     76.0     39.977306    116.327396   \n",
       "114  2008-11-17 05:33:51.829664    631.0     39.982576    116.328367   \n",
       "115  2008-11-17 07:01:17.191002     76.0     39.977306    116.327396   \n",
       "116  2008-11-17 10:30:13.488783    755.0     39.984119    116.326999   \n",
       "117  2008-11-17 13:15:29.089006    763.0     39.998484    116.325050   \n",
       "118  2008-11-17 14:02:20.190903    330.0     40.009103    116.316503   \n",
       "119         2008-11-17 23:44:00     77.0     40.013854    116.306511   \n",
       "120  2008-11-17 23:46:46.764725     77.0     40.013854    116.306511   \n",
       "121         2008-11-18 13:28:00     76.0     39.977306    116.327396   \n",
       "122  2008-11-18 13:28:41.033266     76.0     39.977306    116.327396   \n",
       "123  2008-11-18 13:57:05.558313    631.0     39.982576    116.328367   \n",
       "124         2008-11-18 23:50:00     77.0     40.013854    116.306511   \n",
       "125  2008-11-18 23:51:58.795366     77.0     40.013854    116.306511   \n",
       "126         2008-11-19 10:47:00     76.0     39.977306    116.327396   \n",
       "127  2008-11-19 10:48:11.490731     76.0     39.977306    116.327396   \n",
       "128         2008-11-19 13:02:00    303.0     39.951160    116.332207   \n",
       "129  2008-11-19 13:04:09.503799    303.0     39.951160    116.332207   \n",
       "130         2008-11-19 22:12:00     77.0     40.013854    116.306511   \n",
       "131         2008-11-19 22:12:00     77.0     40.013854    116.306511   \n",
       "132         2008-11-19 22:12:00     77.0     40.013854    116.306511   \n",
       "133  2008-11-20 12:20:58.677396    631.0     39.982576    116.328367   \n",
       "134         2008-11-20 23:49:00     77.0     40.013854    116.306511   \n",
       "135         2008-11-20 23:49:00     77.0     40.013854    116.306511   \n",
       "\n",
       "     StateStart  StateEnd  \n",
       "0           NaN       NaN  \n",
       "1           NaN       NaN  \n",
       "2           NaN       NaN  \n",
       "3           NaN       NaN  \n",
       "4           NaN       NaN  \n",
       "5           NaN       NaN  \n",
       "6           NaN       NaN  \n",
       "7           NaN       NaN  \n",
       "8           NaN       NaN  \n",
       "9           NaN       NaN  \n",
       "10          NaN       NaN  \n",
       "11          NaN       NaN  \n",
       "12          NaN       NaN  \n",
       "13          NaN       NaN  \n",
       "14          NaN       NaN  \n",
       "15          NaN       NaN  \n",
       "16          NaN       NaN  \n",
       "17          NaN       NaN  \n",
       "18          NaN       NaN  \n",
       "19          NaN       NaN  \n",
       "20          NaN       NaN  \n",
       "21          NaN       NaN  \n",
       "22          NaN       NaN  \n",
       "23          NaN       NaN  \n",
       "24          NaN       NaN  \n",
       "25          NaN       NaN  \n",
       "26          NaN       NaN  \n",
       "27          NaN       NaN  \n",
       "28          NaN       NaN  \n",
       "29          NaN       NaN  \n",
       "..          ...       ...  \n",
       "106         NaN       NaN  \n",
       "107         NaN       NaN  \n",
       "108         NaN       NaN  \n",
       "109         NaN       NaN  \n",
       "110         NaN       NaN  \n",
       "111         NaN       NaN  \n",
       "112         NaN       NaN  \n",
       "113         NaN       NaN  \n",
       "114         NaN       NaN  \n",
       "115         NaN       NaN  \n",
       "116         NaN       NaN  \n",
       "117         NaN       NaN  \n",
       "118         NaN       NaN  \n",
       "119         NaN       NaN  \n",
       "120         NaN       NaN  \n",
       "121         NaN       NaN  \n",
       "122         NaN       NaN  \n",
       "123         NaN       NaN  \n",
       "124         NaN       NaN  \n",
       "125         NaN       NaN  \n",
       "126         NaN       NaN  \n",
       "127         NaN       NaN  \n",
       "128         NaN       NaN  \n",
       "129         NaN       NaN  \n",
       "130         NaN       NaN  \n",
       "131         NaN       NaN  \n",
       "132         NaN       NaN  \n",
       "133         NaN       NaN  \n",
       "134         NaN       NaN  \n",
       "135         NaN       NaN  \n",
       "\n",
       "[136 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staypts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
