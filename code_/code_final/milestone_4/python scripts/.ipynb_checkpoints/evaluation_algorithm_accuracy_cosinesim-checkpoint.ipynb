{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from matplotlib.pyplot import figure\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from_user = 0\n",
    "to_user = 182\n",
    "src_path = \"C:/Users/12sha/Documents/thesislocation/Data/Final Example Results\"\n",
    "\n",
    "# fetch user vs train test months\n",
    "\n",
    "usern_mnth_df = pd.read_csv(\"C:/Users/12sha/Documents/thesislocation/Data/user_vs_traintestmonth.csv\", sep = \"\\t\")\n",
    "usern_mnth_df = usern_mnth_df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positives, true negatives, false positives, false negatives, accuracy\n",
    "\n",
    "# Find distance between two lan:lon points in meters\n",
    "def meters(lat1, lon1, lat2, lon2):\n",
    "    R = 6378.137  # Radius of earth in KM\n",
    "    dlat = lat2 * math.pi / 180 - lat1 * math.pi / 180\n",
    "    dlon = lon2 * math.pi / 180 - lon1 * math.pi / 180\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(lat1 * math.pi / 180) * math.cos(\n",
    "        lat2 * math.pi / 180) * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = R * c\n",
    "    return d * 1000  # meters\n",
    "\n",
    "\n",
    "def draw_plot(data, edge_color, fill_color):\n",
    "    bp = ax.boxplot(data, patch_artist=True)\n",
    "    for element in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']:\n",
    "        plt.setp(bp[element], color=edge_color)\n",
    "    plt.xticks(range(3))\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set(facecolor=fill_color)\n",
    "\n",
    "\n",
    "# calculate prediction parameters\n",
    "def check_pred(indx_row):\n",
    "    global predic_df\n",
    "    global tobepredicted_df\n",
    "    global correct_pred\n",
    "    global incorrect_pred\n",
    "    global true_pos\n",
    "    global false_pos\n",
    "    global true_neg\n",
    "    global false_neg\n",
    "\n",
    "    true_pred = False\n",
    "    visit_next_hour = False\n",
    "    visit_count_next_hour = 0\n",
    "    curr_hour = tobepredicted_df.loc[indx_row, 'Hour']\n",
    "    curr_date = tobepredicted_df.loc[indx_row, 'Date']\n",
    "\n",
    "    # check if there are points found in next hour\n",
    "    for k in range(indx_row + 1, len(tobepredicted_df)):\n",
    "\n",
    "        next_hour = tobepredicted_df.loc[k, 'Hour']\n",
    "        next_date = tobepredicted_df.loc[k, 'Date']\n",
    "\n",
    "        if (curr_hour != next_hour) or (curr_date != next_date):\n",
    "\n",
    "            if (curr_hour == 23) and (next_date == curr_date + timedelta(days=1)) and (next_hour == 0):\n",
    "                visit_next_hour = True\n",
    "                visit_count_next_hour = visit_count_next_hour + 1\n",
    "            elif (next_date == curr_date) and (next_hour == curr_hour + 1):\n",
    "                visit_next_hour = True\n",
    "                visit_count_next_hour = visit_count_next_hour + 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # visit encountered in next hour: Either:\n",
    "    #      A. True Positive, or\n",
    "    #      B. False Negative\n",
    "    if visit_next_hour == True:\n",
    "\n",
    "        # B. False Negative\n",
    "        if predic_df.empty:\n",
    "            false_neg = false_neg + 1\n",
    "        # A. True Positive\n",
    "        else:\n",
    "            true_pos = true_pos + 1\n",
    "\n",
    "            # check if prediction is correct or incorrect\n",
    "            for l in range(1, visit_count_next_hour + 1):\n",
    "\n",
    "                true_lat = tobepredicted_df['AvgLat'][indx_row + l]\n",
    "                true_lon = tobepredicted_df['AvgLon'][indx_row + l]\n",
    "                true_pred = False\n",
    "                for i in range(0, len(predic_df)):\n",
    "\n",
    "                    pred_lat = predic_df.loc[i, 'Latitude']\n",
    "                    pred_lon = predic_df.loc[i, 'Longitude']\n",
    "\n",
    "                    if meters(true_lat, true_lon, pred_lat, pred_lon) <= state_d_thrhld:\n",
    "                        correct_pred = correct_pred + 1\n",
    "                        true_pred = True\n",
    "                        break\n",
    "\n",
    "                if true_pred == True:\n",
    "                    break\n",
    "\n",
    "            if true_pred == False:\n",
    "                incorrect_pred = incorrect_pred + 1\n",
    "\n",
    "    # visit not encountered in next hour: Either:\n",
    "    #      A. False Positive, or\n",
    "    #      B. True Negative\n",
    "    else:\n",
    "        # B. True Negative\n",
    "        if predic_df.empty:\n",
    "            true_neg = true_neg + 1\n",
    "        # A. False Positive\n",
    "        else:\n",
    "            false_pos = false_pos + 1\n",
    "\n",
    "\n",
    "def predict():\n",
    "    global trained_model_df\n",
    "    global hourlyweights_df\n",
    "    global tobepredicted_df\n",
    "    global predic_df\n",
    "    global total_pred\n",
    "    global correct_pred\n",
    "    global incorrect_pred\n",
    "    global true_pos\n",
    "    global false_pos\n",
    "    global true_neg\n",
    "    global false_neg\n",
    "    \n",
    "    # if the training model or the hourly state weight file is empty, return\n",
    "    if hourlyweights_df.empty or trained_model_df.empty:\n",
    "        return\n",
    "    \n",
    "    # flag to track if the prediction is made or not\n",
    "    pred_made = False\n",
    "\n",
    "    # create a list for all the states, latitude, longitude, date, hour for which the prediction should be done\n",
    "    row = 0\n",
    "    for i in range(0, len(hourlyweights_df)):\n",
    "        for j in range(0, 24):\n",
    "            if hourlyweights_df.loc[i, str(j)] != 0:\n",
    "                tobepredicted_df.loc[row, 'Date'] = hourlyweights_df.loc[i, 'Date']\n",
    "                tobepredicted_df.loc[row, 'StateId'] = hourlyweights_df.loc[i, 'StateId']\n",
    "                tobepredicted_df.loc[row, 'AvgLat'] = hourlyweights_df.loc[i, 'AvgLat']\n",
    "                tobepredicted_df.loc[row, 'AvgLon'] = hourlyweights_df.loc[i, 'AvgLon']\n",
    "                tobepredicted_df.loc[row, 'Hour'] = j\n",
    "                row = row + 1\n",
    "    tobepredicted_df['Date'] = pd.to_datetime(tobepredicted_df['Date'])\n",
    "    tobepredicted_df = tobepredicted_df.sort_values(['Date', 'Hour'])\n",
    "    tobepredicted_df = tobepredicted_df.reset_index(drop=True)\n",
    "\n",
    "    # create prediction file path\n",
    "    file_name = \"Predictions.csv\"\n",
    "    file = dest_predicted_dir + file_name\n",
    "    # remove if the file already exists\n",
    "    try:\n",
    "        os.remove(file)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    # start reading to be predicted list and predict\n",
    "    for j in range(0, len(tobepredicted_df)):\n",
    "\n",
    "        new_lat = tobepredicted_df['AvgLat'][j]\n",
    "        new_lon = tobepredicted_df['AvgLon'][j]\n",
    "        hour = tobepredicted_df.loc[j, 'Hour']\n",
    "\n",
    "        for i in range(0, len(trained_model_df)):\n",
    "\n",
    "            trn_lat = trained_model_df['AvgLat'][i]\n",
    "            trn_lon = trained_model_df['AvgLon'][i]\n",
    "            predic_df = pd.DataFrame()\n",
    "            pred_made = False\n",
    "\n",
    "            if meters(trn_lat, trn_lon, new_lat, new_lon) <= state_d_thrhld:\n",
    "                # prediction is made\n",
    "                pred_made = True\n",
    "                total_pred = total_pred + 1\n",
    "\n",
    "                cluster_id = trained_model_df['StateId'][i]\n",
    "\n",
    "                jmp_dat = False\n",
    "                if hour == 23:\n",
    "                    jmp_dat = True\n",
    "\n",
    "                if jmp_dat == True:\n",
    "                    # check if there exists a next row\n",
    "                    if i + 1 < len(trained_model_df):\n",
    "                        from_col_no = 5\n",
    "                        to_col_no = from_col_no + trained_model_df['StateId'].nunique()\n",
    "                        predic_df = trained_model_df.iloc[i + 1:i + 2, int(from_col_no):int(to_col_no)]\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    from_col_no = trained_model_df['StateId'].nunique() * (hour + 1) + 5\n",
    "                    to_col_no = from_col_no + trained_model_df['StateId'].nunique()\n",
    "                    predic_df = trained_model_df.iloc[i:i + 1, int(from_col_no):int(to_col_no)]\n",
    "\n",
    "                predic_df = predic_df.T\n",
    "                predic_df['StateId'] = cluster_id\n",
    "                predic_df['PredState'] = predic_df.index\n",
    "                predic_df['PredState'] = predic_df['PredState'].map(lambda x: x.split('-', 2)[-1])\n",
    "                predic_df.columns = ['Probability', 'StateId', 'PredState']\n",
    "\n",
    "                predic_df = predic_df.sort_values('Probability', ascending=False)\n",
    "                predic_df['DateHour'] = str(tobepredicted_df['Date'][j]) + \" \" + str(tobepredicted_df['Hour'][j])\n",
    "                predic_df['Address'] = 0\n",
    "                predic_df['Latitude'] = 0.0\n",
    "                predic_df['Longitude'] = 0.0\n",
    "                predic_df = predic_df.reset_index(drop=True)\n",
    "\n",
    "                for k in range(0, len(predic_df)):\n",
    "                    clus_to_find = int(float(predic_df['PredState'][k]))\n",
    "                    add = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'Address'].values[0]\n",
    "                    lat = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'AvgLat'].values[0]\n",
    "                    lon = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'AvgLon'].values[0]\n",
    "\n",
    "                    predic_df.loc[k, 'Address'] = add\n",
    "                    predic_df.loc[k, 'Latitude'] = lat\n",
    "                    predic_df.loc[k, 'Longitude'] = lon\n",
    "\n",
    "                predic_df.to_csv(file, mode='a')\n",
    "                break\n",
    "\n",
    "        # if prediction was made, calculate prediction parameters\n",
    "        if pred_made == True:\n",
    "            check_pred(j)\n",
    "\n",
    "    # plot parameters\n",
    "    figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    objects = ('Tot Pred', 'Corr Pred', 'Incor Pred', 'True Pos', 'False Pos', 'False Neg', 'True Neg')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    performance = [total_pred, correct_pred, incorrect_pred, true_pos, false_pos, false_neg, true_neg]\n",
    "\n",
    "    plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(user + 'Prediction Performance')\n",
    "    destpng = dest_predicted_dir + \"pred performance.png\"\n",
    "    plt.savefig(destpng)\n",
    "    plt.show()\n",
    "\n",
    "    # prediction parameters\n",
    "    if total_pred != 0:\n",
    "        acc = correct_pred / total_pred * 100\n",
    "    else:\n",
    "        acc = 0\n",
    "\n",
    "    if (true_pos + false_neg) != 0:\n",
    "        true_pos_rate = true_pos / (true_pos + false_neg) * 100\n",
    "    else:\n",
    "        true_pos_rate = 0\n",
    "\n",
    "    if total_pred != 0:\n",
    "        acc_pos = (true_pos + true_neg) / total_pred * 100\n",
    "    else:\n",
    "        acc_pos = 0\n",
    "\n",
    "    if (true_pos + false_pos) != 0:\n",
    "        pos_pred_value = true_pos / (true_pos + false_pos) * 100\n",
    "        false_dis_rate = false_pos / (true_pos + false_pos) * 100\n",
    "    else:\n",
    "        pos_pred_value = 0\n",
    "        false_dis_rate = 0\n",
    "\n",
    "    prediction_perf = (\"Total Predictions: \" + str(total_pred) + \"\\nCorrect Predictions: \" + str(correct_pred) +\n",
    "                       \"\\nIncorrect Predictions: \" + str(incorrect_pred) +\n",
    "                       \"\\nAccuracy%: \" + str(acc) +\n",
    "                       \"\\nTrue Positives: \" + str(true_pos) + \"\\nFalse Positives: \" + str(false_pos) +\n",
    "                       \"\\nFalse Negatives: \" + str(false_neg) + \"\\nTrue Negatives: \" + str(true_neg) +\n",
    "                       \"\\nTrue positive rate(Recall)%: \" + str(true_pos_rate) +\n",
    "                       # \"\\nFalse positive rate(Fall-out): \" + str(false_pos_rate) +\n",
    "                       \"\\nAccuracy Positives%: \" + str(acc_pos) +\n",
    "                       \"\\nPositive predictive value(Precision)%: \" + str(pos_pred_value) +\n",
    "                       \"\\nFalse discovery rate%: \" + str(false_dis_rate))\n",
    "    text_file = dest_predicted_dir + \"corr pred ratio \" + str(acc) + \" .txt\"\n",
    "    \n",
    "    # delete the file if already present\n",
    "    for f in os.listdir(dest_predicted_dir):\n",
    "        if re.search(\"corr pred ratio \", f):\n",
    "            os.remove(os.path.join(dest_predicted_dir, f))\n",
    "            \n",
    "    # write the new file        \n",
    "    f = open(text_file, \"w+\")\n",
    "    f.write(prediction_perf)\n",
    "    f.close()\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "state_d_thrhld = 200\n",
    "acc_per = []\n",
    "err_per = []\n",
    "\n",
    "for i in range(from_user, to_user):\n",
    "    user = \"{0:0=3d}\".format(usern_mnth_df.loc[i, 'User'])\n",
    "    train_month = str(usern_mnth_df.loc[i, 'TrainMonth'])\n",
    "    test_month = str(usern_mnth_df.loc[i, 'TestMonth'])\n",
    "\n",
    "    tobepredicted_df = pd.DataFrame()\n",
    "    predic_df = pd.DataFrame()\n",
    "\n",
    "    # hourly weight file path\n",
    "    hourlyweights_file = src_path + \"/User \" + user + \"/\" + test_month + \"/hourlyweights/hourlyweights.csv\"\n",
    "    # trained model\n",
    "    trained_model_file = src_path + \"/User \" + user + \"/\" + train_month + \"/markovchains/final.csv\"\n",
    "    # predicted file\n",
    "    dest_predicted_dir = src_path + \"/User \" + user + \"/\" + test_month + \"/predict/\"\n",
    "\n",
    "    # counts\n",
    "    total_pred = 0\n",
    "    correct_pred = 0\n",
    "    incorrect_pred = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    true_neg = 0\n",
    "    false_neg = 0\n",
    "\n",
    "    # check if the path is found\n",
    "    if ((not os.path.exists(src_path + \"/User \" + user + \"/\" + test_month)) or\n",
    "            not os.path.exists(src_path + \"/User \" + user + \"/\" + train_month)):\n",
    "        print(\"For user: \" + user + \" test and training path not found.\" +\n",
    "              \" Check if you have files inside: <<\" + src_path + \"/User \" + user + \"/\" + test_month + \"/hourlyweights/hourlyweights.csv\"\n",
    "                                                                                                      \">> and <<\" + src_path + \"/User \" + user + \"/\" + train_month + \"/markovchains/final.csv>>\")\n",
    "        continue\n",
    "\n",
    "    # check if the file is found\n",
    "    if ((not os.path.isfile(trained_model_file)) or\n",
    "            (not os.path.isfile(hourlyweights_file))):\n",
    "        print(\"For user: \" + user + \" test and training files not found.\")\n",
    "        continue\n",
    "\n",
    "    trained_model_df = pd.read_csv(trained_model_file, header=0)\n",
    "    hourlyweights_df = pd.read_csv(hourlyweights_file, header=0, sep='\\t')\n",
    "\n",
    "    predict()\n",
    "\n",
    "    if total_pred != 0:\n",
    "        acc_per_v = correct_pred / total_pred\n",
    "        err_per_v = incorrect_pred / total_pred\n",
    "        acc_per.append(acc_per_v)\n",
    "        err_per.append(err_per_v)\n",
    "\n",
    "print(\"mean accuracy percentage: \" + str(sum(acc_per) / len(acc_per), 2))\n",
    "print(\"mean error percentage: \" + str(sum(err_per) / len(err_per)))\n",
    "\n",
    "# plot error percentage\n",
    "fig, ax = plt.subplots()\n",
    "draw_plot(err_per, \"tomato\", \"white\")\n",
    "plt.title(\"Error Percentage with median: \" + str(round(np.median(err_per),2)))\n",
    "\n",
    "# plot accuracy percentage\n",
    "fig, ax = plt.subplots()\n",
    "draw_plot(acc_per, \"tomato\", \"white\")\n",
    "plt.title(\"Accuracy Percentage with median: \" + str(round(np.median(acc_per),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 000. Cosine Similarity is: 0.7441054926788429\n",
      "User: 000. Accuracy Correctness is: 0.8223270440251572\n",
      "User: 000. Accuracy Precision is: 0.6398882235823254\n",
      "User: 001. Cosine Similarity is: 0.8383847717449147\n",
      "User: 001. Accuracy Correctness is: 0.8823529411764706\n",
      "User: 001. Accuracy Precision is: 0.7629533835314478\n",
      "User: 002. Cosine Similarity is: 0.9127305936676772\n",
      "User: 002. Accuracy Correctness is: 0.9388379204892966\n",
      "User: 002. Accuracy Precision is: 0.8146658581901199\n",
      "User: 003. Cosine Similarity is: 0.703296412253689\n",
      "User: 003. Accuracy Correctness is: 0.8566176470588235\n",
      "User: 003. Accuracy Precision is: 0.5964649988185924\n",
      "User: 004. Cosine Similarity is: 0.699513442541384\n",
      "User: 004. Accuracy Correctness is: 0.8038067349926794\n",
      "User: 004. Accuracy Precision is: 0.6048010933306601\n",
      "User: 005. Cosine Similarity is: 0.843894579366166\n",
      "User: 005. Accuracy Correctness is: 0.8947368421052632\n",
      "User: 005. Accuracy Precision is: 0.7426784959328948\n",
      "User: 006. Cosine Similarity is: 0.5647499077127542\n",
      "User: 006. Accuracy Correctness is: 0.8918918918918919\n",
      "User: 006. Accuracy Precision is: 0.4615062128099621\n",
      "User: 007. Cosine Similarity is: 0.8264415673635199\n",
      "User: 007. Accuracy Correctness is: 0.9174311926605505\n",
      "User: 007. Accuracy Precision is: 0.6717463247244697\n",
      "User: 008. Cosine Similarity is: 0.8679121068841995\n",
      "User: 008. Accuracy Correctness is: 0.8888888888888888\n",
      "User: 008. Accuracy Precision is: 0.7910136418315662\n",
      "User: 009. Cosine Similarity is: 0.942523767251392\n",
      "User: 009. Accuracy Correctness is: 0.9128919860627178\n",
      "User: 009. Accuracy Precision is: 0.8696165135044676\n",
      "User: 010. Cosine Similarity is: 0.7693084005039196\n",
      "User: 010. Accuracy Correctness is: 0.958974358974359\n",
      "User: 010. Accuracy Precision is: 0.6762584094055946\n",
      "User: 011. Cosine Similarity is: 0.9027980237127261\n",
      "User: 011. Accuracy Correctness is: 0.9111111111111111\n",
      "User: 011. Accuracy Precision is: 0.8198313428571142\n",
      "User: 012. Cosine Similarity is: 0.824254410038328\n",
      "User: 012. Accuracy Correctness is: 0.9266409266409267\n",
      "User: 012. Accuracy Precision is: 0.7494050816481072\n",
      "User: 013. Cosine Similarity is: 0.8391304212211682\n",
      "User: 013. Accuracy Correctness is: 0.966824644549763\n",
      "User: 013. Accuracy Precision is: 0.7547718659302882\n",
      "User: 014. Cosine Similarity is: 0.7231223954773223\n",
      "User: 014. Accuracy Correctness is: 0.856687898089172\n",
      "User: 014. Accuracy Precision is: 0.6315430515454737\n",
      "User: 015. Cosine Similarity is: 0.5340897843371833\n",
      "User: 015. Accuracy Correctness is: 0.9363057324840764\n",
      "User: 015. Accuracy Precision is: 0.4173323982334374\n",
      "User: 016. Cosine Similarity is: 0.6904147746085276\n",
      "User: 016. Accuracy Correctness is: 0.8986486486486487\n",
      "User: 016. Accuracy Precision is: 0.6076127640642328\n",
      "User: 017. Cosine Similarity is: 0.8290729523783212\n",
      "User: 017. Accuracy Correctness is: 0.8823529411764706\n",
      "User: 017. Accuracy Precision is: 0.7012544047565532\n",
      "User: 018. Cosine Similarity is: 0.9255726421906045\n",
      "User: 018. Accuracy Correctness is: 0.9941860465116279\n",
      "User: 018. Accuracy Precision is: 0.8333791616266517\n",
      "User: 019. Cosine Similarity is: 0.5267707465152264\n",
      "User: 019. Accuracy Correctness is: 0.8953488372093024\n",
      "User: 019. Accuracy Precision is: 0.4846549439727857\n",
      "User: 020. Cosine Similarity is: 0.8043253092044969\n",
      "User: 020. Accuracy Correctness is: 0.9634703196347032\n",
      "User: 020. Accuracy Precision is: 0.6942415386088259\n",
      "User: 022. Cosine Similarity is: 0.4640387702315113\n",
      "User: 022. Accuracy Correctness is: 0.9581881533101045\n",
      "User: 022. Accuracy Precision is: 0.36873339773731856\n",
      "User: 023. Cosine Similarity is: 0.8692767835376083\n",
      "User: 023. Accuracy Correctness is: 0.9618320610687023\n",
      "User: 023. Accuracy Precision is: 0.7672199762942737\n",
      "User: 024. Cosine Similarity is: 0.8104145831216469\n",
      "User: 024. Accuracy Correctness is: 0.9263456090651558\n",
      "User: 024. Accuracy Precision is: 0.7369702080358814\n",
      "User: 025. Cosine Similarity is: 0.7134643188459816\n",
      "User: 025. Accuracy Correctness is: 0.871536523929471\n",
      "User: 025. Accuracy Precision is: 0.6194225125954321\n",
      "User: 026. Cosine Similarity is: 0.5017796208651032\n",
      "User: 026. Accuracy Correctness is: 0.9899328859060402\n",
      "User: 026. Accuracy Precision is: 0.4092168614283464\n",
      "For user: 027 test and training path not found. Check if you have files inside: <<C:/Users/12sha/Documents/thesislocation/Data/Final Example Results/User 027/na/staypoints/staypoints.csv>> and <<C:/Users/12sha/Documents/thesislocation/Data/Final Example Results/User 027/200901/markovchains/final.csv>>\n",
      "User: 028. Cosine Similarity is: 0.8427990561499513\n",
      "User: 028. Accuracy Correctness is: 0.9937106918238994\n",
      "User: 028. Accuracy Precision is: 0.7448325621763335\n",
      "User: 029. Cosine Similarity is: 0.9678607203393943\n",
      "User: 029. Accuracy Correctness is: 0.9888888888888889\n",
      "User: 029. Accuracy Precision is: 0.9132852608487578\n",
      "User: 030. Cosine Similarity is: 0.7592059218210787\n",
      "User: 030. Accuracy Correctness is: 0.8502604166666666\n",
      "User: 030. Accuracy Precision is: 0.6512653092436763\n",
      "User: 033. Cosine Similarity is: 0.8768241956428136\n",
      "User: 033. Accuracy Correctness is: 1.0\n",
      "User: 033. Accuracy Precision is: 0.7858891938935983\n",
      "User: 034. Cosine Similarity is: 0.5350446645536643\n",
      "User: 034. Accuracy Correctness is: 0.7794117647058824\n",
      "User: 034. Accuracy Precision is: 0.4638019566398039\n",
      "User: 035. Cosine Similarity is: 0.8367889348814559\n",
      "User: 035. Accuracy Correctness is: 0.8754208754208754\n",
      "User: 035. Accuracy Precision is: 0.7632647276279758\n",
      "User: 037. Cosine Similarity is: 0.632067295532221\n",
      "User: 037. Accuracy Correctness is: 0.8271604938271605\n",
      "User: 037. Accuracy Precision is: 0.554038833535502\n",
      "User: 038. Cosine Similarity is: 0.37433370135368993\n",
      "User: 038. Accuracy Correctness is: 0.8477751756440282\n",
      "User: 038. Accuracy Precision is: 0.316275181608309\n",
      "User: 039. Cosine Similarity is: 0.7742001547338936\n",
      "User: 039. Accuracy Correctness is: 0.9137931034482759\n",
      "User: 039. Accuracy Precision is: 0.6912563752358737\n",
      "User: 040. Cosine Similarity is: 0.6888189940137337\n",
      "User: 040. Accuracy Correctness is: 0.9142857142857143\n",
      "User: 040. Accuracy Precision is: 0.6167914629955215\n",
      "User: 041. Cosine Similarity is: 0.8057766914523039\n",
      "User: 041. Accuracy Correctness is: 0.8870967741935484\n",
      "User: 041. Accuracy Precision is: 0.6760324198337004\n",
      "User: 042. Cosine Similarity is: 0.360354522714258\n",
      "User: 042. Accuracy Correctness is: 0.8518518518518519\n",
      "User: 042. Accuracy Precision is: 0.3635655153391595\n",
      "User: 044. Cosine Similarity is: 0.8394658782419646\n",
      "User: 044. Accuracy Correctness is: 0.9101123595505618\n",
      "User: 044. Accuracy Precision is: 0.7272545715840628\n",
      "For user: 045 test and training path not found. Check if you have files inside: <<C:/Users/12sha/Documents/thesislocation/Data/Final Example Results/User 045/201008/staypoints/staypoints.csv>> and <<C:/Users/12sha/Documents/thesislocation/Data/Final Example Results/User 045/201006/markovchains/final.csv>>\n",
      "User: 046. Cosine Similarity is: 0.9999999999913436\n",
      "User: 046. Accuracy Correctness is: 1.0\n",
      "User: 046. Accuracy Precision is: 0.7499934211688757\n",
      "For user: 047 test and training path not found. Check if you have files inside: <<C:/Users/12sha/Documents/thesislocation/Data/Final Example Results/User 047/na/staypoints/staypoints.csv>> and <<C:/Users/12sha/Documents/thesislocation/Data/Final Example Results/User 047/200708/markovchains/final.csv>>\n",
      "For user: 048 test and training path not found. Check if you have files inside: <<C:/Users/12sha/Documents/thesislocation/Data/Final Example Results/User 048/na/staypoints/staypoints.csv>> and <<C:/Users/12sha/Documents/thesislocation/Data/Final Example Results/User 048/200909/markovchains/final.csv>>\n",
      "For user: 049 test and training path not found. Check if you have files inside: <<C:/Users/12sha/Documents/thesislocation/Data/Final Example Results/User 049/na/staypoints/staypoints.csv>> and <<C:/Users/12sha/Documents/thesislocation/Data/Final Example Results/User 049/200909/markovchains/final.csv>>\n",
      "mean cosine similarity: 0.7491231827418995\n",
      "mean accuracy: 0.9086984474492183\n",
      "mean distance variation: 0.6561182364181993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Accuracy Precision with median: 0.6837573923207341')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cosine similarity\n",
    "\n",
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from_user = 0\n",
    "to_user = 50\n",
    "src_path = \"C:/Users/12sha/Documents/thesislocation/Data/Final Example Results\"\n",
    "\n",
    "# fetch user vs train test months\n",
    "\n",
    "usern_mnth_df = pd.read_csv(\"C:/Users/12sha/Documents/thesislocation/Data/user_vs_traintestmonth.csv\", sep=\"\\t\")\n",
    "usern_mnth_df = usern_mnth_df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "\n",
    "# Cosine Similarity\n",
    "\n",
    "# Find distance between two lan:lon points in meters\n",
    "def meters(lat1, lon1, lat2, lon2):\n",
    "    R = 6378.137  # Radius of earth in KM\n",
    "    dLat = lat2 * math.pi / 180 - lat1 * math.pi / 180\n",
    "    dLon = lon2 * math.pi / 180 - lon1 * math.pi / 180\n",
    "    a = math.sin(dLat / 2) * math.sin(dLat / 2) + math.cos(lat1 * math.pi / 180) * math.cos(\n",
    "        lat2 * math.pi / 180) * math.sin(dLon / 2) * math.sin(dLon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = R * c\n",
    "    return d * 1000  # meters\n",
    "\n",
    "\n",
    "def draw_plot(data, edge_color, fill_color):\n",
    "    bp = ax.boxplot(data, patch_artist=True)\n",
    "    for element in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']:\n",
    "        plt.setp(bp[element], color=edge_color)\n",
    "    plt.xticks(range(3))\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set(facecolor=fill_color)\n",
    "\n",
    "\n",
    "def dotproduct(v1, v2):\n",
    "    return sum((a * b) for a, b in zip(v1, v2))\n",
    "\n",
    "\n",
    "def length(v):\n",
    "    return math.sqrt(dotproduct(v, v))\n",
    "\n",
    "\n",
    "# def find_similarity(pred_prob, act_prob_all):\n",
    "#    return math.acos(dotproduct(pred_prob, act_prob_all) / (length(pred_prob) * length(act_prob_all)))\n",
    "\n",
    "def find_similarity(pred_prob, act_prob_all):\n",
    "    result = 1 - spatial.distance.cosine(pred_prob, act_prob_all)\n",
    "    return result\n",
    "\n",
    "\n",
    "def total_variation_distance(pred_prob, act_prob_all):\n",
    "    diff_sum = 0\n",
    "    for i in range(0, len(pred_prob)):\n",
    "        diff_sum = diff_sum + abs(pred_prob[i] - act_prob_all[i])\n",
    "    diff_sum = diff_sum/2\n",
    "    return diff_sum\n",
    "\n",
    "\n",
    "def accuracy(pred_prob, act_prob_all):\n",
    "    acc = False\n",
    "    if sum(pred_prob)!=0:\n",
    "        # find the max in predicted list\n",
    "        max_pred = max(pred_prob)\n",
    "        max_pred_pos = [i for i, j in enumerate(pred_prob) if j == max_pred]\n",
    "\n",
    "        # find max in ground truth list\n",
    "        max_truth = max(act_prob_all)\n",
    "        max_truth_pos = [i for i, j in enumerate(act_prob_all) if j == max_truth]\n",
    "\n",
    "        # check if max prediction list and max ground truth list matches\n",
    "        acc = not set(max_pred_pos).isdisjoint(max_truth_pos)\n",
    "    return acc\n",
    "\n",
    "\n",
    "# calculate prediction parameters\n",
    "def check_pred(hour, indx_row):\n",
    "    global predic_df\n",
    "    global hrywghts_df\n",
    "    global similarity_arr\n",
    "    global precision_arr\n",
    "    global correct_arr\n",
    "\n",
    "    pred_prob = predic_df['PredProbability'].values\n",
    "    act_prob_all = [0] * len(pred_prob)\n",
    "    curr_date = hrywghts_df.loc[indx_row, 'Date']\n",
    "\n",
    "    jmp_dat = False\n",
    "    if hour == 23:\n",
    "        jmp_dat = True\n",
    "\n",
    "    # check if there are GPS coordinates found in next hour\n",
    "    # the next hour is checked for the entire day, and all the visits in the next hour are recorded\n",
    "    hrywghts_day_df = hrywghts_df.loc[hrywghts_df['Date'] == curr_date]\n",
    "    hrywghts_day_df = hrywghts_day_df.reset_index(drop=True)\n",
    "    for k in range(0, len(hrywghts_day_df)):\n",
    "        if jmp_dat == True:\n",
    "            if k + 1 < len(hrywghts_day_df):\n",
    "                next_hour = 0\n",
    "                row = k + 1\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            next_hour = hour + 1\n",
    "            row = k\n",
    "\n",
    "        if hrywghts_day_df.loc[row, str(next_hour)] != 0:\n",
    "\n",
    "            true_lat = hrywghts_day_df['AvgLat'][row]\n",
    "            true_lon = hrywghts_day_df['AvgLon'][row]\n",
    "\n",
    "            # look for the next visited GPS coordinate in the predicted vector\n",
    "            for i in range(0, len(predic_df)):\n",
    "                pred_lat = predic_df.loc[i, 'Latitude']\n",
    "                pred_lon = predic_df.loc[i, 'Longitude']\n",
    "\n",
    "                if meters(true_lat, true_lon, pred_lat, pred_lon) <= state_d_thrhld:\n",
    "                    act_prob_all[i] = hrywghts_day_df.loc[k, str(next_hour)]\n",
    "                    break\n",
    "\n",
    "    #   Use the below code if the method \"find_similarity\" used as to find the cosine degree\n",
    "    #     #if the actual_prob_all has all 0's, this means the prediction is incorrect and hence similarity is 0.\n",
    "    #     if np.mean(act_prob_all) == 0:\n",
    "    #         similarity = 90\n",
    "    #     else:\n",
    "    #         similarity = find_similarity(pred_prob, act_prob_all)\n",
    "    # Find cosine similarity between actual probability and predicted probability vectors\n",
    "    similarity = find_similarity(pred_prob, act_prob_all)\n",
    "    similarity_arr = np.append(similarity_arr, similarity)\n",
    "    predic_df['ActProbability'] = act_prob_all\n",
    "    predic_df['Similarity'] = similarity\n",
    "\n",
    "    # accuracy\n",
    "    acc = accuracy(pred_prob, act_prob_all)\n",
    "    correct_arr = np.append(correct_arr, acc)\n",
    "\n",
    "    # total variation distance\n",
    "    tot_var_dis = total_variation_distance(pred_prob, act_prob_all)\n",
    "    precision_arr = np.append(precision_arr, 1-tot_var_dis)\n",
    "\n",
    "\n",
    "def predict():\n",
    "    global trained_model_df\n",
    "    global hrywghts_df\n",
    "    global predic_df\n",
    "\n",
    "    file_name = \"Similarity.csv\"\n",
    "    file = dest_predicted_dir + file_name\n",
    "\n",
    "    # remove if the file already exists\n",
    "    try:\n",
    "        os.remove(file)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    # read user movements for each time slot\n",
    "    for j in range(0, len(hrywghts_df)):\n",
    "        for h in range(0, 24):\n",
    "            # continue only if the data is non-zero\n",
    "            if hrywghts_df.loc[j, str(h)] != 0:\n",
    "                hour = h\n",
    "                new_lat = hrywghts_df['AvgLat'][j]\n",
    "                new_lon = hrywghts_df['AvgLon'][j]\n",
    "                # current state probabilities\n",
    "                curr_state_prob = hrywghts_df.loc[j, str(h)]\n",
    "\n",
    "                # search the coordinate in markov model\n",
    "                for i in range(0, len(trained_model_df)):\n",
    "\n",
    "                    trn_lat = trained_model_df['AvgLat'][i]\n",
    "                    trn_lon = trained_model_df['AvgLon'][i]\n",
    "                    predic_df = pd.DataFrame()\n",
    "\n",
    "                    if meters(trn_lat, trn_lon, new_lat, new_lon) <= state_d_thrhld:\n",
    "\n",
    "                        cluster_id = trained_model_df['StateId'][i]\n",
    "\n",
    "                        # next hour prediction probabilities\n",
    "                        jmp_dat = False\n",
    "                        if hour == 23:\n",
    "                            jmp_dat = True\n",
    "\n",
    "                        if jmp_dat == True:\n",
    "                            # check if there exists a next row\n",
    "                            if i + 1 < len(trained_model_df):\n",
    "                                from_col_no = 5\n",
    "                                to_col_no = from_col_no + trained_model_df['StateId'].nunique()\n",
    "                                predic_df = trained_model_df.iloc[i + 1:i + 2, from_col_no:to_col_no]\n",
    "                            else:\n",
    "                                break\n",
    "                        else:\n",
    "                            from_col_no = trained_model_df['StateId'].nunique() * (hour + 1) + 5\n",
    "                            to_col_no = from_col_no + trained_model_df['StateId'].nunique()\n",
    "                            predic_df = trained_model_df.iloc[i:i + 1, from_col_no:to_col_no]\n",
    "\n",
    "                        predic_df = (predic_df).T\n",
    "\n",
    "                        predic_df['StateId'] = cluster_id\n",
    "                        predic_df['PredState'] = predic_df.index\n",
    "                        predic_df['PredState'] = predic_df['PredState'].map(lambda x: x.split('-', 2)[-1])\n",
    "\n",
    "                        predic_df.columns = ['PredProbability', 'StateId', 'PredState']\n",
    "\n",
    "                        # predic_df = predic_df.sort_values('Probability', ascending=False).head(10)\n",
    "                        predic_df = predic_df.sort_values('PredProbability', ascending=False)\n",
    "                        predic_df['DateHour'] = str(hrywghts_df['Date'][j]) + \" \" + str(hour)\n",
    "                        predic_df['Address'] = 0\n",
    "                        predic_df['Latitude'] = 0.0\n",
    "                        predic_df['Longitude'] = 0.0\n",
    "                        predic_df = predic_df.reset_index(drop=True)\n",
    "\n",
    "                        for k in range(0, len(predic_df)):\n",
    "                            # import pdb; pdb.set_trace()\n",
    "                            clus_to_find = int(float(predic_df['PredState'][k]))\n",
    "                            add = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'Address'].values[\n",
    "                                0]\n",
    "                            lat = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'AvgLat'].values[\n",
    "                                0]\n",
    "                            lon = trained_model_df.loc[(trained_model_df['StateId'] == clus_to_find), 'AvgLon'].values[\n",
    "                                0]\n",
    "\n",
    "                            predic_df.loc[k, 'Address'] = add\n",
    "                            predic_df.loc[k, 'Latitude'] = lat\n",
    "                            predic_df.loc[k, 'Longitude'] = lon\n",
    "\n",
    "                        # if prediction was made, calculate prediction parameters\n",
    "                        check_pred(hour, j)\n",
    "\n",
    "                        predic_df.to_csv(file, mode='a')\n",
    "                        break\n",
    "\n",
    "\n",
    "# --------------------------------------- MAIN ----------------------------------------------------------------\n",
    "state_d_thrhld = 200\n",
    "cos_sim_mean = []\n",
    "cor_mean = []\n",
    "pre_mean = []\n",
    "\n",
    "for i in range(from_user, to_user):\n",
    "\n",
    "    user = \"{0:0=3d}\".format(usern_mnth_df.loc[i, 'User'])\n",
    "    train_month = str(usern_mnth_df.loc[i, 'TrainMonth'])\n",
    "    test_month = str(usern_mnth_df.loc[i, 'TestMonth'])\n",
    "\n",
    "    tobepredicted_df = pd.DataFrame()\n",
    "    predic_df = pd.DataFrame()\n",
    "\n",
    "    # hourly weights file\n",
    "    hrly_wghts_file = src_path + \"/User \" + user + \"/\" + test_month + \"/hourlyweights/hourlyweights.csv\"\n",
    "    # trained model\n",
    "    trained_model_file = src_path + \"/User \" + user + \"/\" + train_month + \"/markovchains/final.csv\"\n",
    "    # predicted file\n",
    "    dest_predicted_dir = src_path + \"/User \" + user + \"/\" + test_month + \"/predict/\"\n",
    "\n",
    "    similarity_arr = []\n",
    "    precision_arr = []\n",
    "    correct_arr = []\n",
    "\n",
    "    # check if the path is found\n",
    "    if ((not os.path.exists(src_path + \"/User \" + user + \"/\" + test_month)) or\n",
    "            not os.path.exists(src_path + \"/User \" + user + \"/\" + train_month)):\n",
    "        print(\"For user: \" + user + \" test and training path not found.\" +\n",
    "              \" Check if you have files inside: <<\" + src_path + \"/User \" + user + \"/\" + test_month + \"/staypoints/staypoints.csv\"\n",
    "                                                                                                      \">> and <<\" + src_path + \"/User \" + user + \"/\" + train_month + \"/markovchains/final.csv>>\")\n",
    "        continue\n",
    "\n",
    "    # check if the file is found\n",
    "    if ((not os.path.isfile(trained_model_file)) or\n",
    "            (not os.path.isfile(hrly_wghts_file))):\n",
    "        print(\"For user: \" + user + \" test and training files not found.\")\n",
    "        continue\n",
    "\n",
    "    trained_model_df = pd.read_csv(trained_model_file, header=0)\n",
    "    hrywghts_df = pd.read_csv(hrly_wghts_file, header=0, sep='\\t')\n",
    "\n",
    "    # start the prediction\n",
    "    predict()\n",
    "\n",
    "    # delete the file if already present\n",
    "    for f in os.listdir(dest_predicted_dir):\n",
    "        if re.search(\"Similarity mean \", f):\n",
    "            os.remove(os.path.join(dest_predicted_dir, f))\n",
    "\n",
    "    # save similarity mean in a text file for each user\n",
    "    if len(similarity_arr) != 0:\n",
    "        similarity_arr = similarity_arr[np.logical_not(np.isnan(similarity_arr))]\n",
    "        sim_mean = np.mean(similarity_arr)\n",
    "        text_file = dest_predicted_dir + \"Similarity mean \" + str(sim_mean) + \" .txt\"\n",
    "        f = open(text_file, \"w+\")\n",
    "        f.close()\n",
    "        print(\"User: \" + user + \". Cosine Similarity is: \" + str(sim_mean))\n",
    "        cos_sim_mean.append(sim_mean)\n",
    "\n",
    "    # calculate mean of accuracy and distance variation for each user\n",
    "    if len(correct_arr) != 0:\n",
    "        print(\"User: \" + user + \". Accuracy Correctness is: \" + str(np.mean(correct_arr)))\n",
    "        cor_mean.append(np.mean(correct_arr))\n",
    "    if len(precision_arr) != 0:\n",
    "        print(\"User: \" + user + \". Accuracy Precision is: \" + str(np.mean(precision_arr)))\n",
    "        pre_mean.append(np.mean(precision_arr))\n",
    "\n",
    "if len(cos_sim_mean) != 0:\n",
    "    cos_sim_mean = [x for x in cos_sim_mean if str(x) != 'nan']\n",
    "    print(\"mean cosine similarity: \" + str(sum(cos_sim_mean) / len(cos_sim_mean)))\n",
    "\n",
    "if len(cor_mean) != 0:\n",
    "    print(\"mean accuracy (correctness): \" + str(sum(cor_mean) / len(cor_mean)))\n",
    "\n",
    "if len(pre_mean) != 0:\n",
    "    print(\"mean accuracy (preciosn): \" + str(sum(pre_mean) / len(pre_mean)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "draw_plot(cos_sim_mean, \"skyblue\", \"white\")\n",
    "plt.title(\"Cosine Similarity with median: \" + str(np.median(cos_sim_mean)))\n",
    "\n",
    "draw_plot(cor_mean, \"skyblue\", \"white\")\n",
    "plt.title(\"Accuracy Correctness with median: \" + str(np.median(cor_mean)))\n",
    "\n",
    "draw_plot(pre_mean, \"skyblue\", \"white\")\n",
    "plt.title(\"Accuracy Precision with median: \" + str(np.median(pre_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
